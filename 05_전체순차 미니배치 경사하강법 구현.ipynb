{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "200_Fl5Wu7Yr"
      ],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.0.2"
      ],
      "metadata": {
        "trusted": true,
        "id": "-KE6KjA6u7Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f243349c-d3a5-4bb4-ab6a-a42e19c82eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (3.3.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.25.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "jBM26Z5ivmZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "bostonDF['PRICE'] = boston.target\n",
        "bostonDF.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Yb9T2XRju7Yp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "9ce3081b-98ec-4994-a013-2afd0e2c9916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  PRICE  \n",
              "0     15.3  396.90   4.98   24.0  \n",
              "1     17.8  396.90   9.14   21.6  \n",
              "2     17.8  392.83   4.03   34.7  \n",
              "3     18.7  394.63   2.94   33.4  \n",
              "4     18.7  396.90   5.33   36.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab1bf856-7c40-41cf-bb78-819c135c8250\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab1bf856-7c40-41cf-bb78-819c135c8250')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab1bf856-7c40-41cf-bb78-819c135c8250 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab1bf856-7c40-41cf-bb78-819c135c8250');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9785f44-f246-4af7-8137-621c7b84760c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9785f44-f246-4af7-8137-621c7b84760c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9785f44-f246-4af7-8137-621c7b84760c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bostonDF",
              "summary": "{\n  \"name\": \"bostonDF\",\n  \"rows\": 506,\n  \"fields\": [\n    {\n      \"column\": \"CRIM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.60154510533249,\n        \"min\": 0.00632,\n        \"max\": 88.9762,\n        \"num_unique_values\": 504,\n        \"samples\": [\n          0.09178,\n          0.05644,\n          0.10574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.32245299451514,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          25.0,\n          30.0,\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INDUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.860352940897585,\n        \"min\": 0.46,\n        \"max\": 27.74,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          8.14,\n          1.47,\n          1.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CHAS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25399404134041037,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NOX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11587767566755595,\n        \"min\": 0.385,\n        \"max\": 0.871,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          0.401,\n          0.538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7026171434153233,\n        \"min\": 3.561,\n        \"max\": 8.78,\n        \"num_unique_values\": 446,\n        \"samples\": [\n          6.849,\n          4.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.148861406903617,\n        \"min\": 2.9,\n        \"max\": 100.0,\n        \"num_unique_values\": 356,\n        \"samples\": [\n          51.8,\n          33.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DIS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.105710126627611,\n        \"min\": 1.1296,\n        \"max\": 12.1265,\n        \"num_unique_values\": 412,\n        \"samples\": [\n          2.2955,\n          4.2515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.707259384239366,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 168.53711605495903,\n        \"min\": 187.0,\n        \"max\": 711.0,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          370.0,\n          666.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PTRATIO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1649455237144406,\n        \"min\": 12.6,\n        \"max\": 22.0,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          19.6,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91.29486438415783,\n        \"min\": 0.32,\n        \"max\": 396.9,\n        \"num_unique_values\": 357,\n        \"samples\": [\n          396.24,\n          395.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LSTAT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.141061511348571,\n        \"min\": 1.73,\n        \"max\": 37.97,\n        \"num_unique_values\": 455,\n        \"samples\": [\n          6.15,\n          4.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRICE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.197104087379818,\n        \"min\": 5.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          14.1,\n          22.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochastic Gradient Descent와 Mini Batch Gradient Descent 구현\n",
        "* SGD 는 전체 데이터에서 **한건만** 임의로 선택하여 Gradient Descent 로 Weight/Bias Update 계산한 뒤 Weight/Bias 적용\n",
        "* Mini Batch GD는 전체 데이터에서 **Batch 건수만큼** 데이터를 선택하여 Gradient Descent로 Weight/Bias Update 계산한 뒤 Weight/Bias 적용"
      ],
      "metadata": {
        "id": "KH1rzO7Ru7Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RM, LSTAT 속성만 스케일링\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])"
      ],
      "metadata": {
        "id": "wjnUf0rJzj-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 반복 시 순차적으로 일정한 batch 크기만큼의 데이터를 전체 학습데이터에 걸쳐서 가져오는 Mini-Batch GD 수행"
      ],
      "metadata": {
        "id": "YFXdpF7Hu7Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_update_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate=0.01):\n",
        "\n",
        "    # 데이터 건수\n",
        "    N = target_batch.shape[0]\n",
        "\n",
        "    # 예측 값\n",
        "    predicted_batch = w1 * rm_batch+ w2 * lstat_batch + bias\n",
        "\n",
        "    # 실제값과 예측값의 차이\n",
        "    diff_batch = target_batch - predicted_batch\n",
        "\n",
        "    # bias 를 array 기반으로 구하기 위해서 설정\n",
        "    bias_factors = np.ones((N,))\n",
        "\n",
        "    # weight와 bias를 얼마나 update할 것인지를 계산\n",
        "    w1_update = -(2/N)*learning_rate*(np.dot(rm_batch.T, diff_batch))\n",
        "    w2_update = -(2/N)*learning_rate*(np.dot(lstat_batch.T, diff_batch))\n",
        "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff_batch))\n",
        "\n",
        "    # Mean Squared Error값을 계산\n",
        "    # mse_loss = np.mean(np.square(diff))\n",
        "\n",
        "    # weight와 bias가 update되어야 할 값 반환\n",
        "    return bias_update, w1_update, w2_update"
      ],
      "metadata": {
        "id": "p0GBabn-yPpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_gradient_descent()는 인자로 batch_size(배치 크기)를 입력 받음\n",
        "def batch_gradient_descent(features, target, iter_epochs=1000, batch_size=30, verbose=1):\n",
        "\n",
        "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
        "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정.\n",
        "    w1 = np.zeros((1,))\n",
        "    w2 = np.zeros((1,))\n",
        "    bias = np.zeros((1, ))\n",
        "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
        "\n",
        "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨\n",
        "    learning_rate = 0.01\n",
        "    rm = features[:, 0]\n",
        "    lstat = features[:, 1]\n",
        "\n",
        "    # NumPy 난수 생성기의 시드(seed) 값을 2024로 설정 -> 같은 시드를 사용하면 항상 같은 무작위 수가 생성\n",
        "    np.random.seed(2024)\n",
        "\n",
        "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행\n",
        "    for i in range(iter_epochs):\n",
        "\n",
        "        # batch_size 만큼 데이터를 가져와서 weight/bias update를 수행하는 로직을 전체 데이터 건수만큼 반복\n",
        "        # start(0), end(506), step(30)\n",
        "        for batch_step in range(0, target.shape[0], batch_size):\n",
        "\n",
        "            # batch_step부터 batch_size만큼 순차적인 데이터를 가져옴\n",
        "            rm_batch = rm[batch_step : batch_size + batch_step]\n",
        "            lstat_batch = lstat[batch_step : batch_size + batch_step]\n",
        "            target_batch = target[batch_step : batch_size + batch_step]\n",
        "\n",
        "            # Batch GD 기반으로 Weight/Bias의 Update를 구함\n",
        "            bias_update, w1_update, w2_update = get_update_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate)\n",
        "\n",
        "            # Batch GD로 구한 weight/bias의 update 적용\n",
        "            w1 = w1 - w1_update\n",
        "            w2 = w2 - w2_update\n",
        "            bias = bias - bias_update\n",
        "\n",
        "            if verbose:\n",
        "                print('Epoch:', i+1,'/', iter_epochs, 'batch step:', batch_step)\n",
        "\n",
        "                # Loss는 전체 학습 데이터 기반으로 구해야 함\n",
        "                predicted = w1 * rm + w2*lstat + bias\n",
        "                diff = target - predicted\n",
        "                mse_loss = np.mean(np.square(diff))\n",
        "                print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
        "\n",
        "    return w1, w2, bias"
      ],
      "metadata": {
        "trusted": true,
        "id": "Od7zpBaYu7Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터를 순차적으로 가져오는 batch_gradient_descent 함수 호출로 학습(epochs 500번, batch_size=30) - 모든 데이터를 학습하므로 오래걸림\n",
        "w1, w2, bias = batch_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=500, batch_size=30, verbose=1)\n",
        "print('##### 최종 w1, w2, bias #######')\n",
        "print(w1, w2, bias)"
      ],
      "metadata": {
        "id": "ypCyO0jbwNWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d5ed87-9026-44e9-991c-42c2f17db9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch: 354 / 500 batch step: 0\n",
            "w1: [25.63681754] w2: [-23.59856786] bias: [16.13577515] loss: 30.540060069710925\n",
            "Epoch: 354 / 500 batch step: 30\n",
            "w1: [25.6299224] w2: [-23.59871148] bias: [16.12200024] loss: 30.545085325058558\n",
            "Epoch: 354 / 500 batch step: 60\n",
            "w1: [25.60814658] w2: [-23.60586014] bias: [16.08046181] loss: 30.56492597712335\n",
            "Epoch: 354 / 500 batch step: 90\n",
            "w1: [25.60169053] w2: [-23.60985298] bias: [16.06522279] loss: 30.5735075276295\n",
            "Epoch: 354 / 500 batch step: 120\n",
            "w1: [25.61146441] w2: [-23.57915213] bias: [16.10154573] loss: 30.553448874027207\n",
            "Epoch: 354 / 500 batch step: 150\n",
            "w1: [25.64605267] w2: [-23.57786479] bias: [16.14542527] loss: 30.53498963798446\n",
            "Epoch: 354 / 500 batch step: 180\n",
            "w1: [25.7140912] w2: [-23.56081123] bias: [16.24842632] loss: 30.522521686008563\n",
            "Epoch: 354 / 500 batch step: 210\n",
            "w1: [25.7513791] w2: [-23.54041121] bias: [16.30803687] loss: 30.53481679295732\n",
            "Epoch: 354 / 500 batch step: 240\n",
            "w1: [25.79072083] w2: [-23.53448281] bias: [16.35022255] loss: 30.553505930407276\n",
            "Epoch: 354 / 500 batch step: 270\n",
            "w1: [25.80729687] w2: [-23.5346081] bias: [16.36749284] loss: 30.563326749060575\n",
            "Epoch: 354 / 500 batch step: 300\n",
            "w1: [25.78751489] w2: [-23.54091524] bias: [16.32830291] loss: 30.544825981504438\n",
            "Epoch: 354 / 500 batch step: 330\n",
            "w1: [25.75126679] w2: [-23.55362053] bias: [16.25677275] loss: 30.52465355627508\n",
            "Epoch: 354 / 500 batch step: 360\n",
            "w1: [25.76270543] w2: [-23.52416853] bias: [16.3461229] loss: 30.54869551270206\n",
            "Epoch: 354 / 500 batch step: 390\n",
            "w1: [25.73708836] w2: [-23.53589351] bias: [16.31200863] loss: 30.534666790367698\n",
            "Epoch: 354 / 500 batch step: 420\n",
            "w1: [25.68793357] w2: [-23.57902375] bias: [16.21749429] loss: 30.522145639839586\n",
            "Epoch: 354 / 500 batch step: 450\n",
            "w1: [25.6627223] w2: [-23.59654204] bias: [16.17458396] loss: 30.528413904803696\n",
            "Epoch: 354 / 500 batch step: 480\n",
            "w1: [25.64558675] w2: [-23.59822627] bias: [16.1480471] loss: 30.535705419695834\n",
            "Epoch: 355 / 500 batch step: 0\n",
            "w1: [25.63921456] w2: [-23.59921947] bias: [16.13472608] loss: 30.539997027574238\n",
            "Epoch: 355 / 500 batch step: 30\n",
            "w1: [25.6323195] w2: [-23.59936181] bias: [16.12095224] loss: 30.545020929760366\n",
            "Epoch: 355 / 500 batch step: 60\n",
            "w1: [25.61054262] w2: [-23.60651054] bias: [16.07941233] loss: 30.56486024757207\n",
            "Epoch: 355 / 500 batch step: 90\n",
            "w1: [25.60408513] w2: [-23.6105032] bias: [16.06417183] loss: 30.573442425556955\n",
            "Epoch: 355 / 500 batch step: 120\n",
            "w1: [25.61386151] w2: [-23.57979801] bias: [16.10050159] loss: 30.55337788597262\n",
            "Epoch: 355 / 500 batch step: 150\n",
            "w1: [25.6484476] w2: [-23.5785102] bias: [16.14437931] loss: 30.534924401533257\n",
            "Epoch: 355 / 500 batch step: 180\n",
            "w1: [25.71648068] w2: [-23.56145683] bias: [16.24737337] loss: 30.52246373346075\n",
            "Epoch: 355 / 500 batch step: 210\n",
            "w1: [25.75376367] w2: [-23.54105648] bias: [16.30697863] loss: 30.534758415138878\n",
            "Epoch: 355 / 500 batch step: 240\n",
            "w1: [25.7931001] w2: [-23.5351287] bias: [16.34915803] loss: 30.553446665607165\n",
            "Epoch: 355 / 500 batch step: 270\n",
            "w1: [25.80967203] w2: [-23.53525437] bias: [16.36642253] loss: 30.563265080149716\n",
            "Epoch: 355 / 500 batch step: 300\n",
            "w1: [25.789889] w2: [-23.54156138] bias: [16.32723153] loss: 30.54476515374265\n",
            "Epoch: 355 / 500 batch step: 330\n",
            "w1: [25.75364025] w2: [-23.55426656] bias: [16.25570068] loss: 30.524595480730003\n",
            "Epoch: 355 / 500 batch step: 360\n",
            "w1: [25.76507955] w2: [-23.52480902] bias: [16.34505836] loss: 30.548632273448177\n",
            "Epoch: 355 / 500 batch step: 390\n",
            "w1: [25.73946512] w2: [-23.53652857] bias: [16.31095227] loss: 30.53460679818345\n",
            "Epoch: 355 / 500 batch step: 420\n",
            "w1: [25.69031188] w2: [-23.57965688] bias: [16.21644136] loss: 30.52208765296937\n",
            "Epoch: 355 / 500 batch step: 450\n",
            "w1: [25.66510114] w2: [-23.59717427] bias: [16.17353272] loss: 30.528355405762372\n",
            "Epoch: 355 / 500 batch step: 480\n",
            "w1: [25.64796629] w2: [-23.59885679] bias: [16.14699854] loss: 30.535644516346974\n",
            "Epoch: 356 / 500 batch step: 0\n",
            "w1: [25.64159441] w2: [-23.59984878] bias: [16.13367904] loss: 30.539934926818077\n",
            "Epoch: 356 / 500 batch step: 30\n",
            "w1: [25.63469943] w2: [-23.59998985] bias: [16.11990627] loss: 30.544957489969555\n",
            "Epoch: 356 / 500 batch step: 60\n",
            "w1: [25.61292151] w2: [-23.60713865] bias: [16.07836494] loss: 30.564795480054954\n",
            "Epoch: 356 / 500 batch step: 90\n",
            "w1: [25.60646262] w2: [-23.61113114] bias: [16.06312298] loss: 30.573378273167215\n",
            "Epoch: 356 / 500 batch step: 120\n",
            "w1: [25.61624145] w2: [-23.58042168] bias: [16.09945944] loss: 30.553307951977267\n",
            "Epoch: 356 / 500 batch step: 150\n",
            "w1: [25.6508254] w2: [-23.5791334] bias: [16.14333539] loss: 30.534860125774074\n",
            "Epoch: 356 / 500 batch step: 180\n",
            "w1: [25.71885312] w2: [-23.5620802] bias: [16.24632257] loss: 30.522406637939188\n",
            "Epoch: 356 / 500 batch step: 210\n",
            "w1: [25.75613125] w2: [-23.54167955] bias: [16.3059226] loss: 30.534700900831034\n",
            "Epoch: 356 / 500 batch step: 240\n",
            "w1: [25.79546246] w2: [-23.53575237] bias: [16.34809579] loss: 30.553388273248057\n",
            "Epoch: 356 / 500 batch step: 270\n",
            "w1: [25.81203033] w2: [-23.53587841] bias: [16.36535461] loss: 30.563204324889963\n",
            "Epoch: 356 / 500 batch step: 300\n",
            "w1: [25.79224628] w2: [-23.54218528] bias: [16.32616257] loss: 30.54470523825179\n",
            "Epoch: 356 / 500 batch step: 330\n",
            "w1: [25.7559969] w2: [-23.55489035] bias: [16.25463108] loss: 30.524538277305894\n",
            "Epoch: 356 / 500 batch step: 360\n",
            "w1: [25.76743685] w2: [-23.52542736] bias: [16.34399617] loss: 30.548569989031314\n",
            "Epoch: 356 / 500 batch step: 390\n",
            "w1: [25.741825] w2: [-23.53714158] bias: [16.30989811] loss: 30.53454769058676\n",
            "Epoch: 356 / 500 batch step: 420\n",
            "w1: [25.69267327] w2: [-23.58026802] bias: [16.21539054] loss: 30.522030514150206\n",
            "Epoch: 356 / 500 batch step: 450\n",
            "w1: [25.66746303] w2: [-23.59778453] bias: [16.17248354] loss: 30.528297771074087\n",
            "Epoch: 356 / 500 batch step: 480\n",
            "w1: [25.65032888] w2: [-23.59946536] bias: [16.14595201] loss: 30.535584514727557\n",
            "Epoch: 357 / 500 batch step: 0\n",
            "w1: [25.64395731] w2: [-23.60045616] bias: [16.13263402] loss: 30.53987374484578\n",
            "Epoch: 357 / 500 batch step: 30\n",
            "w1: [25.63706243] w2: [-23.60059599] bias: [16.11886233] loss: 30.54489498289079\n",
            "Epoch: 357 / 500 batch step: 60\n",
            "w1: [25.61528349] w2: [-23.60774484] bias: [16.07731963] loss: 30.564731651716038\n",
            "Epoch: 357 / 500 batch step: 90\n",
            "w1: [25.60882322] w2: [-23.61173715] bias: [16.06207624] loss: 30.57331504781797\n",
            "Epoch: 357 / 500 batch step: 120\n",
            "w1: [25.61860446] w2: [-23.58102351] bias: [16.09841928] loss: 30.553239047705336\n",
            "Epoch: 357 / 500 batch step: 150\n",
            "w1: [25.65318631] w2: [-23.57973476] bias: [16.14229351] loss: 30.534796787897502\n",
            "Epoch: 357 / 500 batch step: 180\n",
            "w1: [25.72120873] w2: [-23.56268174] bias: [16.2452739] loss: 30.522350378305543\n",
            "Epoch: 357 / 500 batch step: 210\n",
            "w1: [25.75848208] w2: [-23.54228078] bias: [16.30486877] loss: 30.53464422881456\n",
            "Epoch: 357 / 500 batch step: 240\n",
            "w1: [25.79780812] w2: [-23.53635419] bias: [16.34703585] loss: 30.5533307319897\n",
            "Epoch: 357 / 500 batch step: 270\n",
            "w1: [25.81437201] w2: [-23.53648061] bias: [16.36428908] loss: 30.56314446127291\n",
            "Epoch: 357 / 500 batch step: 300\n",
            "w1: [25.79458696] w2: [-23.54278733] bias: [16.32509604] loss: 30.54464621301715\n",
            "Epoch: 357 / 500 batch step: 330\n",
            "w1: [25.75833698] w2: [-23.55549228] bias: [16.25356395] loss: 30.524481924623313\n",
            "Epoch: 357 / 500 batch step: 360\n",
            "w1: [25.76977754] w2: [-23.52602394] bias: [16.34293634] loss: 30.548508636801547\n",
            "Epoch: 357 / 500 batch step: 390\n",
            "w1: [25.74416822] w2: [-23.53773294] bias: [16.30884615] loss: 30.534489446148065\n",
            "Epoch: 357 / 500 batch step: 420\n",
            "w1: [25.69501796] w2: [-23.58085755] bias: [16.21434182] loss: 30.521974202561637\n",
            "Epoch: 357 / 500 batch step: 450\n",
            "w1: [25.6698082] w2: [-23.5983732] bias: [16.17143643] loss: 30.528240979639804\n",
            "Epoch: 357 / 500 batch step: 480\n",
            "w1: [25.65267474] w2: [-23.60005237] bias: [16.14490752] loss: 30.535525393145896\n",
            "Epoch: 358 / 500 batch step: 0\n",
            "w1: [25.64630348] w2: [-23.60104199] bias: [16.13159103] loss: 30.539813459702827\n",
            "Epoch: 358 / 500 batch step: 30\n",
            "w1: [25.6394087] w2: [-23.6011806] bias: [16.11782043] loss: 30.544833386373586\n",
            "Epoch: 358 / 500 batch step: 60\n",
            "w1: [25.61762879] w2: [-23.60832951] bias: [16.0762764] loss: 30.56466874034473\n",
            "Epoch: 358 / 500 batch step: 90\n",
            "w1: [25.61116716] w2: [-23.61232164] bias: [16.06103161] loss: 30.573252727508546\n",
            "Epoch: 358 / 500 batch step: 120\n",
            "w1: [25.62095076] w2: [-23.58160388] bias: [16.09738112] loss: 30.553171149489604\n",
            "Epoch: 358 / 500 batch step: 150\n",
            "w1: [25.65553055] w2: [-23.58031467] bias: [16.14125366] loss: 30.534734365737425\n",
            "Epoch: 358 / 500 batch step: 180\n",
            "w1: [25.72354775] w2: [-23.56326182] bias: [16.24422737] loss: 30.5222949340369\n",
            "Epoch: 358 / 500 batch step: 210\n",
            "w1: [25.76081637] w2: [-23.54286056] bias: [16.30381714] loss: 30.534588378486145\n",
            "Epoch: 358 / 500 batch step: 240\n",
            "w1: [25.8001373] w2: [-23.53693456] bias: [16.34597819] loss: 30.553274021109317\n",
            "Epoch: 358 / 500 batch step: 270\n",
            "w1: [25.81669728] w2: [-23.53706133] bias: [16.36322592] loss: 30.56308546791837\n",
            "Epoch: 358 / 500 batch step: 300\n",
            "w1: [25.79691126] w2: [-23.54336791] bias: [16.32403193] loss: 30.544588056652422\n",
            "Epoch: 358 / 500 batch step: 330\n",
            "w1: [25.7606607] w2: [-23.55607274] bias: [16.25249928] loss: 30.524426401921115\n",
            "Epoch: 358 / 500 batch step: 360\n",
            "w1: [25.77210186] w2: [-23.52659914] bias: [16.34187886] loss: 30.548448194745614\n",
            "Epoch: 358 / 500 batch step: 390\n",
            "w1: [25.746495] w2: [-23.53830301] bias: [16.30779639] loss: 30.53443204405301\n",
            "Epoch: 358 / 500 batch step: 420\n",
            "w1: [25.69734617] w2: [-23.58142585] bias: [16.21329522] loss: 30.52191869798819\n",
            "Epoch: 358 / 500 batch step: 450\n",
            "w1: [25.67213687] w2: [-23.59894067] bias: [16.17039138] loss: 30.52818501097\n",
            "Epoch: 358 / 500 batch step: 480\n",
            "w1: [25.6550041] w2: [-23.6006182] bias: [16.14386508] loss: 30.53546713052908\n",
            "Epoch: 359 / 500 batch step: 0\n",
            "w1: [25.64863315] w2: [-23.60160666] bias: [16.13055007] loss: 30.539754050057418\n",
            "Epoch: 359 / 500 batch step: 30\n",
            "w1: [25.64173848] w2: [-23.60174405] bias: [16.11678057] loss: 30.544772678892894\n",
            "Epoch: 359 / 500 batch step: 60\n",
            "w1: [25.61995762] w2: [-23.60889301] bias: [16.07523526] loss: 30.564606724356413\n",
            "Epoch: 359 / 500 batch step: 90\n",
            "w1: [25.61349465] w2: [-23.61288497] bias: [16.05998909] loss: 30.5731912908605\n",
            "Epoch: 359 / 500 batch step: 120\n",
            "w1: [25.62328056] w2: [-23.58216317] bias: [16.09634495] loss: 30.5531042343116\n",
            "Epoch: 359 / 500 batch step: 150\n",
            "w1: [25.65785833] w2: [-23.58087349] bias: [16.14021586] loss: 30.53467283775169\n",
            "Epoch: 359 / 500 batch step: 180\n",
            "w1: [25.72587039] w2: [-23.56382081] bias: [16.24318298] loss: 30.522240285206856\n",
            "Epoch: 359 / 500 batch step: 210\n",
            "w1: [25.76313433] w2: [-23.54341926] bias: [16.3027677] loss: 30.534533329839583\n",
            "Epoch: 359 / 500 batch step: 240\n",
            "w1: [25.80245023] w2: [-23.53749384] bias: [16.34492281] loss: 30.553218120482782\n",
            "Epoch: 359 / 500 batch step: 270\n",
            "w1: [25.81900635] w2: [-23.53762097] bias: [16.36216514] loss: 30.563027324055366\n",
            "Epoch: 359 / 500 batch step: 300\n",
            "w1: [25.79921939] w2: [-23.5439274] bias: [16.32297023] loss: 30.544530748380694\n",
            "Epoch: 359 / 500 batch step: 330\n",
            "w1: [25.76296827] w2: [-23.5566321] bias: [16.25143705] loss: 30.524371689037622\n",
            "Epoch: 359 / 500 batch step: 360\n",
            "w1: [25.77441001] w2: [-23.52715333] bias: [16.34082372] loss: 30.548388641467803\n",
            "Epoch: 359 / 500 batch step: 390\n",
            "w1: [25.74880556] w2: [-23.53885217] bias: [16.30674882] loss: 30.534375464083762\n",
            "Epoch: 359 / 500 batch step: 420\n",
            "w1: [25.69965811] w2: [-23.58197329] bias: [16.21225073] loss: 30.52186398080086\n",
            "Epoch: 359 / 500 batch step: 450\n",
            "w1: [25.67444926] w2: [-23.5994873] bias: [16.16934839] loss: 30.528129845165935\n",
            "Epoch: 359 / 500 batch step: 480\n",
            "w1: [25.65731718] w2: [-23.6011632] bias: [16.14282467] loss: 30.535409706404185\n",
            "Epoch: 360 / 500 batch step: 0\n",
            "w1: [25.65094653] w2: [-23.60215052] bias: [16.12951114] loss: 30.539695495181668\n",
            "Epoch: 360 / 500 batch step: 30\n",
            "w1: [25.64405199] w2: [-23.60228672] bias: [16.11574273] loss: 30.54471283953026\n",
            "Epoch: 360 / 500 batch step: 60\n",
            "w1: [25.6222702] w2: [-23.60943572] bias: [16.0741962] loss: 30.564545582773583\n",
            "Epoch: 360 / 500 batch step: 90\n",
            "w1: [25.61580591] w2: [-23.61342751] bias: [16.05894867] loss: 30.57313071709891\n",
            "Epoch: 360 / 500 batch step: 120\n",
            "w1: [25.6255941] w2: [-23.58270175] bias: [16.09531077] loss: 30.55303827978249\n",
            "Epoch: 360 / 500 batch step: 150\n",
            "w1: [25.66016988] w2: [-23.5814116] bias: [16.13918009] loss: 30.53461218300329\n",
            "Epoch: 360 / 500 batch step: 180\n",
            "w1: [25.72817687] w2: [-23.56435908] bias: [16.24214073] loss: 30.522186412467224\n",
            "Epoch: 360 / 500 batch step: 210\n",
            "w1: [25.76543619] w2: [-23.54395725] bias: [16.30172047] loss: 30.534479063447456\n",
            "Epoch: 360 / 500 batch step: 240\n",
            "w1: [25.80474712] w2: [-23.5380324] bias: [16.3438697] loss: 30.553163010566305\n",
            "Epoch: 360 / 500 batch step: 270\n",
            "w1: [25.82129944] w2: [-23.53815987] bias: [16.36110673] loss: 30.56297000950361\n",
            "Epoch: 360 / 500 batch step: 300\n",
            "w1: [25.80151156] w2: [-23.54446615] bias: [16.32191094] loss: 30.54447426801598\n",
            "Epoch: 360 / 500 batch step: 330\n",
            "w1: [25.7652599] w2: [-23.55717073] bias: [16.25037728] loss: 30.52431776639229\n",
            "Epoch: 360 / 500 batch step: 360\n",
            "w1: [25.7767022] w2: [-23.52768687] bias: [16.33977093] loss: 30.54832995617141\n",
            "Epoch: 360 / 500 batch step: 390\n",
            "w1: [25.75110011] w2: [-23.53938079] bias: [16.30570345] loss: 30.534319686600828\n",
            "Epoch: 360 / 500 batch step: 420\n",
            "w1: [25.701954] w2: [-23.58250022] bias: [16.21120834] loss: 30.52181003193912\n",
            "Epoch: 360 / 500 batch step: 450\n",
            "w1: [25.67674557] w2: [-23.60001345] bias: [16.16830747] loss: 30.528075462901747\n",
            "Epoch: 360 / 500 batch step: 480\n",
            "w1: [25.65961418] w2: [-23.60168774] bias: [16.14178631] loss: 30.535353100880123\n",
            "Epoch: 361 / 500 batch step: 0\n",
            "w1: [25.65324384] w2: [-23.60267395] bias: [16.12847424] loss: 30.53963777493338\n",
            "Epoch: 361 / 500 batch step: 30\n",
            "w1: [25.64634943] w2: [-23.60280897] bias: [16.11470694] loss: 30.544653847955566\n",
            "Epoch: 361 / 500 batch step: 60\n",
            "w1: [25.62456675] w2: [-23.609958] bias: [16.07315922] loss: 30.564485295207607\n",
            "Epoch: 361 / 500 batch step: 90\n",
            "w1: [25.61810115] w2: [-23.61394962] bias: [16.05791037] loss: 30.57307098603413\n",
            "Epoch: 361 / 500 batch step: 120\n",
            "w1: [25.62789158] w2: [-23.58321996] bias: [16.0942786] loss: 30.552973264124443\n",
            "Epoch: 361 / 500 batch step: 150\n",
            "w1: [25.66246541] w2: [-23.58192935] bias: [16.13814637] loss: 30.53455238114226\n",
            "Epoch: 361 / 500 batch step: 180\n",
            "w1: [25.7304674] w2: [-23.56487699] bias: [16.24110061] loss: 30.522133297030372\n",
            "Epoch: 361 / 500 batch step: 210\n",
            "w1: [25.76772216] w2: [-23.54447489] bias: [16.30067542] loss: 30.53442556044345\n",
            "Epoch: 361 / 500 batch step: 240\n",
            "w1: [25.80702817] w2: [-23.5385506] bias: [16.34281887] loss: 30.553108672378716\n",
            "Epoch: 361 / 500 batch step: 270\n",
            "w1: [25.82357675] w2: [-23.53867841] bias: [16.36005068] loss: 30.562913504655672\n",
            "Epoch: 361 / 500 batch step: 300\n",
            "w1: [25.80378798] w2: [-23.54498454] bias: [16.32085405] loss: 30.544418595945324\n",
            "Epoch: 361 / 500 batch step: 330\n",
            "w1: [25.76753582] w2: [-23.55768898] bias: [16.24931994] loss: 30.52426461496796\n",
            "Epoch: 361 / 500 batch step: 360\n",
            "w1: [25.77897865] w2: [-23.52820012] bias: [16.33872047] loss: 30.548272118640796\n",
            "Epoch: 361 / 500 batch step: 390\n",
            "w1: [25.75337887] w2: [-23.53988921] bias: [16.30466026] loss: 30.534264692525504\n",
            "Epoch: 361 / 500 batch step: 420\n",
            "w1: [25.70423406] w2: [-23.58300702] bias: [16.21016807] loss: 30.52175683289353\n",
            "Epoch: 361 / 500 batch step: 450\n",
            "w1: [25.67902603] w2: [-23.60051948] bias: [16.16726861] loss: 30.52802184540686\n",
            "Epoch: 361 / 500 batch step: 480\n",
            "w1: [25.66189532] w2: [-23.60219219] bias: [16.14074999] loss: 30.535297294630027\n",
            "Epoch: 362 / 500 batch step: 0\n",
            "w1: [25.65552528] w2: [-23.60317729] bias: [16.12743937] loss: 30.539580869738387\n",
            "Epoch: 362 / 500 batch step: 30\n",
            "w1: [25.64863102] w2: [-23.60331115] bias: [16.11367318] loss: 30.544595684409316\n",
            "Epoch: 362 / 500 batch step: 60\n",
            "w1: [25.62684747] w2: [-23.61046021] bias: [16.07212433] loss: 30.564425841841036\n",
            "Epoch: 362 / 500 batch step: 90\n",
            "w1: [25.62038059] w2: [-23.61445166] bias: [16.05687417] loss: 30.573012078044222\n",
            "Epoch: 362 / 500 batch step: 120\n",
            "w1: [25.63017322] w2: [-23.58371817] bias: [16.09324842] loss: 30.552909166152617\n",
            "Epoch: 362 / 500 batch step: 150\n",
            "w1: [25.66474512] w2: [-23.5824271] bias: [16.13711468] loss: 30.53449341238798\n",
            "Epoch: 362 / 500 batch step: 180\n",
            "w1: [25.73274219] w2: [-23.5653749] bias: [16.24006262] loss: 30.52208092065199\n",
            "Epoch: 362 / 500 batch step: 210\n",
            "w1: [25.76999243] w2: [-23.54497252] bias: [16.29963257] loss: 30.53437280250521\n",
            "Epoch: 362 / 500 batch step: 240\n",
            "w1: [25.80929359] w2: [-23.53904879] bias: [16.34177031] loss: 30.55305508748434\n",
            "Epoch: 362 / 500 batch step: 270\n",
            "w1: [25.82583851] w2: [-23.53917694] bias: [16.35899699] loss: 30.56285779045964\n",
            "Epoch: 362 / 500 batch step: 300\n",
            "w1: [25.80604886] w2: [-23.54548291] bias: [16.31979956] loss: 30.544363713111473\n",
            "Epoch: 362 / 500 batch step: 330\n",
            "w1: [25.76979621] w2: [-23.55818722] bias: [16.24826504] loss: 30.524212216293726\n",
            "Epoch: 362 / 500 batch step: 360\n",
            "w1: [25.78123956] w2: [-23.52869344] bias: [16.33767234] loss: 30.548215109223964\n",
            "Epoch: 362 / 500 batch step: 390\n",
            "w1: [25.75564203] w2: [-23.5403778] bias: [16.30361927] loss: 30.534210463322864\n",
            "Epoch: 362 / 500 batch step: 420\n",
            "w1: [25.70649848] w2: [-23.58349402] bias: [16.2091299] loss: 30.521704365688887\n",
            "Epoch: 362 / 500 batch step: 450\n",
            "w1: [25.68129083] w2: [-23.60100574] bias: [16.16623182] loss: 30.527968974449166\n",
            "Epoch: 362 / 500 batch step: 480\n",
            "w1: [25.6641608] w2: [-23.60267688] bias: [16.13971572] loss: 30.53524226887421\n",
            "Epoch: 363 / 500 batch step: 0\n",
            "w1: [25.65779108] w2: [-23.60366089] bias: [16.12640653] loss: 30.539524760573446\n",
            "Epoch: 363 / 500 batch step: 30\n",
            "w1: [25.65089696] w2: [-23.60379362] bias: [16.11264146] loss: 30.544538329685537\n",
            "Epoch: 363 / 500 batch step: 60\n",
            "w1: [25.62911257] w2: [-23.6109427] bias: [16.07109152] loss: 30.564367203410455\n",
            "Epoch: 363 / 500 batch step: 90\n",
            "w1: [25.62264443] w2: [-23.61493398] bias: [16.05584007] loss: 30.572953974057853\n",
            "Epoch: 363 / 500 batch step: 120\n",
            "w1: [25.63243921] w2: [-23.58419673] bias: [16.09222024] loss: 30.55284596525768\n",
            "Epoch: 363 / 500 batch step: 150\n",
            "w1: [25.66700924] w2: [-23.5829052] bias: [16.13608504] loss: 30.534435257512165\n",
            "Epoch: 363 / 500 batch step: 180\n",
            "w1: [25.73500144] w2: [-23.56585316] bias: [16.23902677] loss: 30.52202926561452\n",
            "Epoch: 363 / 500 batch step: 210\n",
            "w1: [25.77224723] w2: [-23.54545052] bias: [16.29859192] loss: 30.53432077183772\n",
            "Epoch: 363 / 500 batch step: 240\n",
            "w1: [25.81154359] w2: [-23.53952733] bias: [16.34072402] loss: 30.5530022379763\n",
            "Epoch: 363 / 500 batch step: 270\n",
            "w1: [25.82808489] w2: [-23.5396558] bias: [16.35794566] loss: 30.562802848402317\n",
            "Epoch: 363 / 500 batch step: 300\n",
            "w1: [25.8082944] w2: [-23.54596161] bias: [16.31874746] loss: 30.544309600996105\n",
            "Epoch: 363 / 500 batch step: 330\n",
            "w1: [25.77204128] w2: [-23.55866578] bias: [16.24721257] loss: 30.52416055242823\n",
            "Epoch: 363 / 500 batch step: 360\n",
            "w1: [25.78348514] w2: [-23.52916717] bias: [16.33662653] loss: 30.548158908815722\n",
            "Epoch: 363 / 500 batch step: 390\n",
            "w1: [25.7578898] w2: [-23.54084689] bias: [16.30258047] loss: 30.53415698098524\n",
            "Epoch: 363 / 500 batch step: 420\n",
            "w1: [25.70874748] w2: [-23.58396158] bias: [16.20809384] loss: 30.521652612867914\n",
            "Epoch: 363 / 500 batch step: 450\n",
            "w1: [25.68354019] w2: [-23.60147257] bias: [16.16519709] loss: 30.527916832318564\n",
            "Epoch: 363 / 500 batch step: 480\n",
            "w1: [25.66641084] w2: [-23.60314217] bias: [16.13868348] loss: 30.535188005363608\n",
            "Epoch: 364 / 500 batch step: 0\n",
            "w1: [25.66004142] w2: [-23.60412511] bias: [16.12537572] loss: 30.539469428949626\n",
            "Epoch: 364 / 500 batch step: 30\n",
            "w1: [25.65314746] w2: [-23.60425671] bias: [16.11161177] loss: 30.54448176511514\n",
            "Epoch: 364 / 500 batch step: 60\n",
            "w1: [25.63136226] w2: [-23.6114058] bias: [16.07006079] loss: 30.564309361189895\n",
            "Epoch: 364 / 500 batch step: 90\n",
            "w1: [25.62489287] w2: [-23.61539692] bias: [16.05480809] loss: 30.57289665553775\n",
            "Epoch: 364 / 500 batch step: 120\n",
            "w1: [25.63468977] w2: [-23.58465599] bias: [16.09119406] loss: 30.552783641388906\n",
            "Epoch: 364 / 500 batch step: 150\n",
            "w1: [25.66925795] w2: [-23.58336399] bias: [16.13505744] loss: 30.534377897822296\n",
            "Epoch: 364 / 500 batch step: 180\n",
            "w1: [25.73724536] w2: [-23.5663121] bias: [16.23799305] loss: 30.52197831471104\n",
            "Epoch: 364 / 500 batch step: 210\n",
            "w1: [25.77448674] w2: [-23.5459092] bias: [16.29755345] loss: 30.53426945115724\n",
            "Epoch: 364 / 500 batch step: 240\n",
            "w1: [25.81377837] w2: [-23.53998656] bias: [16.33968] loss: 30.552950106460486\n",
            "Epoch: 364 / 500 batch step: 270\n",
            "w1: [25.83031612] w2: [-23.54011534] bias: [16.35689668] loss: 30.562748660492996\n",
            "Epoch: 364 / 500 batch step: 300\n",
            "w1: [25.8105248] w2: [-23.54642099] bias: [16.31769775] loss: 30.544256241603517\n",
            "Epoch: 364 / 500 batch step: 330\n",
            "w1: [25.77427124] w2: [-23.55912502] bias: [16.24616252] loss: 30.524109605943593\n",
            "Epoch: 364 / 500 batch step: 360\n",
            "w1: [25.78571558] w2: [-23.52962166] bias: [16.33558305] loss: 30.54810349884133\n",
            "Epoch: 364 / 500 batch step: 390\n",
            "w1: [25.76012239] w2: [-23.54129683] bias: [16.30154385] loss: 30.53410422801628\n",
            "Epoch: 364 / 500 batch step: 420\n",
            "w1: [25.71098124] w2: [-23.58441003] bias: [16.20705988] loss: 30.521601557475385\n",
            "Epoch: 364 / 500 batch step: 450\n",
            "w1: [25.6857743] w2: [-23.60192032] bias: [16.16416442] loss: 30.527865401811116\n",
            "Epoch: 364 / 500 batch step: 480\n",
            "w1: [25.66864562] w2: [-23.6035884] bias: [16.13765329] loss: 30.53513448636379\n",
            "Epoch: 365 / 500 batch step: 0\n",
            "w1: [25.66227651] w2: [-23.60457028] bias: [16.12434695] loss: 30.539414856896308\n",
            "Epoch: 365 / 500 batch step: 30\n",
            "w1: [25.65538273] w2: [-23.60470077] bias: [16.11058412] loss: 30.544425972549842\n",
            "Epoch: 365 / 500 batch step: 60\n",
            "w1: [25.63359673] w2: [-23.61184987] bias: [16.06903215] loss: 30.56425229697474\n",
            "Epoch: 365 / 500 batch step: 90\n",
            "w1: [25.62712612] w2: [-23.61584082] bias: [16.0537782] loss: 30.57284010446468\n",
            "Epoch: 365 / 500 batch step: 120\n",
            "w1: [25.6369251] w2: [-23.58509626] bias: [16.09016988] loss: 30.55272217503773\n",
            "Epoch: 365 / 500 batch step: 150\n",
            "w1: [25.67149146] w2: [-23.58380381] bias: [16.13403187] loss: 30.534321315145622\n",
            "Epoch: 365 / 500 batch step: 180\n",
            "w1: [25.73947414] w2: [-23.56675207] bias: [16.23696147] loss: 30.521928051229654\n",
            "Epoch: 365 / 500 batch step: 210\n",
            "w1: [25.77671117] w2: [-23.54634892] bias: [16.29651716] loss: 30.534218823675648\n",
            "Epoch: 365 / 500 batch step: 240\n",
            "w1: [25.81599813] w2: [-23.54042681] bias: [16.33863823] loss: 30.552898676039884\n",
            "Epoch: 365 / 500 batch step: 270\n",
            "w1: [25.83253238] w2: [-23.5405559] bias: [16.35585005] loss: 30.56269520924765\n",
            "Epoch: 365 / 500 batch step: 300\n",
            "w1: [25.81274026] w2: [-23.54686139] bias: [16.31665041] loss: 30.544203617444907\n",
            "Epoch: 365 / 500 batch step: 330\n",
            "w1: [25.77648627] w2: [-23.55956528] bias: [16.24511489] loss: 30.52405935990978\n",
            "Epoch: 365 / 500 batch step: 360\n",
            "w1: [25.78793107] w2: [-23.53005725] bias: [16.33454189] loss: 30.54804886124065\n",
            "Epoch: 365 / 500 batch step: 390\n",
            "w1: [25.76233998] w2: [-23.54172796] bias: [16.30050941] loss: 30.534052187415398\n",
            "Epoch: 365 / 500 batch step: 420\n",
            "w1: [25.71319998] w2: [-23.58483971] bias: [16.20602803] loss: 30.52155118304287\n",
            "Epoch: 365 / 500 batch step: 450\n",
            "w1: [25.68799336] w2: [-23.60234932] bias: [16.16313382] loss: 30.52781466621362\n",
            "Epoch: 365 / 500 batch step: 480\n",
            "w1: [25.67086536] w2: [-23.60401589] bias: [16.13662515] loss: 30.535081694639445\n",
            "Epoch: 366 / 500 batch step: 0\n",
            "w1: [25.66449656] w2: [-23.60499673] bias: [16.12332021] loss: 30.53936102694555\n",
            "Epoch: 366 / 500 batch step: 30\n",
            "w1: [25.65760295] w2: [-23.60512612] bias: [16.10955851] loss: 30.54437093434656\n",
            "Epoch: 366 / 500 batch step: 60\n",
            "w1: [25.63581619] w2: [-23.61227524] bias: [16.06800559] loss: 30.564195993066082\n",
            "Epoch: 366 / 500 batch step: 90\n",
            "w1: [25.62934437] w2: [-23.61626602] bias: [16.05275042] loss: 30.57278430332194\n",
            "Epoch: 366 / 500 batch step: 120\n",
            "w1: [25.63914539] w2: [-23.5855179] bias: [16.0891477] loss: 30.552661547221835\n",
            "Epoch: 366 / 500 batch step: 150\n",
            "w1: [25.67370996] w2: [-23.58422499] bias: [16.13300836] loss: 30.534265491813535\n",
            "Epoch: 366 / 500 batch step: 180\n",
            "w1: [25.74168799] w2: [-23.5671734] bias: [16.23593201] loss: 30.521878458938403\n",
            "Epoch: 366 / 500 batch step: 210\n",
            "w1: [25.77892072] w2: [-23.54677] bias: [16.29548306] loss: 30.534168873085413\n",
            "Epoch: 366 / 500 batch step: 240\n",
            "w1: [25.81820306] w2: [-23.54084842] bias: [16.33759873] loss: 30.552847930299528\n",
            "Epoch: 366 / 500 batch step: 270\n",
            "w1: [25.83473386] w2: [-23.54097782] bias: [16.35480576] loss: 30.562642477673702\n",
            "Epoch: 366 / 500 batch step: 300\n",
            "w1: [25.81494096] w2: [-23.54728314] bias: [16.31560546] loss: 30.544151711523092\n",
            "Epoch: 366 / 500 batch step: 330\n",
            "w1: [25.77868658] w2: [-23.55998688] bias: [16.24406966] loss: 30.524009797879454\n",
            "Epoch: 366 / 500 batch step: 360\n",
            "w1: [25.79013182] w2: [-23.53047426] bias: [16.33350305] loss: 30.547994978452866\n",
            "Epoch: 366 / 500 batch step: 390\n",
            "w1: [25.76454278] w2: [-23.5421406] bias: [16.29947716] loss: 30.534000842662884\n",
            "Epoch: 366 / 500 batch step: 420\n",
            "w1: [25.71540389] w2: [-23.58525094] bias: [16.20499829] loss: 30.52150147357385\n",
            "Epoch: 366 / 500 batch step: 450\n",
            "w1: [25.69019758] w2: [-23.6027599] bias: [16.16210528] loss: 30.52776460928876\n",
            "Epoch: 366 / 500 batch step: 480\n",
            "w1: [25.67307024] w2: [-23.60442498] bias: [16.13559905] loss: 30.535029613439317\n",
            "Epoch: 367 / 500 batch step: 0\n",
            "w1: [25.66670175] w2: [-23.6054048] bias: [16.12229551] loss: 30.539307922117015\n",
            "Epoch: 367 / 500 batch step: 30\n",
            "w1: [25.65980832] w2: [-23.60553311] bias: [16.10853494] loss: 30.54431663335229\n",
            "Epoch: 367 / 500 batch step: 60\n",
            "w1: [25.63802082] w2: [-23.61268222] bias: [16.06698111] loss: 30.56414043225569\n",
            "Epoch: 367 / 500 batch step: 90\n",
            "w1: [25.63154782] w2: [-23.61667284] bias: [16.05172475] loss: 30.572729235080214\n",
            "Epoch: 367 / 500 batch step: 120\n",
            "w1: [25.64135084] w2: [-23.58592123] bias: [16.08812753] loss: 30.552601739469747\n",
            "Epoch: 367 / 500 batch step: 150\n",
            "w1: [25.67591366] w2: [-23.58462785] bias: [16.13198688] loss: 30.534210410646647\n",
            "Epoch: 367 / 500 batch step: 180\n",
            "w1: [25.74388709] w2: [-23.56757641] bias: [16.23490468] loss: 30.521829522070583\n",
            "Epoch: 367 / 500 batch step: 210\n",
            "w1: [25.78111557] w2: [-23.54717278] bias: [16.29445115] loss: 30.534119583544943\n",
            "Epoch: 367 / 500 batch step: 240\n",
            "w1: [25.82039334] w2: [-23.54125171] bias: [16.33656147] loss: 30.5527978532918\n",
            "Epoch: 367 / 500 batch step: 270\n",
            "w1: [25.83692076] w2: [-23.54138141] bias: [16.3537638] loss: 30.56259044925523\n",
            "Epoch: 367 / 500 batch step: 300\n",
            "w1: [25.81712711] w2: [-23.54768656] bias: [16.31456287] loss: 30.544100507317673\n",
            "Epoch: 367 / 500 batch step: 330\n",
            "w1: [25.78087234] w2: [-23.56039015] bias: [16.24302684] loss: 30.523960903873324\n",
            "Epoch: 367 / 500 batch step: 360\n",
            "w1: [25.79231801] w2: [-23.53087302] bias: [16.33246651] loss: 30.547941833401506\n",
            "Epoch: 367 / 500 batch step: 390\n",
            "w1: [25.76673097] w2: [-23.54253507] bias: [16.29844709] loss: 30.533950177705268\n",
            "Epoch: 367 / 500 batch step: 420\n",
            "w1: [25.71759315] w2: [-23.58564406] bias: [16.20397065] loss: 30.52145241352936\n",
            "Epoch: 367 / 500 batch step: 450\n",
            "w1: [25.69238713] w2: [-23.60315237] bias: [16.16107881] loss: 30.52771521526061\n",
            "Epoch: 367 / 500 batch step: 480\n",
            "w1: [25.67526046] w2: [-23.60481598] bias: [16.13457499] loss: 30.53497822648168\n",
            "Epoch: 368 / 500 batch step: 0\n",
            "w1: [25.66889227] w2: [-23.60579479] bias: [16.12127283] loss: 30.539255525903396\n",
            "Epoch: 368 / 500 batch step: 30\n",
            "w1: [25.66199903] w2: [-23.60592204] bias: [16.10751341] loss: 30.54426305288947\n",
            "Epoch: 368 / 500 batch step: 60\n",
            "w1: [25.64021083] w2: [-23.61307115] bias: [16.06595871] loss: 30.56408559781128\n",
            "Epoch: 368 / 500 batch step: 90\n",
            "w1: [25.63373665] w2: [-23.61706161] bias: [16.05070117] loss: 30.572674883183097\n",
            "Epoch: 368 / 500 batch step: 120\n",
            "w1: [25.64354164] w2: [-23.58630657] bias: [16.08710936] loss: 30.552542733805858\n",
            "Epoch: 368 / 500 batch step: 150\n",
            "w1: [25.67810274] w2: [-23.58501273] bias: [16.13096744] loss: 30.534156054940084\n",
            "Epoch: 368 / 500 batch step: 180\n",
            "w1: [25.74607164] w2: [-23.56796143] bias: [16.23387947] loss: 30.521781225310633\n",
            "Epoch: 368 / 500 batch step: 210\n",
            "w1: [25.78329591] w2: [-23.54755756] bias: [16.29342141] loss: 30.53407093966438\n",
            "Epoch: 368 / 500 batch step: 240\n",
            "w1: [25.82256918] w2: [-23.54163701] bias: [16.33552647] loss: 30.552748429522264\n",
            "Epoch: 368 / 500 batch step: 270\n",
            "w1: [25.83909327] w2: [-23.541767] bias: [16.35272418] loss: 30.562539107938594\n",
            "Epoch: 368 / 500 batch step: 300\n",
            "w1: [25.81929888] w2: [-23.54807198] bias: [16.31352265] loss: 30.544049988770745\n",
            "Epoch: 368 / 500 batch step: 330\n",
            "w1: [25.78304375] w2: [-23.56077542] bias: [16.24198642] loss: 30.52391266236597\n",
            "Epoch: 368 / 500 batch step: 360\n",
            "w1: [25.79448983] w2: [-23.53125385] bias: [16.33143228] loss: 30.547889409480113\n",
            "Epoch: 368 / 500 batch step: 390\n",
            "w1: [25.76890474] w2: [-23.54291171] bias: [16.29741919] loss: 30.533900176941295\n",
            "Epoch: 368 / 500 batch step: 420\n",
            "w1: [25.71976796] w2: [-23.58601938] bias: [16.20294511] loss: 30.521403987814043\n",
            "Epoch: 368 / 500 batch step: 450\n",
            "w1: [25.69456221] w2: [-23.60352707] bias: [16.1600544] loss: 30.52766646880069\n",
            "Epoch: 368 / 500 batch step: 480\n",
            "w1: [25.6774362] w2: [-23.60518922] bias: [16.13355298] loss: 30.53492751794018\n",
            "Epoch: 369 / 500 batch step: 0\n",
            "w1: [25.67106832] w2: [-23.60616704] bias: [16.1202522] loss: 30.539203822256198\n",
            "Epoch: 369 / 500 batch step: 30\n",
            "w1: [25.66417528] w2: [-23.60629324] bias: [16.10649391] loss: 30.544210176741775\n",
            "Epoch: 369 / 500 batch step: 60\n",
            "w1: [25.64238639] w2: [-23.61344234] bias: [16.06493838] loss: 30.564031473462393\n",
            "Epoch: 369 / 500 batch step: 90\n",
            "w1: [25.63591106] w2: [-23.61743264] bias: [16.0496797] loss: 30.5726212315329\n",
            "Epoch: 369 / 500 batch step: 120\n",
            "w1: [25.64571797] w2: [-23.58667423] bias: [16.08609319] loss: 30.55248451273595\n",
            "Epoch: 369 / 500 batch step: 150\n",
            "w1: [25.68027739] w2: [-23.58537994] bias: [16.12995005] loss: 30.534102408449424\n",
            "Epoch: 369 / 500 batch step: 180\n",
            "w1: [25.74824182] w2: [-23.56832877] bias: [16.23285639] loss: 30.521733553780333\n",
            "Epoch: 369 / 500 batch step: 210\n",
            "w1: [25.78546194] w2: [-23.54792468] bias: [16.29239385] loss: 30.5340229264919\n",
            "Epoch: 369 / 500 batch step: 240\n",
            "w1: [25.82473076] w2: [-23.54200464] bias: [16.33449372] loss: 30.55269964393593\n",
            "Epoch: 369 / 500 batch step: 270\n",
            "w1: [25.84125157] w2: [-23.5421349] bias: [16.35168688] loss: 30.562488438118596\n",
            "Epoch: 369 / 500 batch step: 300\n",
            "w1: [25.82145646] w2: [-23.54843972] bias: [16.31248479] loss: 30.544000140272956\n",
            "Epoch: 369 / 500 batch step: 330\n",
            "w1: [25.78520099] w2: [-23.561143] bias: [16.24094839] loss: 30.523865058272037\n",
            "Epoch: 369 / 500 batch step: 360\n",
            "w1: [25.79664746] w2: [-23.53161707] bias: [16.33040035] loss: 30.54783769053823\n",
            "Epoch: 369 / 500 batch step: 390\n",
            "w1: [25.77106427] w2: [-23.54327081] bias: [16.29639346] loss: 30.533850825208244\n",
            "Epoch: 369 / 500 batch step: 420\n",
            "w1: [25.72192849] w2: [-23.58637721] bias: [16.20192167] loss: 30.521356181762645\n",
            "Epoch: 369 / 500 batch step: 450\n",
            "w1: [25.696723] w2: [-23.6038843] bias: [16.15903205] loss: 30.527618355014344\n",
            "Epoch: 369 / 500 batch step: 480\n",
            "w1: [25.67959766] w2: [-23.60554501] bias: [16.13253301] loss: 30.53487747243019\n",
            "Epoch: 370 / 500 batch step: 0\n",
            "w1: [25.67323009] w2: [-23.60652186] bias: [16.11923359] loss: 30.539152795572043\n",
            "Epoch: 370 / 500 batch step: 30\n",
            "w1: [25.66633725] w2: [-23.60664702] bias: [16.10547646] loss: 30.544157989140384\n",
            "Epoch: 370 / 500 batch step: 60\n",
            "w1: [25.64454769] w2: [-23.6137961] bias: [16.06392014] loss: 30.563978043386584\n",
            "Epoch: 370 / 500 batch step: 90\n",
            "w1: [25.63807123] w2: [-23.61778624] bias: [16.04866033] loss: 30.57256826447693\n",
            "Epoch: 370 / 500 batch step: 120\n",
            "w1: [25.64788003] w2: [-23.58702452] bias: [16.08507903] loss: 30.552427059233114\n",
            "Epoch: 370 / 500 batch step: 150\n",
            "w1: [25.68243779] w2: [-23.58572978] bias: [16.1289347] loss: 30.534049455376945\n",
            "Epoch: 370 / 500 batch step: 180\n",
            "w1: [25.75039782] w2: [-23.56867875] bias: [16.23183544] loss: 30.52168649302553\n",
            "Epoch: 370 / 500 batch step: 210\n",
            "w1: [25.78761383] w2: [-23.54827444] bias: [16.29136847] loss: 30.533975529500424\n",
            "Epoch: 370 / 500 batch step: 240\n",
            "w1: [25.82687825] w2: [-23.54235489] bias: [16.33346321] loss: 30.552651481903897\n",
            "Epoch: 370 / 500 batch step: 270\n",
            "w1: [25.84339584] w2: [-23.54248544] bias: [16.35065191] loss: 30.56243842462498\n",
            "Epoch: 370 / 500 batch step: 300\n",
            "w1: [25.82360004] w2: [-23.54879008] bias: [16.31144928] loss: 30.54395094665008\n",
            "Epoch: 370 / 500 batch step: 330\n",
            "w1: [25.78734424] w2: [-23.5614932] bias: [16.23991275] loss: 30.523818076932937\n",
            "Epoch: 370 / 500 batch step: 360\n",
            "w1: [25.79879109] w2: [-23.53196298] bias: [16.32937071] loss: 30.5477866608679\n",
            "Epoch: 370 / 500 batch step: 390\n",
            "w1: [25.77320976] w2: [-23.5436127] bias: [16.29536991] loss: 30.533802107768768\n",
            "Epoch: 370 / 500 batch step: 420\n",
            "w1: [25.72407495] w2: [-23.58671785] bias: [16.20090034] loss: 30.521308981127\n",
            "Epoch: 370 / 500 batch step: 450\n",
            "w1: [25.69886969] w2: [-23.60422436] bias: [16.15801177] loss: 30.52757085942771\n",
            "Epoch: 370 / 500 batch step: 480\n",
            "w1: [25.68174501] w2: [-23.60588366] bias: [16.13151508] loss: 30.53482807499555\n",
            "Epoch: 371 / 500 batch step: 0\n",
            "w1: [25.67537774] w2: [-23.60685954] bias: [16.11821702] loss: 30.539102430679346\n",
            "Epoch: 371 / 500 batch step: 30\n",
            "w1: [25.66848512] w2: [-23.60698369] bias: [16.10446104] loss: 30.544106474750624\n",
            "Epoch: 371 / 500 batch step: 60\n",
            "w1: [25.64669492] w2: [-23.61413274] bias: [16.06290398] loss: 30.563925292196107\n",
            "Epoch: 371 / 500 batch step: 90\n",
            "w1: [25.64021734] w2: [-23.61812272] bias: [16.04764305] loss: 30.572515966794274\n",
            "Epoch: 371 / 500 batch step: 120\n",
            "w1: [25.650028] w2: [-23.58735776] bias: [16.08406688] loss: 30.552370356724136\n",
            "Epoch: 371 / 500 batch step: 150\n",
            "w1: [25.68458413] w2: [-23.58606256] bias: [16.12792139] loss: 30.53399718035837\n",
            "Epoch: 371 / 500 batch step: 180\n",
            "w1: [25.75253981] w2: [-23.56901166] bias: [16.2308166] loss: 30.521640029003226\n",
            "Epoch: 371 / 500 batch step: 210\n",
            "w1: [25.78975177] w2: [-23.54860714] bias: [16.29034526] loss: 30.533928734574673\n",
            "Epoch: 371 / 500 batch step: 240\n",
            "w1: [25.82901184] w2: [-23.54268809] bias: [16.33243494] loss: 30.552603929210516\n",
            "Epoch: 371 / 500 batch step: 270\n",
            "w1: [25.84552625] w2: [-23.5428189] bias: [16.34961926] loss: 30.562389052709392\n",
            "Epoch: 371 / 500 batch step: 300\n",
            "w1: [25.82572978] w2: [-23.54912337] bias: [16.31041612] loss: 30.543902393149963\n",
            "Epoch: 371 / 500 batch step: 330\n",
            "w1: [25.78947368] w2: [-23.56182633] bias: [16.23887949] loss: 30.523771704103936\n",
            "Epoch: 371 / 500 batch step: 360\n",
            "w1: [25.80092089] w2: [-23.53229189] bias: [16.32834337] loss: 30.547736305190497\n",
            "Epoch: 371 / 500 batch step: 390\n",
            "w1: [25.77534137] w2: [-23.54393766] bias: [16.29434853] loss: 30.53375401029804\n",
            "Epoch: 371 / 500 batch step: 420\n",
            "w1: [25.72620749] w2: [-23.58704163] bias: [16.1998811] loss: 30.521262372063255\n",
            "Epoch: 371 / 500 batch step: 450\n",
            "w1: [25.70100246] w2: [-23.60454757] bias: [16.15699355] loss: 30.52752396797488\n",
            "Epoch: 371 / 500 batch step: 480\n",
            "w1: [25.68387843] w2: [-23.60620547] bias: [16.1304992] loss: 30.534779311095676\n",
            "Epoch: 372 / 500 batch step: 0\n",
            "w1: [25.67751148] w2: [-23.6071804] bias: [16.11720249] loss: 30.53905271282545\n",
            "Epoch: 372 / 500 batch step: 30\n",
            "w1: [25.67061908] w2: [-23.60730354] bias: [16.10344766] loss: 30.544055618659048\n",
            "Epoch: 372 / 500 batch step: 60\n",
            "w1: [25.64882826] w2: [-23.61445257] bias: [16.06188989] loss: 30.56387320492502\n",
            "Epoch: 372 / 500 batch step: 90\n",
            "w1: [25.64234957] w2: [-23.61844239] bias: [16.04662787] loss: 30.57246432368289\n",
            "Epoch: 372 / 500 batch step: 120\n",
            "w1: [25.65216206] w2: [-23.58767424] bias: [16.08305672] loss: 30.552314389076276\n",
            "Epoch: 372 / 500 batch step: 150\n",
            "w1: [25.68671659] w2: [-23.58637859] bias: [16.12691011] loss: 30.53394556844999\n",
            "Epoch: 372 / 500 batch step: 180\n",
            "w1: [25.75466799] w2: [-23.56932782] bias: [16.22979989] loss: 30.52159414806912\n",
            "Epoch: 372 / 500 batch step: 210\n",
            "w1: [25.79187593] w2: [-23.54892309] bias: [16.28932422] loss: 30.533882527998745\n",
            "Epoch: 372 / 500 batch step: 240\n",
            "w1: [25.83113171] w2: [-23.54300452] bias: [16.33140891] loss: 30.55255697204081\n",
            "Epoch: 372 / 500 batch step: 270\n",
            "w1: [25.847643] w2: [-23.54313561] bias: [16.34858892] loss: 30.562340308032773\n",
            "Epoch: 372 / 500 batch step: 300\n",
            "w1: [25.82784588] w2: [-23.54943989] bias: [16.30938531] loss: 30.54385446542984\n",
            "Epoch: 372 / 500 batch step: 330\n",
            "w1: [25.79158949] w2: [-23.56214269] bias: [16.2378486] loss: 30.523725925941598\n",
            "Epoch: 372 / 500 batch step: 360\n",
            "w1: [25.80303704] w2: [-23.53260411] bias: [16.32731831] loss: 30.54768660864405\n",
            "Epoch: 372 / 500 batch step: 390\n",
            "w1: [25.77745929] w2: [-23.54424601] bias: [16.29332932] loss: 30.533706518871327\n",
            "Epoch: 372 / 500 batch step: 420\n",
            "w1: [25.72832631] w2: [-23.58734882] bias: [16.19886396] loss: 30.521216341119718\n",
            "Epoch: 372 / 500 batch step: 450\n",
            "w1: [25.70312148] w2: [-23.60485422] bias: [16.15597739] loss: 30.527477666985657\n",
            "Epoch: 372 / 500 batch step: 480\n",
            "w1: [25.68599811] w2: [-23.60651073] bias: [16.12948537] loss: 30.5347311665932\n",
            "Epoch: 373 / 500 batch step: 0\n",
            "w1: [25.67963146] w2: [-23.60748473] bias: [16.11618999] loss: 30.539003627664087\n",
            "Epoch: 373 / 500 batch step: 30\n",
            "w1: [25.67273929] w2: [-23.60760688] bias: [16.10243631] loss: 30.544005406360956\n",
            "Epoch: 373 / 500 batch step: 60\n",
            "w1: [25.65094787] w2: [-23.61475588] bias: [16.06087788] loss: 30.563821767016627\n",
            "Epoch: 373 / 500 batch step: 90\n",
            "w1: [25.6444681] w2: [-23.61874554] bias: [16.04561479] loss: 30.57241332074714\n",
            "Epoch: 373 / 500 batch step: 120\n",
            "w1: [25.65428238] w2: [-23.58797426] bias: [16.08204858] loss: 30.552259140584503\n",
            "Epoch: 373 / 500 batch step: 150\n",
            "w1: [25.68883534] w2: [-23.58667816] bias: [16.12590088] loss: 30.53389460511619\n",
            "Epoch: 373 / 500 batch step: 180\n",
            "w1: [25.75678251] w2: [-23.56962752] bias: [16.2287853] loss: 30.52154883696545\n",
            "Epoch: 373 / 500 batch step: 210\n",
            "w1: [25.79398649] w2: [-23.54922258] bias: [16.28830535] loss: 30.533836896443976\n",
            "Epoch: 373 / 500 batch step: 240\n",
            "w1: [25.83323802] w2: [-23.54330449] bias: [16.33038512] loss: 30.55251059696844\n",
            "Epoch: 373 / 500 batch step: 270\n",
            "w1: [25.84974624] w2: [-23.54343584] bias: [16.34756088] loss: 30.562292176653056\n",
            "Epoch: 373 / 500 batch step: 300\n",
            "w1: [25.82994849] w2: [-23.54973994] bias: [16.30835684] loss: 30.543807149544126\n",
            "Epoch: 373 / 500 batch step: 330\n",
            "w1: [25.79369183] w2: [-23.56244257] bias: [16.23682008] loss: 30.523680728991707\n",
            "Epoch: 373 / 500 batch step: 360\n",
            "w1: [25.80513972] w2: [-23.53289992] bias: [16.32629554] loss: 30.547637556770876\n",
            "Epoch: 373 / 500 batch step: 390\n",
            "w1: [25.77956369] w2: [-23.54453804] bias: [16.29231227] loss: 30.533659619952008\n",
            "Epoch: 373 / 500 batch step: 420\n",
            "w1: [25.73043157] w2: [-23.58763973] bias: [16.19784892] loss: 30.521170875224893\n",
            "Epoch: 373 / 500 batch step: 450\n",
            "w1: [25.70522693] w2: [-23.6051446] bias: [16.15496329] loss: 30.527431943173575\n",
            "Epoch: 373 / 500 batch step: 480\n",
            "w1: [25.68810421] w2: [-23.60679974] bias: [16.12847357] loss: 30.534683627741853\n",
            "Epoch: 374 / 500 batch step: 0\n",
            "w1: [25.68173787] w2: [-23.60777282] bias: [16.11517952] loss: 30.538955161243354\n",
            "Epoch: 374 / 500 batch step: 30\n",
            "w1: [25.67484594] w2: [-23.60789399] bias: [16.10142701] loss: 30.54395582374818\n",
            "Epoch: 374 / 500 batch step: 60\n",
            "w1: [25.65305395] w2: [-23.61504296] bias: [16.05986794] loss: 30.563770964311352\n",
            "Epoch: 374 / 500 batch step: 90\n",
            "w1: [25.6465731] w2: [-23.61903246] bias: [16.0446038] loss: 30.572362943985706\n",
            "Epoch: 374 / 500 batch step: 120\n",
            "w1: [25.65638914] w2: [-23.58825811] bias: [16.08104244] loss: 30.552204595958997\n",
            "Epoch: 374 / 500 batch step: 150\n",
            "w1: [25.69094056] w2: [-23.58696156] bias: [16.12489369] loss: 30.53384427621735\n",
            "Epoch: 374 / 500 batch step: 180\n",
            "w1: [25.75888356] w2: [-23.56991104] bias: [16.22777282] loss: 30.521504082809326\n",
            "Epoch: 374 / 500 batch step: 210\n",
            "w1: [25.79608362] w2: [-23.54950591] bias: [16.28728864] loss: 30.533791826957245\n",
            "Epoch: 374 / 500 batch step: 240\n",
            "w1: [25.83533096] w2: [-23.54358829] bias: [16.32936355] loss: 30.552464790943905\n",
            "Epoch: 374 / 500 batch step: 270\n",
            "w1: [25.85183616] w2: [-23.54371989] bias: [16.34653515] loss: 30.562244645013347\n",
            "Epoch: 374 / 500 batch step: 300\n",
            "w1: [25.83203779] w2: [-23.55002381] bias: [16.30733069] loss: 30.543760431932544\n",
            "Epoch: 374 / 500 batch step: 330\n",
            "w1: [25.79578088] w2: [-23.56272627] bias: [16.23579393] loss: 30.523636100177516\n",
            "Epoch: 374 / 500 batch step: 360\n",
            "w1: [25.80722908] w2: [-23.53317962] bias: [16.32527505] loss: 30.547589135505675\n",
            "Epoch: 374 / 500 batch step: 390\n",
            "w1: [25.78165474] w2: [-23.54481403] bias: [16.29129739] loss: 30.533613300379905\n",
            "Epoch: 374 / 500 batch step: 420\n",
            "w1: [25.73252345] w2: [-23.58791464] bias: [16.19683598] loss: 30.52112596167598\n",
            "Epoch: 374 / 500 batch step: 450\n",
            "w1: [25.70731898] w2: [-23.605419] bias: [16.15395126] loss: 30.527386783624316\n",
            "Epoch: 374 / 500 batch step: 480\n",
            "w1: [25.69019692] w2: [-23.60707279] bias: [16.12746382] loss: 30.534636681174774\n",
            "Epoch: 375 / 500 batch step: 0\n",
            "w1: [25.68383088] w2: [-23.60804496] bias: [16.11417108] loss: 30.53890729999386\n",
            "Epoch: 375 / 500 batch step: 30\n",
            "w1: [25.67693919] w2: [-23.60816517] bias: [16.10041974] loss: 30.543906857097422\n",
            "Epoch: 375 / 500 batch step: 60\n",
            "w1: [25.65514665] w2: [-23.61531409] bias: [16.05886008] loss: 30.563720783034995\n",
            "Epoch: 375 / 500 batch step: 90\n",
            "w1: [25.64866475] w2: [-23.61930344] bias: [16.04359491] loss: 30.57231317977991\n",
            "Epoch: 375 / 500 batch step: 120\n",
            "w1: [25.65848251] w2: [-23.58852608] bias: [16.0800383] loss: 30.552150740313166\n",
            "Epoch: 375 / 500 batch step: 150\n",
            "w1: [25.69303241] w2: [-23.58722908] bias: [16.12388854] loss: 30.53379456799814\n",
            "Epoch: 375 / 500 batch step: 180\n",
            "w1: [25.76097131] w2: [-23.57017868] bias: [16.22676246] loss: 30.52145987308133\n",
            "Epoch: 375 / 500 batch step: 210\n",
            "w1: [25.79816749] w2: [-23.54977335] bias: [16.2862741] loss: 30.5337473069496\n",
            "Epoch: 375 / 500 batch step: 240\n",
            "w1: [25.83741069] w2: [-23.54385621] bias: [16.32834421] loss: 30.552419541283225\n",
            "Epoch: 375 / 500 batch step: 270\n",
            "w1: [25.85391291] w2: [-23.54398805] bias: [16.34551173] loss: 30.562197699930408\n",
            "Epoch: 375 / 500 batch step: 300\n",
            "w1: [25.83411396] w2: [-23.55029179] bias: [16.30630688] loss: 30.543714299408588\n",
            "Epoch: 375 / 500 batch step: 330\n",
            "w1: [25.79785681] w2: [-23.56299408] bias: [16.23477013] loss: 30.52359202678833\n",
            "Epoch: 375 / 500 batch step: 360\n",
            "w1: [25.80930531] w2: [-23.5334435] bias: [16.32425683] loss: 30.54754133116391\n",
            "Epoch: 375 / 500 batch step: 390\n",
            "w1: [25.7837326] w2: [-23.54507427] bias: [16.29028466] loss: 30.533567547359983\n",
            "Epoch: 375 / 500 batch step: 420\n",
            "w1: [25.73460212] w2: [-23.58817384] bias: [16.19582513] loss: 30.52108158812773\n",
            "Epoch: 375 / 500 batch step: 450\n",
            "w1: [25.70939781] w2: [-23.6056777] bias: [16.15294128] loss: 30.527342175784515\n",
            "Epoch: 375 / 500 batch step: 480\n",
            "w1: [25.69227639] w2: [-23.60733016] bias: [16.12645611] loss: 30.534590313893194\n",
            "Epoch: 376 / 500 batch step: 0\n",
            "w1: [25.68591066] w2: [-23.60830144] bias: [16.11316468] loss: 30.538860030717448\n",
            "Epoch: 376 / 500 batch step: 30\n",
            "w1: [25.67901922] w2: [-23.60842069] bias: [16.09941451] loss: 30.543858493058735\n",
            "Epoch: 376 / 500 batch step: 60\n",
            "w1: [25.65722614] w2: [-23.61556957] bias: [16.0578543] loss: 30.563671209787287\n",
            "Epoch: 376 / 500 batch step: 90\n",
            "w1: [25.65074321] w2: [-23.61955877] bias: [16.0425881] loss: 30.57226401488231\n",
            "Epoch: 376 / 500 batch step: 120\n",
            "w1: [25.66056266] w2: [-23.58877844] bias: [16.07903617] loss: 30.552097559151953\n",
            "Epoch: 376 / 500 batch step: 150\n",
            "w1: [25.69511108] w2: [-23.58748099] bias: [16.12288543] loss: 30.53374546707614\n",
            "Epoch: 376 / 500 batch step: 180\n",
            "w1: [25.76304592] w2: [-23.57043072] bias: [16.22575421] loss: 30.521416195614545\n",
            "Epoch: 376 / 500 batch step: 210\n",
            "w1: [25.80023826] w2: [-23.5500252] bias: [16.28526172] loss: 30.53370332418528\n",
            "Epoch: 376 / 500 batch step: 240\n",
            "w1: [25.83947737] w2: [-23.54410852] bias: [16.3273271] loss: 30.552374835656874\n",
            "Epoch: 376 / 500 batch step: 270\n",
            "w1: [25.85597667] w2: [-23.54424061] bias: [16.34449059] loss: 30.562151328583504\n",
            "Epoch: 376 / 500 batch step: 300\n",
            "w1: [25.83617714] w2: [-23.55054416] bias: [16.30528539] loss: 30.543668739148394\n",
            "Epoch: 376 / 500 batch step: 330\n",
            "w1: [25.79991978] w2: [-23.56324627] bias: [16.23374869] loss: 30.52354849646851\n",
            "Epoch: 376 / 500 batch step: 360\n",
            "w1: [25.81136856] w2: [-23.53369182] bias: [16.32324088] loss: 30.547494130430614\n",
            "Epoch: 376 / 500 batch step: 390\n",
            "w1: [25.78579745] w2: [-23.54531903] bias: [16.28927409] loss: 30.5335223484514\n",
            "Epoch: 376 / 500 batch step: 420\n",
            "w1: [25.73666773] w2: [-23.5884176] bias: [16.19481638] loss: 30.521037742581605\n",
            "Epoch: 376 / 500 batch step: 450\n",
            "w1: [25.71146357] w2: [-23.60592099] bias: [16.15193336] loss: 30.5272981074509\n",
            "Epoch: 376 / 500 batch step: 480\n",
            "w1: [25.69434279] w2: [-23.60757212] bias: [16.12545044] loss: 30.534544513255486\n",
            "Epoch: 377 / 500 batch step: 0\n",
            "w1: [25.68797737] w2: [-23.60854252] bias: [16.11216031] loss: 30.538813340576155\n",
            "Epoch: 377 / 500 batch step: 30\n",
            "w1: [25.68108619] w2: [-23.60866084] bias: [16.09841131] loss: 30.543810718644615\n",
            "Epoch: 377 / 500 batch step: 60\n",
            "w1: [25.6592926] w2: [-23.61580967] bias: [16.05685058] loss: 30.5636222315309\n",
            "Epoch: 377 / 500 batch step: 90\n",
            "w1: [25.65280865] w2: [-23.61979871] bias: [16.04158339] loss: 30.572215436405738\n",
            "Epoch: 377 / 500 batch step: 120\n",
            "w1: [25.66262975] w2: [-23.58901549] bias: [16.07803605] loss: 30.552045038360514\n",
            "Epoch: 377 / 500 batch step: 150\n",
            "w1: [25.69717672] w2: [-23.58771759] bias: [16.12188436] loss: 30.533696960430856\n",
            "Epoch: 377 / 500 batch step: 180\n",
            "w1: [25.76510756] w2: [-23.57066743] bias: [16.22474808] loss: 30.521373038583867\n",
            "Epoch: 377 / 500 batch step: 210\n",
            "w1: [25.80229611] w2: [-23.55026173] bias: [16.28425149] loss: 30.53365986677101\n",
            "Epoch: 377 / 500 batch step: 240\n",
            "w1: [25.84153117] w2: [-23.5443455] bias: [16.3263122] loss: 30.552330662079147\n",
            "Epoch: 377 / 500 batch step: 270\n",
            "w1: [25.8580276] w2: [-23.54447783] bias: [16.34347175] loss: 30.562105518503568\n",
            "Epoch: 377 / 500 batch step: 300\n",
            "w1: [25.83822751] w2: [-23.55078119] bias: [16.30426622] loss: 30.543623738679937\n",
            "Epoch: 377 / 500 batch step: 330\n",
            "w1: [25.80196995] w2: [-23.56348313] bias: [16.23272959] loss: 30.52350549720678\n",
            "Epoch: 377 / 500 batch step: 360\n",
            "w1: [25.813419] w2: [-23.53392488] bias: [16.32222719] loss: 30.547447520349476\n",
            "Epoch: 377 / 500 batch step: 390\n",
            "w1: [25.78784945] w2: [-23.5455486] bias: [16.28826568] loss: 30.533477691556946\n",
            "Epoch: 377 / 500 batch step: 420\n",
            "w1: [25.73872047] w2: [-23.5886462] bias: [16.19380971] loss: 30.52099441337534\n",
            "Epoch: 377 / 500 batch step: 450\n",
            "w1: [25.71351643] w2: [-23.60614913] bias: [16.1509275] loss: 30.527254566759733\n",
            "Epoch: 377 / 500 batch step: 480\n",
            "w1: [25.6963963] w2: [-23.60779896] bias: [16.12444682] loss: 30.53449926696648\n",
            "Epoch: 378 / 500 batch step: 0\n",
            "w1: [25.69003118] w2: [-23.6087685] bias: [16.11115798] loss: 30.538767217081496\n",
            "Epoch: 378 / 500 batch step: 30\n",
            "w1: [25.68314026] w2: [-23.60888589] bias: [16.09741015] loss: 30.543763521219145\n",
            "Epoch: 378 / 500 batch step: 60\n",
            "w1: [25.66134619] w2: [-23.61603467] bias: [16.05584893] loss: 30.563573835580666\n",
            "Epoch: 378 / 500 batch step: 90\n",
            "w1: [25.65486123] w2: [-23.62002355] bias: [16.04058077] loss: 30.572167431812616\n",
            "Epoch: 378 / 500 batch step: 120\n",
            "w1: [25.66468396] w2: [-23.58923748] bias: [16.07703793] loss: 30.55199316419325\n",
            "Epoch: 378 / 500 batch step: 150\n",
            "w1: [25.6992295] w2: [-23.58793913] bias: [16.12088532] loss: 30.53364903539304\n",
            "Epoch: 378 / 500 batch step: 180\n",
            "w1: [25.76715639] w2: [-23.57088909] bias: [16.22374405] loss: 30.52133039049568\n",
            "Epoch: 378 / 500 batch step: 210\n",
            "w1: [25.8043412] w2: [-23.55048321] bias: [16.28324342] loss: 30.533616923145736\n",
            "Epoch: 378 / 500 batch step: 240\n",
            "w1: [25.84357226] w2: [-23.54456743] bias: [16.32529952] loss: 30.552287008897807\n",
            "Epoch: 378 / 500 batch step: 270\n",
            "w1: [25.86006585] w2: [-23.54469999] bias: [16.34245519] loss: 30.56206025756281\n",
            "Epoch: 378 / 500 batch step: 300\n",
            "w1: [25.84026523] w2: [-23.55100316] bias: [16.30324936] loss: 30.54357928587253\n",
            "Epoch: 378 / 500 batch step: 330\n",
            "w1: [25.80400749] w2: [-23.56370492] bias: [16.23171283] loss: 30.523463017325856\n",
            "Epoch: 378 / 500 batch step: 360\n",
            "w1: [25.81545679] w2: [-23.53414294] bias: [16.32121577] loss: 30.547401488312317\n",
            "Epoch: 378 / 500 batch step: 390\n",
            "w1: [25.78988875] w2: [-23.54576325] bias: [16.28725942] loss: 30.533433564912716\n",
            "Epoch: 378 / 500 batch step: 420\n",
            "w1: [25.74076048] w2: [-23.58885992] bias: [16.19280514] loss: 30.520951589172746\n",
            "Epoch: 378 / 500 batch step: 450\n",
            "w1: [25.71555656] w2: [-23.6063624] bias: [16.1499237] loss: 30.527211542176644\n",
            "Epoch: 378 / 500 batch step: 480\n",
            "w1: [25.69843707] w2: [-23.60801094] bias: [16.12344523] loss: 30.534454563067204\n",
            "Epoch: 379 / 500 batch step: 0\n",
            "w1: [25.69207226] w2: [-23.60897962] bias: [16.11015767] loss: 30.538721648084163\n",
            "Epoch: 379 / 500 batch step: 30\n",
            "w1: [25.6851816] w2: [-23.60909611] bias: [16.09641102] loss: 30.543716888487733\n",
            "Epoch: 379 / 500 batch step: 60\n",
            "w1: [25.66338706] w2: [-23.61624482] bias: [16.05484936] loss: 30.563526009593254\n",
            "Epoch: 379 / 500 batch step: 90\n",
            "w1: [25.65690111] w2: [-23.62023356] bias: [16.03958023] loss: 30.572119988904642\n",
            "Epoch: 379 / 500 batch step: 120\n",
            "w1: [25.66672544] w2: [-23.58944468] bias: [16.07604181] loss: 30.551941923263133\n",
            "Epoch: 379 / 500 batch step: 150\n",
            "w1: [25.70126957] w2: [-23.58814589] bias: [16.11988832] loss: 30.533601679634323\n",
            "Epoch: 379 / 500 batch step: 180\n",
            "w1: [25.76919257] w2: [-23.57109597] bias: [16.22274213] loss: 30.521288240177864\n",
            "Epoch: 379 / 500 batch step: 210\n",
            "w1: [25.80637367] w2: [-23.55068992] bias: [16.28223751] loss: 30.533574482070552\n",
            "Epoch: 379 / 500 batch step: 240\n",
            "w1: [25.84560078] w2: [-23.54477458] bias: [16.32428906] loss: 30.552243864784028\n",
            "Epoch: 379 / 500 batch step: 270\n",
            "w1: [25.86209159] w2: [-23.54490736] bias: [16.34144091] loss: 30.56201553396449\n",
            "Epoch: 379 / 500 batch step: 300\n",
            "w1: [25.84229045] w2: [-23.55121034] bias: [16.30223481] loss: 30.543535368926722\n",
            "Epoch: 379 / 500 batch step: 330\n",
            "w1: [25.80603254] w2: [-23.56391192] bias: [16.2306984] loss: 30.52342104547244\n",
            "Epoch: 379 / 500 batch step: 360\n",
            "w1: [25.81748208] w2: [-23.53434626] bias: [16.3202066] loss: 30.547356022048863\n",
            "Epoch: 379 / 500 batch step: 390\n",
            "w1: [25.79191553] w2: [-23.54596324] bias: [16.28625531] loss: 30.53338995707817\n",
            "Epoch: 379 / 500 batch step: 420\n",
            "w1: [25.74278793] w2: [-23.589059] bias: [16.19180265] loss: 30.520909258953935\n",
            "Epoch: 379 / 500 batch step: 450\n",
            "w1: [25.7175841] w2: [-23.60656106] bias: [16.14892196] loss: 30.52716902248671\n",
            "Epoch: 379 / 500 batch step: 480\n",
            "w1: [25.70046525] w2: [-23.60820833] bias: [16.12244569] loss: 30.534410389924844\n",
            "Epoch: 380 / 500 batch step: 0\n",
            "w1: [25.69410075] w2: [-23.60917617] bias: [16.1091594] loss: 30.538676621763926\n",
            "Epoch: 380 / 500 batch step: 30\n",
            "w1: [25.68721037] w2: [-23.60929175] bias: [16.09541393] loss: 30.54367080848699\n",
            "Epoch: 380 / 500 batch step: 60\n",
            "w1: [25.66541538] w2: [-23.61644041] bias: [16.05385185] loss: 30.563478741557084\n",
            "Epoch: 380 / 500 batch step: 90\n",
            "w1: [25.65892845] w2: [-23.62042899] bias: [16.03858178] loss: 30.57207309581274\n",
            "Epoch: 380 / 500 batch step: 120\n",
            "w1: [25.66875434] w2: [-23.58963737] bias: [16.07504771] loss: 30.5518913025314\n",
            "Epoch: 380 / 500 batch step: 150\n",
            "w1: [25.7032971] w2: [-23.58833813] bias: [16.11889336] loss: 30.53355488115722\n",
            "Epoch: 380 / 500 batch step: 180\n",
            "w1: [25.77121627] w2: [-23.57128832] bias: [16.22174232] loss: 30.521246576770064\n",
            "Epoch: 380 / 500 batch step: 210\n",
            "w1: [25.8083937] w2: [-23.5508821] bias: [16.28123374] loss: 30.533532532619056\n",
            "Epoch: 380 / 500 batch step: 240\n",
            "w1: [25.84761691] w2: [-23.5449672] bias: [16.3232808] loss: 30.55220121872274\n",
            "Epoch: 380 / 500 batch step: 270\n",
            "w1: [25.86410497] w2: [-23.54510021] bias: [16.34042891] loss: 30.561971336233157\n",
            "Epoch: 380 / 500 batch step: 300\n",
            "w1: [25.84430333] w2: [-23.55140299] bias: [16.30122256] loss: 30.543491976364425\n",
            "Epoch: 380 / 500 batch step: 330\n",
            "w1: [25.80804527] w2: [-23.56410439] bias: [16.22968631] loss: 30.52337957060748\n",
            "Epoch: 380 / 500 batch step: 360\n",
            "w1: [25.81949504] w2: [-23.53453512] bias: [16.31919969] loss: 30.547311109616828\n",
            "Epoch: 380 / 500 batch step: 390\n",
            "w1: [25.79392992] w2: [-23.54614882] bias: [16.28525335] loss: 30.533346856926524\n",
            "Epoch: 380 / 500 batch step: 420\n",
            "w1: [25.74480297] w2: [-23.58924373] bias: [16.19080226] loss: 30.520867412005735\n",
            "Epoch: 380 / 500 batch step: 450\n",
            "w1: [25.71959923] w2: [-23.60674538] bias: [16.14792227] loss: 30.527126996784908\n",
            "Epoch: 380 / 500 batch step: 480\n",
            "w1: [25.70248102] w2: [-23.60839138] bias: [16.12144818] loss: 30.53436673622308\n",
            "Epoch: 381 / 500 batch step: 0\n",
            "w1: [25.69611682] w2: [-23.6093584] bias: [16.10816315] loss: 30.538632126619948\n",
            "Epoch: 381 / 500 batch step: 30\n",
            "w1: [25.68922672] w2: [-23.60947309] bias: [16.09441887] loss: 30.543625269574974\n",
            "Epoch: 381 / 500 batch step: 60\n",
            "w1: [25.6674313] w2: [-23.61662168] bias: [16.05285641] loss: 30.563432019782535\n",
            "Epoch: 381 / 500 batch step: 90\n",
            "w1: [25.66094341] w2: [-23.62061011] bias: [16.03758541] loss: 30.572026740987376\n",
            "Epoch: 381 / 500 batch step: 120\n",
            "w1: [25.67077084] w2: [-23.5898158] bias: [16.0740556] loss: 30.551841289297574\n",
            "Epoch: 381 / 500 batch step: 150\n",
            "w1: [25.70531224] w2: [-23.58851612] bias: [16.11790043] loss: 30.53350862828539\n",
            "Epoch: 381 / 500 batch step: 180\n",
            "w1: [25.77322762] w2: [-23.57146641] bias: [16.22074461] loss: 30.521205389714336\n",
            "Epoch: 381 / 500 batch step: 210\n",
            "w1: [25.81040143] w2: [-23.55106003] bias: [16.28023213] loss: 30.533491064167926\n",
            "Epoch: 381 / 500 batch step: 240\n",
            "w1: [25.84962078] w2: [-23.54514556] bias: [16.32227475] loss: 30.552159060003184\n",
            "Epoch: 381 / 500 batch step: 270\n",
            "w1: [25.86610615] w2: [-23.54527878] bias: [16.33941917] loss: 30.561927653205036\n",
            "Epoch: 381 / 500 batch step: 300\n",
            "w1: [25.84630402] w2: [-23.55158138] bias: [16.30021261] loss: 30.543449097019383\n",
            "Epoch: 381 / 500 batch step: 330\n",
            "w1: [25.81004583] w2: [-23.56428259] bias: [16.22867654] loss: 30.52333858199675\n",
            "Epoch: 381 / 500 batch step: 360\n",
            "w1: [25.8214958] w2: [-23.53470977] bias: [16.31819502] loss: 30.54726673939231\n",
            "Epoch: 381 / 500 batch step: 390\n",
            "w1: [25.79593209] w2: [-23.54632027] bias: [16.28425353] loss: 30.53330425363533\n",
            "Epoch: 381 / 500 batch step: 420\n",
            "w1: [25.74680576] w2: [-23.58941435] bias: [16.18980394] loss: 30.52082603791248\n",
            "Epoch: 381 / 500 batch step: 450\n",
            "w1: [25.72160209] w2: [-23.6069156] bias: [16.14692463] loss: 30.527085454466807\n",
            "Epoch: 381 / 500 batch step: 480\n",
            "w1: [25.70448451] w2: [-23.60856036] bias: [16.12045271] loss: 30.534323590952738\n",
            "Epoch: 382 / 500 batch step: 0\n",
            "w1: [25.69812062] w2: [-23.60952656] bias: [16.10716894] loss: 30.53858815146137\n",
            "Epoch: 382 / 500 batch step: 30\n",
            "w1: [25.69123081] w2: [-23.60964038] bias: [16.09342584] loss: 30.543580260421777\n",
            "Epoch: 382 / 500 batch step: 60\n",
            "w1: [25.66943498] w2: [-23.6167889] bias: [16.05186303] loss: 30.563385832892568\n",
            "Epoch: 382 / 500 batch step: 90\n",
            "w1: [25.66294614] w2: [-23.62077718] bias: [16.03659113] loss: 30.57198091318913\n",
            "Epoch: 382 / 500 batch step: 120\n",
            "w1: [25.67277507] w2: [-23.58998022] bias: [16.0730655] loss: 30.551791871189696\n",
            "Epoch: 382 / 500 batch step: 150\n",
            "w1: [25.70731515] w2: [-23.5886801] bias: [16.11690953] loss: 30.53346290965423\n",
            "Epoch: 382 / 500 batch step: 180\n",
            "w1: [25.77522679] w2: [-23.5716305] bias: [16.21974901] loss: 30.521164668746003\n",
            "Epoch: 382 / 500 batch step: 210\n",
            "w1: [25.81239702] w2: [-23.55122396] bias: [16.27923265] loss: 30.533450066387825\n",
            "Epoch: 382 / 500 batch step: 240\n",
            "w1: [25.85161255] w2: [-23.54530992] bias: [16.3212709] loss: 30.552117378209797\n",
            "Epoch: 382 / 500 batch step: 270\n",
            "w1: [25.86809527] w2: [-23.54544335] bias: [16.33841171] loss: 30.561884474018882\n",
            "Epoch: 382 / 500 batch step: 300\n",
            "w1: [25.84829268] w2: [-23.55174574] bias: [16.29920495] loss: 30.54340672002795\n",
            "Epoch: 382 / 500 batch step: 330\n",
            "w1: [25.81203437] w2: [-23.56444677] bias: [16.22766908] loss: 30.523298069201726\n",
            "Epoch: 382 / 500 batch step: 360\n",
            "w1: [25.82348454] w2: [-23.53487047] bias: [16.3171926] loss: 30.54722290006046\n",
            "Epoch: 382 / 500 batch step: 390\n",
            "w1: [25.79792218] w2: [-23.54647784] bias: [16.28325585] loss: 30.533262136677457\n",
            "Epoch: 382 / 500 batch step: 420\n",
            "w1: [25.74879645] w2: [-23.58957111] bias: [16.18880771] loss: 30.520785126547082\n",
            "Epoch: 382 / 500 batch step: 450\n",
            "w1: [25.72359284] w2: [-23.60707199] bias: [16.14592905] loss: 30.527044385219597\n",
            "Epoch: 382 / 500 batch step: 480\n",
            "w1: [25.70647589] w2: [-23.60871551] bias: [16.11945928] loss: 30.53428094340263\n",
            "Epoch: 383 / 500 batch step: 0\n",
            "w1: [25.7001123] w2: [-23.60968091] bias: [16.10617675] loss: 30.538544685398154\n",
            "Epoch: 383 / 500 batch step: 30\n",
            "w1: [25.69322278] w2: [-23.60979387] bias: [16.09243485] loss: 30.543535770000304\n",
            "Epoch: 383 / 500 batch step: 60\n",
            "w1: [25.67142656] w2: [-23.61694231] bias: [16.05087172] loss: 30.563340169813493\n",
            "Epoch: 383 / 500 batch step: 90\n",
            "w1: [25.66493679] w2: [-23.62093044] bias: [16.03559892] loss: 30.571935601479595\n",
            "Epoch: 383 / 500 batch step: 120\n",
            "w1: [25.6747672] w2: [-23.59013089] bias: [16.0720774] loss: 30.55174303615496\n",
            "Epoch: 383 / 500 batch step: 150\n",
            "w1: [25.70930598] w2: [-23.58883033] bias: [16.11592067] loss: 30.533417714201722\n",
            "Epoch: 383 / 500 batch step: 180\n",
            "w1: [25.77721394] w2: [-23.57178083] bias: [16.2187555] loss: 30.521124403884862\n",
            "Epoch: 383 / 500 batch step: 210\n",
            "w1: [25.81438062] w2: [-23.55137414] bias: [16.27823532] loss: 30.53340952923457\n",
            "Epoch: 383 / 500 batch step: 240\n",
            "w1: [25.85359238] w2: [-23.54546052] bias: [16.32026925] loss: 30.552076163213375\n",
            "Epoch: 383 / 500 batch step: 270\n",
            "w1: [25.87007248] w2: [-23.54559415] bias: [16.33740651] loss: 30.561841788106957\n",
            "Epoch: 383 / 500 batch step: 300\n",
            "w1: [25.85026944] w2: [-23.55189635] bias: [16.29819957] loss: 30.54336483482013\n",
            "Epoch: 383 / 500 batch step: 330\n",
            "w1: [25.81401103] w2: [-23.56459719] bias: [16.22666394] loss: 30.523258022070756\n",
            "Epoch: 383 / 500 batch step: 360\n",
            "w1: [25.82546138] w2: [-23.53501746] bias: [16.31619241] loss: 30.547179580606493\n",
            "Epoch: 383 / 500 batch step: 390\n",
            "w1: [25.79990035] w2: [-23.54662176] bias: [16.28226031] loss: 30.53322049581231\n",
            "Epoch: 383 / 500 batch step: 420\n",
            "w1: [25.75077519] w2: [-23.58971427] bias: [16.18781357] loss: 30.520744668062342\n",
            "Epoch: 383 / 500 batch step: 450\n",
            "w1: [25.72557162] w2: [-23.60721478] bias: [16.14493552] loss: 30.527003779013356\n",
            "Epoch: 383 / 500 batch step: 480\n",
            "w1: [25.7084553] w2: [-23.60885709] bias: [16.11846788] loss: 30.534238783150784\n",
            "Epoch: 384 / 500 batch step: 0\n",
            "w1: [25.70209202] w2: [-23.6098217] bias: [16.10518659] loss: 30.538501717832204\n",
            "Epoch: 384 / 500 batch step: 30\n",
            "w1: [25.6952028] w2: [-23.60993381] bias: [16.09144588] loss: 30.543491787577445\n",
            "Epoch: 384 / 500 batch step: 60\n",
            "w1: [25.6734062] w2: [-23.61708217] bias: [16.04988247] loss: 30.563295019766095\n",
            "Epoch: 384 / 500 batch step: 90\n",
            "w1: [25.66691551] w2: [-23.62107015] bias: [16.0346088] loss: 30.57189079521251\n",
            "Epoch: 384 / 500 batch step: 120\n",
            "w1: [25.67674737] w2: [-23.59026805] bias: [16.07109131] loss: 30.551694772450556\n",
            "Epoch: 384 / 500 batch step: 150\n",
            "w1: [25.71128487] w2: [-23.58896705] bias: [16.11493384] loss: 30.5333730311596\n",
            "Epoch: 384 / 500 batch step: 180\n",
            "w1: [25.77918919] w2: [-23.57191765] bias: [16.21776409] loss: 30.521084585426618\n",
            "Epoch: 384 / 500 batch step: 210\n",
            "w1: [25.81635237] w2: [-23.55151081] bias: [16.27724013] loss: 30.5333694429406\n",
            "Epoch: 384 / 500 batch step: 240\n",
            "w1: [25.8555604] w2: [-23.54559761] bias: [16.3192698] loss: 30.552035405162535\n",
            "Epoch: 384 / 500 batch step: 270\n",
            "w1: [25.87203794] w2: [-23.54573145] bias: [16.33640356] loss: 30.561799585186368\n",
            "Epoch: 384 / 500 batch step: 300\n",
            "w1: [25.85223446] w2: [-23.55203344] bias: [16.29719648] loss: 30.543323431110878\n",
            "Epoch: 384 / 500 batch step: 330\n",
            "w1: [25.81597596] w2: [-23.56473409] bias: [16.22566111] loss: 30.52321843073045\n",
            "Epoch: 384 / 500 batch step: 360\n",
            "w1: [25.82742649] w2: [-23.53515099] bias: [16.31519446] loss: 30.547136770306874\n",
            "Epoch: 384 / 500 batch step: 390\n",
            "w1: [25.80186674] w2: [-23.54675229] bias: [16.28126691] loss: 30.533179321077302\n",
            "Epoch: 384 / 500 batch step: 420\n",
            "w1: [25.75274212] w2: [-23.58984407] bias: [16.1868215] loss: 30.520704652882547\n",
            "Epoch: 384 / 500 batch step: 450\n",
            "w1: [25.72753858] w2: [-23.60734423] bias: [16.14394404] loss: 30.526963626092606\n",
            "Epoch: 384 / 500 batch step: 480\n",
            "w1: [25.71042289] w2: [-23.60898534] bias: [16.11747852] loss: 30.534197100055867\n",
            "Epoch: 385 / 500 batch step: 0\n",
            "w1: [25.70405991] w2: [-23.60994916] bias: [16.10419846] loss: 30.53845923844881\n",
            "Epoch: 385 / 500 batch step: 30\n",
            "w1: [25.69717099] w2: [-23.61006044] bias: [16.09045895] loss: 30.543448302705436\n",
            "Epoch: 385 / 500 batch step: 60\n",
            "w1: [25.67537405] w2: [-23.61720871] bias: [16.04889528] loss: 30.563250372257045\n",
            "Epoch: 385 / 500 batch step: 90\n",
            "w1: [25.66888244] w2: [-23.62119655] bias: [16.03362075] loss: 30.571846484025187\n",
            "Epoch: 385 / 500 batch step: 120\n",
            "w1: [25.67871573] w2: [-23.59039195] bias: [16.07010721] loss: 30.551647068634814\n",
            "Epoch: 385 / 500 batch step: 150\n",
            "w1: [25.71325198] w2: [-23.58909051] bias: [16.11394904] loss: 30.533328850044743\n",
            "Epoch: 385 / 500 batch step: 180\n",
            "w1: [25.78115271] w2: [-23.57204121] bias: [16.21677478] loss: 30.52104520393462\n",
            "Epoch: 385 / 500 batch step: 210\n",
            "w1: [25.81831242] w2: [-23.55163423] bias: [16.27624708] loss: 30.533329798006687\n",
            "Epoch: 385 / 500 batch step: 240\n",
            "w1: [25.85751676] w2: [-23.54572143] bias: [16.31827253] loss: 30.551995094475362\n",
            "Epoch: 385 / 500 batch step: 270\n",
            "w1: [25.87399177] w2: [-23.54585547] bias: [16.33540287] loss: 30.561757855250697\n",
            "Epoch: 385 / 500 batch step: 300\n",
            "w1: [25.85418788] w2: [-23.55215726] bias: [16.29619567] loss: 30.54328249889171\n",
            "Epoch: 385 / 500 batch step: 330\n",
            "w1: [25.8179293] w2: [-23.56485771] bias: [16.22466057] loss: 30.523179285577385\n",
            "Epoch: 385 / 500 batch step: 360\n",
            "w1: [25.82937999] w2: [-23.53527131] bias: [16.31419874] loss: 30.5470944587209\n",
            "Epoch: 385 / 500 batch step: 390\n",
            "w1: [25.8038215] w2: [-23.54686967] bias: [16.28027564] loss: 30.533138602779605\n",
            "Epoch: 385 / 500 batch step: 420\n",
            "w1: [25.75469739] w2: [-23.58996075] bias: [16.18583151] loss: 30.520665071695337\n",
            "Epoch: 385 / 500 batch step: 450\n",
            "w1: [25.72949387] w2: [-23.60746057] bias: [16.14295461] loss: 30.526923916968137\n",
            "Epoch: 385 / 500 batch step: 480\n",
            "w1: [25.7123788] w2: [-23.60910049] bias: [16.11649119] loss: 30.534155884248946\n",
            "Epoch: 386 / 500 batch step: 0\n",
            "w1: [25.70601613] w2: [-23.61006355] bias: [16.10321235] loss: 30.538417237208332\n",
            "Epoch: 386 / 500 batch step: 30\n",
            "w1: [25.69912752] w2: [-23.610174] bias: [16.08947404] loss: 30.54340530521351\n",
            "Epoch: 386 / 500 batch step: 60\n",
            "w1: [25.67733024] w2: [-23.61732219] bias: [16.04791015] loss: 30.563206217070505\n",
            "Epoch: 386 / 500 batch step: 90\n",
            "w1: [25.67083774] w2: [-23.62130988] bias: [16.03263477] loss: 30.571802657830215\n",
            "Epoch: 386 / 500 batch step: 120\n",
            "w1: [25.68067242] w2: [-23.59050283] bias: [16.06912512] loss: 30.55159991355864\n",
            "Epoch: 386 / 500 batch step: 150\n",
            "w1: [25.71520744] w2: [-23.58920094] bias: [16.11296627] loss: 30.533285160650863\n",
            "Epoch: 386 / 500 batch step: 180\n",
            "w1: [25.78310463] w2: [-23.57215175] bias: [16.21578756] loss: 30.521006250231817\n",
            "Epoch: 386 / 500 batch step: 210\n",
            "w1: [25.82026091] w2: [-23.55174462] bias: [16.27525616] loss: 30.533290585193896\n",
            "Epoch: 386 / 500 batch step: 240\n",
            "w1: [25.85946161] w2: [-23.54583223] bias: [16.31727745] loss: 30.551955221831452\n",
            "Epoch: 386 / 500 batch step: 270\n",
            "w1: [25.87593414] w2: [-23.54596646] bias: [16.33440442] loss: 30.561716588561804\n",
            "Epoch: 386 / 500 batch step: 300\n",
            "w1: [25.85612984] w2: [-23.55226805] bias: [16.29519712] loss: 30.543242028422554\n",
            "Epoch: 386 / 500 batch step: 330\n",
            "w1: [25.81987121] w2: [-23.56496831] bias: [16.22366233] loss: 30.52314057727011\n",
            "Epoch: 386 / 500 batch step: 360\n",
            "w1: [25.83132204] w2: [-23.53537865] bias: [16.31320525] loss: 30.54705263568241\n",
            "Epoch: 386 / 500 batch step: 390\n",
            "w1: [25.80576477] w2: [-23.54697414] bias: [16.27928651] loss: 30.53309833148817\n",
            "Epoch: 386 / 500 batch step: 420\n",
            "w1: [25.75664114] w2: [-23.59006455] bias: [16.1848436] loss: 30.520625915443837\n",
            "Epoch: 386 / 500 batch step: 450\n",
            "w1: [25.73143762] w2: [-23.60756405] bias: [16.14196723] loss: 30.52688464240905\n",
            "Epoch: 386 / 500 batch step: 480\n",
            "w1: [25.71432318] w2: [-23.60920279] bias: [16.1155059] loss: 30.534115126125418\n",
            "Epoch: 387 / 500 batch step: 0\n",
            "w1: [25.70796081] w2: [-23.61016509] bias: [16.10222827] loss: 30.53837570433811\n",
            "Epoch: 387 / 500 batch step: 30\n",
            "w1: [25.70107252] w2: [-23.61027472] bias: [16.08849116] loss: 30.543362785199797\n",
            "Epoch: 387 / 500 batch step: 60\n",
            "w1: [25.67927492] w2: [-23.61742282] bias: [16.04692707] loss: 30.563162544260095\n",
            "Epoch: 387 / 500 batch step: 90\n",
            "w1: [25.67278154] w2: [-23.62141037] bias: [16.03165087] loss: 30.57175930680741\n",
            "Epoch: 387 / 500 batch step: 120\n",
            "w1: [25.68261759] w2: [-23.59060091] bias: [16.06814503] loss: 30.55155329635716\n",
            "Epoch: 387 / 500 batch step: 150\n",
            "w1: [25.7171514] w2: [-23.58929859] bias: [16.11198553] loss: 30.533241953040466\n",
            "Epoch: 387 / 500 batch step: 180\n",
            "w1: [25.7850451] w2: [-23.57224949] bias: [16.21480243] loss: 30.520967715392988\n",
            "Epoch: 387 / 500 batch step: 210\n",
            "w1: [25.82219798] w2: [-23.55184223] bias: [16.27426737] loss: 30.53325179551582\n",
            "Epoch: 387 / 500 batch step: 240\n",
            "w1: [25.86139508] w2: [-23.54593024] bias: [16.31628456] loss: 30.551915778164034\n",
            "Epoch: 387 / 500 batch step: 270\n",
            "w1: [25.87786516] w2: [-23.54606465] bias: [16.33340822] loss: 30.561675775641945\n",
            "Epoch: 387 / 500 batch step: 300\n",
            "w1: [25.85806048] w2: [-23.55236604] bias: [16.29420085] loss: 30.543202010223805\n",
            "Epoch: 387 / 500 batch step: 330\n",
            "w1: [25.8218018] w2: [-23.5650661] bias: [16.22266639] loss: 30.52310229672124\n",
            "Epoch: 387 / 500 batch step: 360\n",
            "w1: [25.83325277] w2: [-23.53547325] bias: [16.31221398] loss: 30.54701129129185\n",
            "Epoch: 387 / 500 batch step: 390\n",
            "w1: [25.80769668] w2: [-23.54706593] bias: [16.2782995] loss: 30.533058498025955\n",
            "Epoch: 387 / 500 batch step: 420\n",
            "w1: [25.75857351] w2: [-23.5901557] bias: [16.18385777] loss: 30.520587175318983\n",
            "Epoch: 387 / 500 batch step: 450\n",
            "w1: [25.73336999] w2: [-23.60765489] bias: [16.14098189] loss: 30.5268457934351\n",
            "Epoch: 387 / 500 batch step: 480\n",
            "w1: [25.71625617] w2: [-23.60929247] bias: [16.11452264] loss: 30.53407481633724\n",
            "Epoch: 388 / 500 batch step: 0\n",
            "w1: [25.70989411] w2: [-23.61025403] bias: [16.10124621] loss: 30.538334630324645\n",
            "Epoch: 388 / 500 batch step: 30\n",
            "w1: [25.70300613] w2: [-23.61036285] bias: [16.0875103] loss: 30.543320733023513\n",
            "Epoch: 388 / 500 batch step: 60\n",
            "w1: [25.68120823] w2: [-23.61751085] bias: [16.04594605] loss: 30.56311934414098\n",
            "Epoch: 388 / 500 batch step: 90\n",
            "w1: [25.67471398] w2: [-23.62149826] bias: [16.03066904] loss: 30.57171642139598\n",
            "Epoch: 388 / 500 batch step: 120\n",
            "w1: [25.68455138] w2: [-23.59068644] bias: [16.06716694] loss: 30.55150720644165\n",
            "Epoch: 388 / 500 batch step: 150\n",
            "w1: [25.719084] w2: [-23.58938368] bias: [16.11100682] loss: 30.533199217536964\n",
            "Epoch: 388 / 500 batch step: 180\n",
            "w1: [25.78697426] w2: [-23.57233468] bias: [16.2138194] loss: 30.520929590737204\n",
            "Epoch: 388 / 500 batch step: 210\n",
            "w1: [25.82412378] w2: [-23.55192729] bias: [16.27328071] loss: 30.53321342023104\n",
            "Epoch: 388 / 500 batch step: 240\n",
            "w1: [25.86331732] w2: [-23.54601569] bias: [16.31529385] loss: 30.55187675465246\n",
            "Epoch: 388 / 500 batch step: 270\n",
            "w1: [25.87978499] w2: [-23.54615028] bias: [16.33241425] loss: 30.561635407266092\n",
            "Epoch: 388 / 500 batch step: 300\n",
            "w1: [25.85997994] w2: [-23.55245147] bias: [16.29320683] loss: 30.54316243506871\n",
            "Epoch: 388 / 500 batch step: 330\n",
            "w1: [25.82372123] w2: [-23.56515132] bias: [16.22167272] loss: 30.52306443509002\n",
            "Epoch: 388 / 500 batch step: 360\n",
            "w1: [25.83517232] w2: [-23.53555533] bias: [16.31122492] loss: 30.546970415908515\n",
            "Epoch: 388 / 500 batch step: 390\n",
            "w1: [25.80961738] w2: [-23.54714526] bias: [16.27731461] loss: 30.533019093462443\n",
            "Epoch: 388 / 500 batch step: 420\n",
            "w1: [25.76049464] w2: [-23.59023442] bias: [16.182874] loss: 30.52054884275215\n",
            "Epoch: 388 / 500 batch step: 450\n",
            "w1: [25.73529111] w2: [-23.60773332] bias: [16.1399986] loss: 30.526807361309224\n",
            "Epoch: 388 / 500 batch step: 480\n",
            "w1: [25.7181779] w2: [-23.60936975] bias: [16.1135414] loss: 30.534034945785415\n",
            "Epoch: 389 / 500 batch step: 0\n",
            "w1: [25.71181614] w2: [-23.61033057] bias: [16.10026618] loss: 30.538294005906035\n",
            "Epoch: 389 / 500 batch step: 30\n",
            "w1: [25.7049285] w2: [-23.6104386] bias: [16.08653147] loss: 30.543279139297297\n",
            "Epoch: 389 / 500 batch step: 60\n",
            "w1: [25.68313031] w2: [-23.61758651] bias: [16.04496709] loss: 30.56307660728228\n",
            "Epoch: 389 / 500 batch step: 90\n",
            "w1: [25.67663521] w2: [-23.62157377] bias: [16.02968928] loss: 30.571673992286964\n",
            "Epoch: 389 / 500 batch step: 120\n",
            "w1: [25.68647392] w2: [-23.59075964] bias: [16.06619085] loss: 30.551461633491716\n",
            "Epoch: 389 / 500 batch step: 150\n",
            "w1: [25.72100538] w2: [-23.58945645] bias: [16.11003013] loss: 30.533156944717177\n",
            "Epoch: 389 / 500 batch step: 180\n",
            "w1: [25.78889223] w2: [-23.57240753] bias: [16.21283844] loss: 30.520891867820552\n",
            "Epoch: 389 / 500 batch step: 210\n",
            "w1: [25.82603844] w2: [-23.55200001] bias: [16.27229617] loss: 30.533175450835827\n",
            "Epoch: 389 / 500 batch step: 240\n",
            "w1: [25.86522845] w2: [-23.5460888] bias: [16.31430531] loss: 30.55183814271491\n",
            "Epoch: 389 / 500 batch step: 270\n",
            "w1: [25.88169376] w2: [-23.54622358] bias: [16.33142252] loss: 30.561595474454542\n",
            "Epoch: 389 / 500 batch step: 300\n",
            "w1: [25.86188835] w2: [-23.55252455] bias: [16.29221507] loss: 30.543123293975913\n",
            "Epoch: 389 / 500 batch step: 330\n",
            "w1: [25.82562962] w2: [-23.56522421] bias: [16.22068133] loss: 30.523026983774866\n",
            "Epoch: 389 / 500 batch step: 360\n",
            "w1: [25.83708082] w2: [-23.53562513] bias: [16.31023807] loss: 30.54693000014306\n",
            "Epoch: 389 / 500 batch step: 390\n",
            "w1: [25.811527] w2: [-23.54721237] bias: [16.27633185] loss: 30.532980109106344\n",
            "Epoch: 389 / 500 batch step: 420\n",
            "w1: [25.76240467] w2: [-23.59030095] bias: [16.18189231] loss: 30.520510909407935\n",
            "Epoch: 389 / 500 batch step: 450\n",
            "w1: [25.7372011] w2: [-23.60779957] bias: [16.13901736] loss: 30.52676933753034\n",
            "Epoch: 389 / 500 batch step: 480\n",
            "w1: [25.72008851] w2: [-23.60943486] bias: [16.1125622] loss: 30.533995505612637\n",
            "Epoch: 390 / 500 batch step: 0\n",
            "w1: [25.71372706] w2: [-23.61039496] bias: [16.09928817] loss: 30.538253822064622\n",
            "Epoch: 390 / 500 batch step: 30\n",
            "w1: [25.70683975] w2: [-23.61050221] bias: [16.08555467] loss: 30.543237994879895\n",
            "Epoch: 390 / 500 batch step: 60\n",
            "w1: [25.68504129] w2: [-23.61765001] bias: [16.04399018] loss: 30.56303432449973\n",
            "Epoch: 390 / 500 batch step: 90\n",
            "w1: [25.67854535] w2: [-23.62163713] bias: [16.02871158] loss: 30.57163201041591\n",
            "Epoch: 390 / 500 batch step: 120\n",
            "w1: [25.68838535] w2: [-23.59082073] bias: [16.06521676] loss: 30.551416567447664\n",
            "Epoch: 390 / 500 batch step: 150\n",
            "w1: [25.72291567] w2: [-23.5895171] bias: [16.10905546] loss: 30.53311512540388\n",
            "Epoch: 390 / 500 batch step: 180\n",
            "w1: [25.79079917] w2: [-23.57246827] bias: [16.21185957] loss: 30.520854538429\n",
            "Epoch: 390 / 500 batch step: 210\n",
            "w1: [25.82794208] w2: [-23.55206064] bias: [16.27131376] loss: 30.533137879057044\n",
            "Epoch: 390 / 500 batch step: 240\n",
            "w1: [25.86712862] w2: [-23.54614981] bias: [16.31331895] loss: 30.55179993400124\n",
            "Epoch: 390 / 500 batch step: 270\n",
            "w1: [25.8835916] w2: [-23.54628476] bias: [16.33043302] loss: 30.56155596846571\n",
            "Epoch: 390 / 500 batch step: 300\n",
            "w1: [25.86378585] w2: [-23.55258553] bias: [16.29122556] loss: 30.54308457820228\n",
            "Epoch: 390 / 500 batch step: 330\n",
            "w1: [25.82752711] w2: [-23.56528498] bias: [16.21969222] loss: 30.522989934406382\n",
            "Epoch: 390 / 500 batch step: 360\n",
            "w1: [25.83897841] w2: [-23.53568286] bias: [16.30925344] loss: 30.546890034850236\n",
            "Epoch: 390 / 500 batch step: 390\n",
            "w1: [25.81342568] w2: [-23.54726748] bias: [16.2753512] loss: 30.532941536498544\n",
            "Epoch: 390 / 500 batch step: 420\n",
            "w1: [25.76430373] w2: [-23.59035551] bias: [16.18091269] loss: 30.520473367177242\n",
            "Epoch: 390 / 500 batch step: 450\n",
            "w1: [25.73910012] w2: [-23.60785385] bias: [16.13803815] loss: 30.52673171382633\n",
            "Epoch: 390 / 500 batch step: 480\n",
            "w1: [25.72198814] w2: [-23.60948802] bias: [16.11158502] loss: 30.53395648719621\n",
            "Epoch: 391 / 500 batch step: 0\n",
            "w1: [25.715627] w2: [-23.61044741] bias: [16.09831217] loss: 30.538214070019826\n",
            "Epoch: 391 / 500 batch step: 30\n",
            "w1: [25.70874002] w2: [-23.61055389] bias: [16.08457988] loss: 30.54319729086898\n",
            "Epoch: 391 / 500 batch step: 60\n",
            "w1: [25.68694131] w2: [-23.61770159] bias: [16.04301531] loss: 30.562992486848465\n",
            "Epoch: 391 / 500 batch step: 90\n",
            "w1: [25.68044454] w2: [-23.62168856] bias: [16.02773595] loss: 30.57159046695573\n",
            "Epoch: 391 / 500 batch step: 120\n",
            "w1: [25.6902858] w2: [-23.59086993] bias: [16.06424467] loss: 30.551371998503132\n",
            "Epoch: 391 / 500 batch step: 150\n",
            "w1: [25.724815] w2: [-23.58956587] bias: [16.10808282] loss: 30.533073750658794\n",
            "Epoch: 391 / 500 batch step: 180\n",
            "w1: [25.79269519] w2: [-23.57251713] bias: [16.21088279] loss: 30.5208175945716\n",
            "Epoch: 391 / 500 batch step: 210\n",
            "w1: [25.82983486] w2: [-23.55210937] bias: [16.27033346] loss: 30.533100696845317\n",
            "Epoch: 391 / 500 batch step: 240\n",
            "w1: [25.86901795] w2: [-23.54619893] bias: [16.31233475] loss: 30.551762120386165\n",
            "Epoch: 391 / 500 batch step: 270\n",
            "w1: [25.88547864] w2: [-23.54633405] bias: [16.32944574] loss: 30.561516880789128\n",
            "Epoch: 391 / 500 batch step: 300\n",
            "w1: [25.86567256] w2: [-23.5526346] bias: [16.2902383] loss: 30.543046279235885\n",
            "Epoch: 391 / 500 batch step: 330\n",
            "w1: [25.82941384] w2: [-23.56533385] bias: [16.21870538] loss: 30.522953278840397\n",
            "Epoch: 391 / 500 batch step: 360\n",
            "w1: [25.84086522] w2: [-23.53572876] bias: [16.308271] loss: 30.54685051112182\n",
            "Epoch: 391 / 500 batch step: 390\n",
            "w1: [25.81531353] w2: [-23.5473108] bias: [16.27437268] loss: 30.53290336740525\n",
            "Epoch: 391 / 500 batch step: 420\n",
            "w1: [25.76619195] w2: [-23.5903983] bias: [16.17993513] loss: 30.52043620817052\n",
            "Epoch: 391 / 500 batch step: 450\n",
            "w1: [25.74098829] w2: [-23.6078964] bias: [16.13706099] loss: 30.526694482147253\n",
            "Epoch: 391 / 500 batch step: 480\n",
            "w1: [25.72387692] w2: [-23.60952946] bias: [16.11060988] loss: 30.53391788214123\n",
            "Epoch: 392 / 500 batch step: 0\n",
            "w1: [25.71751608] w2: [-23.61048814] bias: [16.0973382] loss: 30.53817474122132\n",
            "Epoch: 392 / 500 batch step: 30\n",
            "w1: [25.71062944] w2: [-23.61059385] bias: [16.08360712] loss: 30.543157018594204\n",
            "Epoch: 392 / 500 batch step: 60\n",
            "w1: [25.6888305] w2: [-23.61774145] bias: [16.0420425] loss: 30.562951085616128\n",
            "Epoch: 392 / 500 batch step: 90\n",
            "w1: [25.68233291] w2: [-23.62172828] bias: [16.02676238] loss: 30.571549353309827\n",
            "Epoch: 392 / 500 batch step: 120\n",
            "w1: [25.69217541] w2: [-23.59090747] bias: [16.06327457] loss: 30.551327917097975\n",
            "Epoch: 392 / 500 batch step: 150\n",
            "w1: [25.72670351] w2: [-23.58960297] bias: [16.1071122] loss: 30.53303281177556\n",
            "Epoch: 392 / 500 batch step: 180\n",
            "w1: [25.79458044] w2: [-23.57255432] bias: [16.20990808] loss: 30.520781028473806\n",
            "Epoch: 392 / 500 batch step: 210\n",
            "w1: [25.83171689] w2: [-23.55214645] bias: [16.26935528] loss: 30.533063896368347\n",
            "Epoch: 392 / 500 batch step: 240\n",
            "w1: [25.87089657] w2: [-23.54623638] bias: [16.31135272] loss: 30.551724693962555\n",
            "Epoch: 392 / 500 batch step: 270\n",
            "w1: [25.88735501] w2: [-23.54637166] bias: [16.32846068] loss: 30.56147820313871\n",
            "Epoch: 392 / 500 batch step: 300\n",
            "w1: [25.86754862] w2: [-23.552672] bias: [16.28925328] loss: 30.54300838878929\n",
            "Epoch: 392 / 500 batch step: 330\n",
            "w1: [25.83128991] w2: [-23.56537104] bias: [16.21772079] loss: 30.522917009151335\n",
            "Epoch: 392 / 500 batch step: 360\n",
            "w1: [25.84274137] w2: [-23.53576302] bias: [16.30729077] loss: 30.546811420279802\n",
            "Epoch: 392 / 500 batch step: 390\n",
            "w1: [25.81719071] w2: [-23.54734255] bias: [16.27339626] loss: 30.532865593811405\n",
            "Epoch: 392 / 500 batch step: 420\n",
            "w1: [25.76806946] w2: [-23.59042956] bias: [16.17895964] loss: 30.520399424711233\n",
            "Epoch: 392 / 500 batch step: 450\n",
            "w1: [25.74286573] w2: [-23.60792741] bias: [16.13608587] loss: 30.526657634658807\n",
            "Epoch: 392 / 500 batch step: 480\n",
            "w1: [25.72575498] w2: [-23.60955937] bias: [16.10963675] loss: 30.533879682273852\n",
            "Epoch: 393 / 500 batch step: 0\n",
            "w1: [25.71939444] w2: [-23.61051737] bias: [16.09636624] loss: 30.538135827342238\n",
            "Epoch: 393 / 500 batch step: 30\n",
            "w1: [25.71250814] w2: [-23.61062233] bias: [16.08263637] loss: 30.54311716961053\n",
            "Epoch: 393 / 500 batch step: 60\n",
            "w1: [25.69070899] w2: [-23.6177698] bias: [16.04107173] loss: 30.562910112316125\n",
            "Epoch: 393 / 500 batch step: 90\n",
            "w1: [25.68421059] w2: [-23.62175649] bias: [16.02579087] loss: 30.571508661105362\n",
            "Epoch: 393 / 500 batch step: 120\n",
            "w1: [25.6940543] w2: [-23.59093354] bias: [16.06230646] loss: 30.551284313911268\n",
            "Epoch: 393 / 500 batch step: 150\n",
            "w1: [25.72858133] w2: [-23.58962862] bias: [16.1061436] loss: 30.5329923002731\n",
            "Epoch: 393 / 500 batch step: 180\n",
            "w1: [25.79645504] w2: [-23.57258004] bias: [16.20893545] loss: 30.520744832571047\n",
            "Epoch: 393 / 500 batch step: 210\n",
            "w1: [25.8335883] w2: [-23.55217206] bias: [16.26837922] loss: 30.533027470004498\n",
            "Epoch: 393 / 500 batch step: 240\n",
            "w1: [25.87276462] w2: [-23.54626236] bias: [16.31037285] loss: 30.551687647035003\n",
            "Epoch: 393 / 500 batch step: 270\n",
            "w1: [25.88922083] w2: [-23.5463978] bias: [16.32747784] loss: 30.56143992744619\n",
            "Epoch: 393 / 500 batch step: 300\n",
            "w1: [25.86941415] w2: [-23.55269794] bias: [16.2882705] loss: 30.542970898792937\n",
            "Epoch: 393 / 500 batch step: 330\n",
            "w1: [25.83315548] w2: [-23.56539677] bias: [16.21673847] loss: 30.522881117625744\n",
            "Epoch: 393 / 500 batch step: 360\n",
            "w1: [25.844607] w2: [-23.53578587] bias: [16.30631273] loss: 30.54677275386972\n",
            "Epoch: 393 / 500 batch step: 390\n",
            "w1: [25.81905733] w2: [-23.54736295] bias: [16.27242196] loss: 30.53282820791421\n",
            "Epoch: 393 / 500 batch step: 420\n",
            "w1: [25.76993639] w2: [-23.59044948] bias: [16.17798621] loss: 30.520363009329547\n",
            "Epoch: 393 / 500 batch step: 450\n",
            "w1: [25.74473259] w2: [-23.60794711] bias: [16.13511278] loss: 30.526621163735918\n",
            "Epoch: 393 / 500 batch step: 480\n",
            "w1: [25.72762244] w2: [-23.60957798] bias: [16.10866565] loss: 30.53384187963489\n",
            "Epoch: 394 / 500 batch step: 0\n",
            "w1: [25.7212622] w2: [-23.61053529] bias: [16.0953963] loss: 30.538097320272758\n",
            "Epoch: 394 / 500 batch step: 30\n",
            "w1: [25.71437626] w2: [-23.61063951] bias: [16.08166765] loss: 30.543077735691647\n",
            "Epoch: 394 / 500 batch step: 60\n",
            "w1: [25.6925769] w2: [-23.61778687] bias: [16.040103] loss: 30.562869558681125\n",
            "Epoch: 394 / 500 batch step: 90\n",
            "w1: [25.6860777] w2: [-23.62177342] bias: [16.02482142] loss: 30.571468382186847\n",
            "Epoch: 394 / 500 batch step: 120\n",
            "w1: [25.69592261] w2: [-23.59094837] bias: [16.06134035] loss: 30.551241179854625\n",
            "Epoch: 394 / 500 batch step: 150\n",
            "w1: [25.73044859] w2: [-23.58964301] bias: [16.10517702] loss: 30.53295220788912\n",
            "Epoch: 394 / 500 batch step: 180\n",
            "w1: [25.79831911] w2: [-23.57259452] bias: [16.20796489] loss: 30.52070899950249\n",
            "Epoch: 394 / 500 batch step: 210\n",
            "w1: [25.83544922] w2: [-23.55218643] bias: [16.26740527] loss: 30.53299141033654\n",
            "Epoch: 394 / 500 batch step: 240\n",
            "w1: [25.87462221] w2: [-23.5462771] bias: [16.30939514] loss: 30.55165097211356\n",
            "Epoch: 394 / 500 batch step: 270\n",
            "w1: [25.89107624] w2: [-23.5464127] bias: [16.32649721] loss: 30.56140204585475\n",
            "Epoch: 394 / 500 batch step: 300\n",
            "w1: [25.87126928] w2: [-23.55271262] bias: [16.28728994] loss: 30.542933801388834\n",
            "Epoch: 394 / 500 batch step: 330\n",
            "w1: [25.83501065] w2: [-23.56541124] bias: [16.21575839] loss: 30.522845596756014\n",
            "Epoch: 394 / 500 batch step: 360\n",
            "w1: [25.84646223] w2: [-23.53579751] bias: [16.30533688] loss: 30.54673450365428\n",
            "Epoch: 394 / 500 batch step: 390\n",
            "w1: [25.82091351] w2: [-23.54737219] bias: [16.27144976] loss: 30.532791202116933\n",
            "Epoch: 394 / 500 batch step: 420\n",
            "w1: [25.77179287] w2: [-23.59045828] bias: [16.17701483] loss: 30.520326954756154\n",
            "Epoch: 394 / 500 batch step: 450\n",
            "w1: [25.74658898] w2: [-23.60795569] bias: [16.13414173] loss: 30.526585061956588\n",
            "Epoch: 394 / 500 batch step: 480\n",
            "w1: [25.72947944] w2: [-23.60958548] bias: [16.10769657] loss: 30.53380446647351\n",
            "Epoch: 395 / 500 batch step: 0\n",
            "w1: [25.7231195] w2: [-23.61054213] bias: [16.09442837] loss: 30.538059212113765\n",
            "Epoch: 395 / 500 batch step: 30\n",
            "w1: [25.71623391] w2: [-23.61064561] bias: [16.08070094] loss: 30.543038708823705\n",
            "Epoch: 395 / 500 batch step: 60\n",
            "w1: [25.69443436] w2: [-23.61779286] bias: [16.03913632] loss: 30.562829416656694\n",
            "Epoch: 395 / 500 batch step: 90\n",
            "w1: [25.68793439] w2: [-23.62177927] bias: [16.02385403] loss: 30.57142850860978\n",
            "Epoch: 395 / 500 batch step: 120\n",
            "w1: [25.69778046] w2: [-23.59095215] bias: [16.06037624] loss: 30.551198506065642\n",
            "Epoch: 395 / 500 batch step: 150\n",
            "w1: [25.7323054] w2: [-23.58964637] bias: [16.10421245] loss: 30.53291252657378\n",
            "Epoch: 395 / 500 batch step: 180\n",
            "w1: [25.80017278] w2: [-23.57259796] bias: [16.20699641] loss: 30.520673522104964\n",
            "Epoch: 395 / 500 batch step: 210\n",
            "w1: [25.83729978] w2: [-23.55218977] bias: [16.26643342] loss: 30.532955710145604\n",
            "Epoch: 395 / 500 batch step: 240\n",
            "w1: [25.87646948] w2: [-23.5462808] bias: [16.30841959] loss: 30.551614661907667\n",
            "Epoch: 395 / 500 batch step: 270\n",
            "w1: [25.89292136] w2: [-23.54641654] bias: [16.32551878] loss: 30.561364550712884\n",
            "Epoch: 395 / 500 batch step: 300\n",
            "w1: [25.87311412] w2: [-23.55271625] bias: [16.28631161] loss: 30.54289708892437\n",
            "Epoch: 395 / 500 batch step: 330\n",
            "w1: [25.83685556] w2: [-23.56541466] bias: [16.21478056] loss: 30.522810439234313\n",
            "Epoch: 395 / 500 batch step: 360\n",
            "w1: [25.84830717] w2: [-23.53579815] bias: [16.30436321] loss: 30.54669666160708\n",
            "Epoch: 395 / 500 batch step: 390\n",
            "w1: [25.82275939] w2: [-23.54737048] bias: [16.27047967] loss: 30.532754569022842\n",
            "Epoch: 395 / 500 batch step: 420\n",
            "w1: [25.77363901] w2: [-23.59045616] bias: [16.17604552] loss: 30.520291253916398\n",
            "Epoch: 395 / 500 batch step: 450\n",
            "w1: [25.74843503] w2: [-23.60795336] bias: [16.13317271] loss: 30.526549322095903\n",
            "Epoch: 395 / 500 batch step: 480\n",
            "w1: [25.73132609] w2: [-23.60958209] bias: [16.10672951] loss: 30.53376743524121\n",
            "Epoch: 396 / 500 batch step: 0\n",
            "w1: [25.72496646] w2: [-23.61053808] bias: [16.09346246] loss: 30.538021495170785\n",
            "Epoch: 396 / 500 batch step: 30\n",
            "w1: [25.71808122] w2: [-23.61064084] bias: [16.07973624] loss: 30.543000081199164\n",
            "Epoch: 396 / 500 batch step: 60\n",
            "w1: [25.6962815] w2: [-23.61778797] bias: [16.03817168] loss: 30.562789678395237\n",
            "Epoch: 396 / 500 batch step: 90\n",
            "w1: [25.68978075] w2: [-23.62177424] bias: [16.02288868] loss: 30.57138903263459\n",
            "Epoch: 396 / 500 batch step: 120\n",
            "w1: [25.69962797] w2: [-23.5909451] bias: [16.05941411] loss: 30.551156283901573\n",
            "Epoch: 396 / 500 batch step: 150\n",
            "w1: [25.7341519] w2: [-23.58963889] bias: [16.1032499] loss: 30.532873248483607\n",
            "Epoch: 396 / 500 batch step: 180\n",
            "w1: [25.80201618] w2: [-23.57259055] bias: [16.20602999] loss: 30.52063839340714\n",
            "Epoch: 396 / 500 batch step: 210\n",
            "w1: [25.83914009] w2: [-23.55218226] bias: [16.26546367] loss: 30.532920362405303\n",
            "Epoch: 396 / 500 batch step: 240\n",
            "w1: [25.87830653] w2: [-23.54627365] bias: [16.30744618] loss: 30.55157870932028\n",
            "Epoch: 396 / 500 batch step: 270\n",
            "w1: [25.8947563] w2: [-23.54640955] bias: [16.32454256] loss: 30.56132743456841\n",
            "Epoch: 396 / 500 batch step: 300\n",
            "w1: [25.87494881] w2: [-23.55270904] bias: [16.28533551] loss: 30.542860753946343\n",
            "Epoch: 396 / 500 batch step: 330\n",
            "w1: [25.83869031] w2: [-23.56540723] bias: [16.21380498] loss: 30.522775637946726\n",
            "Epoch: 396 / 500 batch step: 360\n",
            "w1: [25.85014196] w2: [-23.53578799] bias: [16.30339173] loss: 30.546659219906594\n",
            "Epoch: 396 / 500 batch step: 390\n",
            "w1: [25.82459508] w2: [-23.54735803] bias: [16.26951167] loss: 30.532718301429387\n",
            "Epoch: 396 / 500 batch step: 420\n",
            "w1: [25.77547495] w2: [-23.59044332] bias: [16.17507827] loss: 30.52025589992443\n",
            "Epoch: 396 / 500 batch step: 450\n",
            "w1: [25.75027085] w2: [-23.60794033] bias: [16.13220572] loss: 30.526513937120235\n",
            "Epoch: 396 / 500 batch step: 480\n",
            "w1: [25.73316252] w2: [-23.60956801] bias: [16.10576447] loss: 30.53373077858591\n",
            "Epoch: 397 / 500 batch step: 0\n",
            "w1: [25.72680319] w2: [-23.61052334] bias: [16.09249855] loss: 30.537984161947996\n",
            "Epoch: 397 / 500 batch step: 30\n",
            "w1: [25.71991832] w2: [-23.61062539] bias: [16.07877356] loss: 30.542961845210876\n",
            "Epoch: 397 / 500 batch step: 60\n",
            "w1: [25.69811844] w2: [-23.61777239] bias: [16.03720907] loss: 30.562750336249948\n",
            "Epoch: 397 / 500 batch step: 90\n",
            "w1: [25.69161693] w2: [-23.62175853] bias: [16.02192539] loss: 30.57134994672068\n",
            "Epoch: 397 / 500 batch step: 120\n",
            "w1: [25.70146527] w2: [-23.59092741] bias: [16.05845398] loss: 30.55111450493317\n",
            "Epoch: 397 / 500 batch step: 150\n",
            "w1: [25.7359882] w2: [-23.58962076] bias: [16.10228936] loss: 30.532834365975546\n",
            "Epoch: 397 / 500 batch step: 180\n",
            "w1: [25.80384942] w2: [-23.57257251] bias: [16.20506565] loss: 30.520603606623826\n",
            "Epoch: 397 / 500 batch step: 210\n",
            "w1: [25.84097028] w2: [-23.55216412] bias: [16.26449603] loss: 30.532885360276065\n",
            "Epoch: 397 / 500 batch step: 240\n",
            "w1: [25.8801335] w2: [-23.54625586] bias: [16.30647492] loss: 30.551543107442175\n",
            "Epoch: 397 / 500 batch step: 270\n",
            "w1: [25.89658119] w2: [-23.5463919] bias: [16.32356853] loss: 30.561290690162668\n",
            "Epoch: 397 / 500 batch step: 300\n",
            "w1: [25.87677346] w2: [-23.55269117] bias: [16.28436162] loss: 30.542824789195155\n",
            "Epoch: 397 / 500 batch step: 330\n",
            "w1: [25.84051504] w2: [-23.56538916] bias: [16.21283162] loss: 30.52274118596751\n",
            "Epoch: 397 / 500 batch step: 360\n",
            "w1: [25.85196671] w2: [-23.53576724] bias: [16.30242242] loss: 30.546622170930302\n",
            "Epoch: 397 / 500 batch step: 390\n",
            "w1: [25.8264207] w2: [-23.54733503] bias: [16.26854578] loss: 30.532682392322492\n",
            "Epoch: 397 / 500 batch step: 420\n",
            "w1: [25.7773008] w2: [-23.59041995] bias: [16.17411306] loss: 30.52022088607769\n",
            "Epoch: 397 / 500 batch step: 450\n",
            "w1: [25.75209658] w2: [-23.60791678] bias: [16.13124077] loss: 30.52647890018162\n",
            "Epoch: 397 / 500 batch step: 480\n",
            "w1: [25.73498885] w2: [-23.60954342] bias: [16.10480145] loss: 30.533694489346235\n",
            "Epoch: 398 / 500 batch step: 0\n",
            "w1: [25.72862982] w2: [-23.61049812] bias: [16.09153666] loss: 30.537947205142583\n",
            "Epoch: 398 / 500 batch step: 30\n",
            "w1: [25.72174532] w2: [-23.61059946] bias: [16.07781289] loss: 30.54292399344627\n",
            "Epoch: 398 / 500 batch step: 60\n",
            "w1: [25.69994529] w2: [-23.61774633] bias: [16.0362485] loss: 30.562711382769173\n",
            "Epoch: 398 / 500 batch step: 90\n",
            "w1: [25.69344304] w2: [-23.62173233] bias: [16.02096415] loss: 30.571311243520785\n",
            "Epoch: 398 / 500 batch step: 120\n",
            "w1: [25.70329248] w2: [-23.59089927] bias: [16.05749583] loss: 30.55107316093875\n",
            "Epoch: 398 / 500 batch step: 150\n",
            "w1: [25.73781443] w2: [-23.5895922] bias: [16.10133084] loss: 30.53279587160125\n",
            "Epoch: 398 / 500 batch step: 180\n",
            "w1: [25.80567263] w2: [-23.57254402] bias: [16.20410336] loss: 30.52056915515045\n",
            "Epoch: 398 / 500 batch step: 210\n",
            "w1: [25.84279047] w2: [-23.55213554] bias: [16.26353049] loss: 30.5328506970996\n",
            "Epoch: 398 / 500 batch step: 240\n",
            "w1: [25.8819505] w2: [-23.54622763] bias: [16.3055058] loss: 30.55150784954641\n",
            "Epoch: 398 / 500 batch step: 270\n",
            "w1: [25.89839615] w2: [-23.54636381] bias: [16.3225967] loss: 30.561254310424943\n",
            "Epoch: 398 / 500 batch step: 300\n",
            "w1: [25.87858818] w2: [-23.55266286] bias: [16.28338994] loss: 30.54278918759923\n",
            "Epoch: 398 / 500 batch step: 330\n",
            "w1: [25.84232986] w2: [-23.56536063] bias: [16.2118605] loss: 30.522707076553587\n",
            "Epoch: 398 / 500 batch step: 360\n",
            "w1: [25.85378154] w2: [-23.53573607] bias: [16.30145529] loss: 30.546585507248984\n",
            "Epoch: 398 / 500 batch step: 390\n",
            "w1: [25.82823637] w2: [-23.54730168] bias: [16.26758198] loss: 30.532646834871073\n",
            "Epoch: 398 / 500 batch step: 420\n",
            "w1: [25.77911667] w2: [-23.59038626] bias: [16.17314991] loss: 30.520186205851456\n",
            "Epoch: 398 / 500 batch step: 450\n",
            "w1: [25.75391233] w2: [-23.60788292] bias: [16.13027784] loss: 30.526444204612286\n",
            "Epoch: 398 / 500 batch step: 480\n",
            "w1: [25.73680519] w2: [-23.60950853] bias: [16.10384044] loss: 30.533658560546023\n",
            "Epoch: 399 / 500 batch step: 0\n",
            "w1: [25.73044647] w2: [-23.61046259] bias: [16.09057678] loss: 30.537910617639096\n",
            "Epoch: 399 / 500 batch step: 30\n",
            "w1: [25.72356234] w2: [-23.61056324] bias: [16.07685423] loss: 30.54288651868184\n",
            "Epoch: 399 / 500 batch step: 60\n",
            "w1: [25.70176218] w2: [-23.61770999] bias: [16.03528997] loss: 30.5626728106907\n",
            "Epoch: 399 / 500 batch step: 90\n",
            "w1: [25.69525919] w2: [-23.62169585] bias: [16.02000496] loss: 30.571272915875312\n",
            "Epoch: 399 / 500 batch step: 120\n",
            "w1: [25.70510971] w2: [-23.59086088] bias: [16.05653967] loss: 30.55103224389838\n",
            "Epoch: 399 / 500 batch step: 150\n",
            "w1: [25.7396307] w2: [-23.58955338] bias: [16.10037432] loss: 30.53275775810147\n",
            "Epoch: 399 / 500 batch step: 180\n",
            "w1: [25.80748593] w2: [-23.57250528] bias: [16.20314314] loss: 30.520535032557746\n",
            "Epoch: 399 / 500 batch step: 210\n",
            "w1: [25.84460077] w2: [-23.55209671] bias: [16.26256704] loss: 30.532816366393586\n",
            "Epoch: 399 / 500 batch step: 240\n",
            "w1: [25.88375765] w2: [-23.54618914] bias: [16.30453882] loss: 30.551472929082998\n",
            "Epoch: 399 / 500 batch step: 270\n",
            "w1: [25.90020128] w2: [-23.54632546] bias: [16.32162705] loss: 30.561218288466975\n",
            "Epoch: 399 / 500 batch step: 300\n",
            "w1: [25.8803931] w2: [-23.55262429] bias: [16.28242046] loss: 30.54275394226953\n",
            "Epoch: 399 / 500 batch step: 330\n",
            "w1: [25.84413488] w2: [-23.56532184] bias: [16.2108916] loss: 30.52267330313917\n",
            "Epoch: 399 / 500 batch step: 360\n",
            "w1: [25.85558657] w2: [-23.53569469] bias: [16.30049032] loss: 30.546549221621238\n",
            "Epoch: 399 / 500 batch step: 390\n",
            "w1: [25.83004221] w2: [-23.54725816] bias: [16.26662027] loss: 30.532611622421726\n",
            "Epoch: 399 / 500 batch step: 420\n",
            "w1: [25.7809227] w2: [-23.59034243] bias: [16.17218881] loss: 30.520151852893612\n",
            "Epoch: 399 / 500 batch step: 450\n",
            "w1: [25.75571822] w2: [-23.60783893] bias: [16.12931694] loss: 30.526409843919396\n",
            "Epoch: 399 / 500 batch step: 480\n",
            "w1: [25.73861167] w2: [-23.60946353] bias: [16.10288144] loss: 30.53362298538892\n",
            "Epoch: 400 / 500 batch step: 0\n",
            "w1: [25.73225325] w2: [-23.61041696] bias: [16.0896189] loss: 30.537874392504115\n",
            "Epoch: 400 / 500 batch step: 30\n",
            "w1: [25.72536949] w2: [-23.61051693] bias: [16.07589757] loss: 30.54284941387766\n",
            "Epoch: 400 / 500 batch step: 60\n",
            "w1: [25.70356923] w2: [-23.61766354] bias: [16.03433347] loss: 30.562634612936424\n",
            "Epoch: 400 / 500 batch step: 90\n",
            "w1: [25.6970655] w2: [-23.62164926] bias: [16.01904781] loss: 30.571234956807007\n",
            "Epoch: 400 / 500 batch step: 120\n",
            "w1: [25.70691708] w2: [-23.59081243] bias: [16.0555855] loss: 30.5509917459883\n",
            "Epoch: 400 / 500 batch step: 150\n",
            "w1: [25.74143713] w2: [-23.58950451] bias: [16.09941981] loss: 30.53272001840068\n",
            "Epoch: 400 / 500 batch step: 180\n",
            "w1: [25.80928942] w2: [-23.57245647] bias: [16.20218498] loss: 30.52050123258656\n",
            "Epoch: 400 / 500 batch step: 210\n",
            "w1: [25.8464013] w2: [-23.55204782] bias: [16.26160568] loss: 30.532782361846476\n",
            "Epoch: 400 / 500 batch step: 240\n",
            "w1: [25.88555506] w2: [-23.54614059] bias: [16.30357398] loss: 30.55143833967368\n",
            "Epoch: 400 / 500 batch step: 270\n",
            "w1: [25.90199671] w2: [-23.54627704] bias: [16.32065958] loss: 30.56118261757769\n",
            "Epoch: 400 / 500 batch step: 300\n",
            "w1: [25.88218832] w2: [-23.55257566] bias: [16.28145319] loss: 30.54271904649429\n",
            "Epoch: 400 / 500 batch step: 330\n",
            "w1: [25.84593022] w2: [-23.56527299] bias: [16.20992492] loss: 30.52263985933058\n",
            "Epoch: 400 / 500 batch step: 360\n",
            "w1: [25.8573819] w2: [-23.53564329] bias: [16.29952752] loss: 30.546513306988114\n",
            "Epoch: 400 / 500 batch step: 390\n",
            "w1: [25.83183833] w2: [-23.54720468] bias: [16.26566065] loss: 30.532576748493483\n",
            "Epoch: 400 / 500 batch step: 420\n",
            "w1: [25.78271898] w2: [-23.59028865] bias: [16.17122975] loss: 30.520117821019575\n",
            "Epoch: 400 / 500 batch step: 450\n",
            "w1: [25.75751435] w2: [-23.60778501] bias: [16.12835806] loss: 30.526375811779936\n",
            "Epoch: 400 / 500 batch step: 480\n",
            "w1: [25.7404084] w2: [-23.60940859] bias: [16.10192446] loss: 30.533587757253226\n",
            "Epoch: 401 / 500 batch step: 0\n",
            "w1: [25.73405028] w2: [-23.61036142] bias: [16.08866303] loss: 30.53783852298096\n",
            "Epoch: 401 / 500 batch step: 30\n",
            "w1: [25.7271669] w2: [-23.61046071] bias: [16.07494293] loss: 30.542812672172175\n",
            "Epoch: 401 / 500 batch step: 60\n",
            "w1: [25.70536653] w2: [-23.61760718] bias: [16.03337899] loss: 30.562596782607027\n",
            "Epoch: 401 / 500 batch step: 90\n",
            "w1: [25.69886209] w2: [-23.62159277] bias: [16.0180927] loss: 30.571197359515722\n",
            "Epoch: 401 / 500 batch step: 120\n",
            "w1: [25.7087147] w2: [-23.5907541] bias: [16.05463331] loss: 30.550951659575393\n",
            "Epoch: 401 / 500 batch step: 150\n",
            "w1: [25.74323384] w2: [-23.58944576] bias: [16.09846731] loss: 30.532682645601813\n",
            "Epoch: 401 / 500 batch step: 180\n",
            "w1: [25.81108322] w2: [-23.57239779] bias: [16.20122887] loss: 30.52046774914287\n",
            "Epoch: 401 / 500 batch step: 210\n",
            "w1: [25.84819217] w2: [-23.55198906] bias: [16.26064641] loss: 30.532748677312462\n",
            "Epoch: 401 / 500 batch step: 240\n",
            "w1: [25.88734285] w2: [-23.54608216] bias: [16.30261127] loss: 30.55140407510692\n",
            "Epoch: 401 / 500 batch step: 270\n",
            "w1: [25.90378255] w2: [-23.54621874] bias: [16.31969429] loss: 30.561147291218127\n",
            "Epoch: 401 / 500 batch step: 300\n",
            "w1: [25.88397397] w2: [-23.55251714] bias: [16.28048811] loss: 30.542684493733898\n",
            "Epoch: 401 / 500 batch step: 330\n",
            "w1: [25.847716] w2: [-23.56521425] bias: [16.20896046] loss: 30.522606738901196\n",
            "Epoch: 401 / 500 batch step: 360\n",
            "w1: [25.85916766] w2: [-23.53558205] bias: [16.29856687] loss: 30.546477756467937\n",
            "Epoch: 401 / 500 batch step: 390\n",
            "w1: [25.83362484] w2: [-23.5471414] bias: [16.26470311] loss: 30.53254220677289\n",
            "Epoch: 401 / 500 batch step: 420\n",
            "w1: [25.78450563] w2: [-23.59022511] bias: [16.17027274] loss: 30.520084104207328\n",
            "Epoch: 401 / 500 batch step: 450\n",
            "w1: [25.75930085] w2: [-23.60772132] bias: [16.12740121] loss: 30.5263421020357\n",
            "Epoch: 401 / 500 batch step: 480\n",
            "w1: [25.74219549] w2: [-23.60934391] bias: [16.10096949] loss: 30.533552869686815\n",
            "Epoch: 402 / 500 batch step: 0\n",
            "w1: [25.73583767] w2: [-23.61029613] bias: [16.08770916] loss: 30.537803002484676\n",
            "Epoch: 402 / 500 batch step: 30\n",
            "w1: [25.72895468] w2: [-23.61039476] bias: [16.07399028] loss: 30.542776286877093\n",
            "Epoch: 402 / 500 batch step: 60\n",
            "w1: [25.70715422] w2: [-23.61754109] bias: [16.03242654] loss: 30.562559312976937\n",
            "Epoch: 402 / 500 batch step: 90\n",
            "w1: [25.70064907] w2: [-23.62152655] bias: [16.01713963] loss: 30.57116011737332\n",
            "Epoch: 402 / 500 batch step: 120\n",
            "w1: [25.71050269] w2: [-23.59068608] bias: [16.05368311] loss: 30.550911977212007\n",
            "Epoch: 402 / 500 batch step: 150\n",
            "w1: [25.74502093] w2: [-23.58937732] bias: [16.09751681] loss: 30.53264563298119\n",
            "Epoch: 402 / 500 batch step: 180\n",
            "w1: [25.81286744] w2: [-23.57232942] bias: [16.20027482] loss: 30.52043457629287\n",
            "Epoch: 402 / 500 batch step: 210\n",
            "w1: [25.8499735] w2: [-23.55192061] bias: [16.25968923] loss: 30.532715306806665\n",
            "Epoch: 402 / 500 batch step: 240\n",
            "w1: [25.88912112] w2: [-23.54601404] bias: [16.30165068] loss: 30.551370129333044\n",
            "Epoch: 402 / 500 batch step: 270\n",
            "w1: [25.90555891] w2: [-23.54615075] bias: [16.31873118] loss: 30.561112303016422\n",
            "Epoch: 402 / 500 batch step: 300\n",
            "w1: [25.88575014] w2: [-23.55244892] bias: [16.27952523] loss: 30.542650277615948\n",
            "Epoch: 402 / 500 batch step: 330\n",
            "w1: [25.84949231] w2: [-23.56514581] bias: [16.2079982] loss: 30.52257393578659\n",
            "Epoch: 402 / 500 batch step: 360\n",
            "w1: [25.86094394] w2: [-23.53551116] bias: [16.29760838] loss: 30.546442563351263\n",
            "Epoch: 402 / 500 batch step: 390\n",
            "w1: [25.83540186] w2: [-23.54706852] bias: [16.26374766] loss: 30.532507991109107\n",
            "Epoch: 402 / 500 batch step: 420\n",
            "w1: [25.78628278] w2: [-23.59015198] bias: [16.16931777] loss: 30.52005069659269\n",
            "Epoch: 402 / 500 batch step: 450\n",
            "w1: [25.76107783] w2: [-23.60764807] bias: [16.12644637] loss: 30.52630870868852\n",
            "Epoch: 402 / 500 batch step: 480\n",
            "w1: [25.74397306] w2: [-23.60926967] bias: [16.10001652] loss: 30.533518316402272\n",
            "Epoch: 403 / 500 batch step: 0\n",
            "w1: [25.73761553] w2: [-23.6102213] bias: [16.08675729] loss: 30.537767824597065\n",
            "Epoch: 403 / 500 batch step: 30\n",
            "w1: [25.73073293] w2: [-23.61031926] bias: [16.07303964] loss: 30.542740251472427\n",
            "Epoch: 403 / 500 batch step: 60\n",
            "w1: [25.7089324] w2: [-23.61746546] bias: [16.03147612] loss: 30.56252219748931\n",
            "Epoch: 403 / 500 batch step: 90\n",
            "w1: [25.70242655] w2: [-23.62145078] bias: [16.0161886] loss: 30.57112322391879\n",
            "Epoch: 403 / 500 batch step: 120\n",
            "w1: [25.71228117] w2: [-23.59060855] bias: [16.05273488] loss: 30.55087269163077\n",
            "Epoch: 403 / 500 batch step: 150\n",
            "w1: [25.74679852] w2: [-23.58929936] bias: [16.09656832] loss: 30.532608973983585\n",
            "Epoch: 403 / 500 batch step: 180\n",
            "w1: [25.8146422] w2: [-23.57225153] bias: [16.19932281] loss: 30.520401708258326\n",
            "Epoch: 403 / 500 batch step: 210\n",
            "w1: [25.85174539] w2: [-23.55184265] bias: [16.25873413] loss: 30.532682244500364\n",
            "Epoch: 403 / 500 batch step: 240\n",
            "w1: [25.89088999] w2: [-23.54593641] bias: [16.30069222] loss: 30.551336496459466\n",
            "Epoch: 403 / 500 batch step: 270\n",
            "w1: [25.90732589] w2: [-23.54607324] bias: [16.31777023] loss: 30.561077646763028\n",
            "Epoch: 403 / 500 batch step: 300\n",
            "w1: [25.88751696] w2: [-23.55237119] bias: [16.27856453] loss: 30.542616391930395\n",
            "Epoch: 403 / 500 batch step: 330\n",
            "w1: [25.85125927] w2: [-23.56506785] bias: [16.20703815] loss: 30.522541444079774\n",
            "Epoch: 403 / 500 batch step: 360\n",
            "w1: [25.86271086] w2: [-23.53543079] bias: [16.29665204] loss: 30.546407721096006\n",
            "Epoch: 403 / 500 batch step: 390\n",
            "w1: [25.83716949] w2: [-23.5469862] bias: [16.26279429] loss: 30.532474095509194\n",
            "Epoch: 403 / 500 batch step: 420\n",
            "w1: [25.78805051] w2: [-23.59006944] bias: [16.16836483] loss: 30.520017592464654\n",
            "Epoch: 403 / 500 batch step: 450\n",
            "w1: [25.76284539] w2: [-23.60756542] bias: [16.12549355] loss: 30.526275625895614\n",
            "Epoch: 403 / 500 batch step: 480\n",
            "w1: [25.74574121] w2: [-23.60918605] bias: [16.09906556] loss: 30.53348409127215\n",
            "Epoch: 404 / 500 batch step: 0\n",
            "w1: [25.73938398] w2: [-23.61013709] bias: [16.08580742] loss: 30.53773298306195\n",
            "Epoch: 404 / 500 batch step: 30\n",
            "w1: [25.73250177] w2: [-23.6102344] bias: [16.072091] loss: 30.542704559601717\n",
            "Epoch: 404 / 500 batch step: 60\n",
            "w1: [25.71070118] w2: [-23.61738045] bias: [16.03052772] loss: 30.562485429751312\n",
            "Epoch: 404 / 500 batch step: 90\n",
            "w1: [25.70419464] w2: [-23.62136564] bias: [16.0152396] loss: 30.57108667285345\n",
            "Epoch: 404 / 500 batch step: 120\n",
            "w1: [25.71405023] w2: [-23.59052169] bias: [16.05178864] loss: 30.550833795739596\n",
            "Epoch: 404 / 500 batch step: 150\n",
            "w1: [25.74856671] w2: [-23.58921208] bias: [16.09562182] loss: 30.532572662217465\n",
            "Epoch: 404 / 500 batch step: 180\n",
            "w1: [25.8164076] w2: [-23.57216432] bias: [16.19837286] loss: 30.520369139411965\n",
            "Epoch: 404 / 500 batch step: 210\n",
            "w1: [25.85350795] w2: [-23.55175536] bias: [16.25778111] loss: 30.532649484716465\n",
            "Epoch: 404 / 500 batch step: 240\n",
            "w1: [25.89264956] w2: [-23.54584945] bias: [16.29973588] loss: 30.551303170746156\n",
            "Epoch: 404 / 500 batch step: 270\n",
            "w1: [25.90908361] w2: [-23.54598639] bias: [16.31681145] loss: 30.561043316406018\n",
            "Epoch: 404 / 500 batch step: 300\n",
            "w1: [25.88927451] w2: [-23.55228411] bias: [16.27760601] loss: 30.542582830624905\n",
            "Epoch: 404 / 500 batch step: 330\n",
            "w1: [25.85301698] w2: [-23.56498056] bias: [16.20608029] loss: 30.52250925802663\n",
            "Epoch: 404 / 500 batch step: 360\n",
            "w1: [25.86446854] w2: [-23.53534112] bias: [16.29569785] loss: 30.546373223322725\n",
            "Epoch: 404 / 500 batch step: 390\n",
            "w1: [25.83892784] w2: [-23.54689464] bias: [16.26184299] loss: 30.532440514133537\n",
            "Epoch: 404 / 500 batch step: 420\n",
            "w1: [25.78980895] w2: [-23.58997768] bias: [16.16741394] loss: 30.519984786260903\n",
            "Epoch: 404 / 500 batch step: 450\n",
            "w1: [25.76460364] w2: [-23.60747356] bias: [16.12454275] loss: 30.526242847964994\n",
            "Epoch: 404 / 500 batch step: 480\n",
            "w1: [25.74750005] w2: [-23.60909322] bias: [16.09811661] loss: 30.53345018832436\n",
            "Epoch: 405 / 500 batch step: 0\n",
            "w1: [25.74114312] w2: [-23.61004368] bias: [16.08485955] loss: 30.53769847178053\n",
            "Epoch: 405 / 500 batch step: 30\n",
            "w1: [25.73426131] w2: [-23.61014035] bias: [16.07114436] loss: 30.542669205067405\n",
            "Epoch: 405 / 500 batch step: 60\n",
            "w1: [25.71246066] w2: [-23.61728625] bias: [16.02958134] loss: 30.562449003529423\n",
            "Epoch: 405 / 500 batch step: 90\n",
            "w1: [25.70595345] w2: [-23.62127131] bias: [16.01429263] loss: 30.57105045803637\n",
            "Epoch: 405 / 500 batch step: 120\n",
            "w1: [25.71580999] w2: [-23.59042567] bias: [16.05084438] loss: 30.550795282616903\n",
            "Epoch: 405 / 500 batch step: 150\n",
            "w1: [25.75032562] w2: [-23.58911564] bias: [16.09467732] loss: 30.532536691450318\n",
            "Epoch: 405 / 500 batch step: 180\n",
            "w1: [25.81816376] w2: [-23.57206794] bias: [16.19742495] loss: 30.520336864273062\n",
            "Epoch: 405 / 500 batch step: 210\n",
            "w1: [25.85526128] w2: [-23.55165891] bias: [16.25683016] loss: 30.532617021925027\n",
            "Epoch: 405 / 500 batch step: 240\n",
            "w1: [25.89439994] w2: [-23.54575332] bias: [16.29878165] loss: 30.551270146601155\n",
            "Epoch: 405 / 500 batch step: 270\n",
            "w1: [25.91083216] w2: [-23.54589038] bias: [16.31585483] loss: 30.561009306046607\n",
            "Epoch: 405 / 500 batch step: 300\n",
            "w1: [25.89102292] w2: [-23.55218788] bias: [16.27664967] loss: 30.542549587800345\n",
            "Epoch: 405 / 500 batch step: 330\n",
            "w1: [25.85476556] w2: [-23.56488409] bias: [16.20512463] loss: 30.52247737202143\n",
            "Epoch: 405 / 500 batch step: 360\n",
            "w1: [25.86621706] w2: [-23.53524233] bias: [16.29474579] loss: 30.546339063810002\n",
            "Epoch: 405 / 500 batch step: 390\n",
            "w1: [25.84067702] w2: [-23.546794] bias: [16.26089377] loss: 30.532407241291452\n",
            "Epoch: 405 / 500 batch step: 420\n",
            "w1: [25.7915582] w2: [-23.58987686] bias: [16.16646508] loss: 30.519952272563486\n",
            "Epoch: 405 / 500 batch step: 450\n",
            "w1: [25.76635269] w2: [-23.60737264] bias: [16.12359397] loss: 30.526210369351162\n",
            "Epoch: 405 / 500 batch step: 480\n",
            "w1: [25.74924968] w2: [-23.60899135] bias: [16.09716965] loss: 30.53341660173772\n",
            "Epoch: 406 / 500 batch step: 0\n",
            "w1: [25.74289306] w2: [-23.60994124] bias: [16.08391367] loss: 30.537664284806894\n",
            "Epoch: 406 / 500 batch step: 30\n",
            "w1: [25.73601164] w2: [-23.61003728] bias: [16.07019972] loss: 30.54263418182628\n",
            "Epoch: 406 / 500 batch step: 60\n",
            "w1: [25.71421096] w2: [-23.61718303] bias: [16.02863698] loss: 30.5624129127449\n",
            "Epoch: 406 / 500 batch step: 90\n",
            "w1: [25.70770308] w2: [-23.62116796] bias: [16.01334769] loss: 30.57101457347984\n",
            "Epoch: 406 / 500 batch step: 120\n",
            "w1: [25.71756055] w2: [-23.59032066] bias: [16.04990209] loss: 30.550757145506903\n",
            "Epoch: 406 / 500 batch step: 150\n",
            "w1: [25.75207535] w2: [-23.58901021] bias: [16.09373482] loss: 30.532501055604175\n",
            "Epoch: 406 / 500 batch step: 180\n",
            "w1: [25.81991077] w2: [-23.57196257] bias: [16.19647909] loss: 30.52030487750315\n",
            "Epoch: 406 / 500 batch step: 210\n",
            "w1: [25.85700551] w2: [-23.55155348] bias: [16.25588129] loss: 30.532584850739035\n",
            "Epoch: 406 / 500 batch step: 240\n",
            "w1: [25.89614124] w2: [-23.5456482] bias: [16.29782953] loss: 30.5512374185763\n",
            "Epoch: 406 / 500 batch step: 270\n",
            "w1: [25.91257166] w2: [-23.54578537] bias: [16.31490037] loss: 30.560975609934715\n",
            "Epoch: 406 / 500 batch step: 300\n",
            "w1: [25.89276229] w2: [-23.55208265] bias: [16.2756955] loss: 30.542516657706347\n",
            "Epoch: 406 / 500 batch step: 330\n",
            "w1: [25.85650511] w2: [-23.56477863] bias: [16.20417116] loss: 30.52244578060257\n",
            "Epoch: 406 / 500 batch step: 360\n",
            "w1: [25.86795654] w2: [-23.53513458] bias: [16.29379588] loss: 30.546305236490014\n",
            "Epoch: 406 / 500 batch step: 390\n",
            "w1: [25.84241713] w2: [-23.54668445] bias: [16.25994661] loss: 30.532374271436847\n",
            "Epoch: 406 / 500 batch step: 420\n",
            "w1: [25.79329836] w2: [-23.58976716] bias: [16.16551825] loss: 30.519920046094548\n",
            "Epoch: 406 / 500 batch step: 450\n",
            "w1: [25.76809265] w2: [-23.60726285] bias: [16.12264719] loss: 30.526178184650785\n",
            "Epoch: 406 / 500 batch step: 480\n",
            "w1: [25.75099022] w2: [-23.60888062] bias: [16.0962247] loss: 30.53338332583767\n",
            "Epoch: 407 / 500 batch step: 0\n",
            "w1: [25.7446339] w2: [-23.60982994] bias: [16.08296979] loss: 30.537630416343696\n",
            "Epoch: 407 / 500 batch step: 30\n",
            "w1: [25.73775288] w2: [-23.60992536] bias: [16.06925707] loss: 30.54259948398514\n",
            "Epoch: 407 / 500 batch step: 60\n",
            "w1: [25.71595218] w2: [-23.61707096] bias: [16.02769463] loss: 30.562377151469484\n",
            "Epoch: 407 / 500 batch step: 90\n",
            "w1: [25.70944364] w2: [-23.62105575] bias: [16.01240478] loss: 30.57097901334503\n",
            "Epoch: 407 / 500 batch step: 120\n",
            "w1: [25.71930203] w2: [-23.59020683] bias: [16.04896177] loss: 30.55071937781502\n",
            "Epoch: 407 / 500 batch step: 150\n",
            "w1: [25.75381601] w2: [-23.58889596] bias: [16.09279432] loss: 30.53246574875126\n",
            "Epoch: 407 / 500 batch step: 180\n",
            "w1: [25.82164873] w2: [-23.57184839] bias: [16.19553526] loss: 30.520273173901877\n",
            "Epoch: 407 / 500 batch step: 210\n",
            "w1: [25.85874071] w2: [-23.55143923] bias: [16.25493448] loss: 30.532552965910163\n",
            "Epoch: 407 / 500 batch step: 240\n",
            "w1: [25.89787355] w2: [-23.54553427] bias: [16.29687953] loss: 30.551204981363018\n",
            "Epoch: 407 / 500 batch step: 270\n",
            "w1: [25.91430221] w2: [-23.54567155] bias: [16.31394805] loss: 30.560942222464753\n",
            "Epoch: 407 / 500 batch step: 300\n",
            "w1: [25.89449271] w2: [-23.55196859] bias: [16.2747435] loss: 30.542484034737107\n",
            "Epoch: 407 / 500 batch step: 330\n",
            "w1: [25.85823572] w2: [-23.56466435] bias: [16.20321987] loss: 30.522414478448333\n",
            "Epoch: 407 / 500 batch step: 360\n",
            "w1: [25.86968708] w2: [-23.53501805] bias: [16.2928481] loss: 30.546271735444183\n",
            "Epoch: 407 / 500 batch step: 390\n",
            "w1: [25.84414828] w2: [-23.54656616] bias: [16.25900152] loss: 30.53234159916411\n",
            "Epoch: 407 / 500 batch step: 420\n",
            "w1: [25.79502953] w2: [-23.58964873] bias: [16.16457345] loss: 30.519888101712294\n",
            "Epoch: 407 / 500 batch step: 450\n",
            "w1: [25.76982362] w2: [-23.60714435] bias: [16.12170243] loss: 30.526146288598646\n",
            "Epoch: 407 / 500 batch step: 480\n",
            "w1: [25.75272177] w2: [-23.60876118] bias: [16.09528174] loss: 30.533350355092022\n",
            "Epoch: 408 / 500 batch step: 0\n",
            "w1: [25.74636574] w2: [-23.60970995] bias: [16.0820279] loss: 30.537596860737867\n",
            "Epoch: 408 / 500 batch step: 30\n",
            "w1: [25.73948513] w2: [-23.60980475] bias: [16.06831641] loss: 30.542565105796534\n",
            "Epoch: 408 / 500 batch step: 60\n",
            "w1: [25.71768441] w2: [-23.6169502] bias: [16.0267543] loss: 30.56234171392106\n",
            "Epoch: 408 / 500 batch step: 90\n",
            "w1: [25.71117523] w2: [-23.62093486] bias: [16.01146389] loss: 30.5709437719378\n",
            "Epoch: 408 / 500 batch step: 120\n",
            "w1: [25.72103451] w2: [-23.59008435] bias: [16.04802343] loss: 30.550681973103547\n",
            "Epoch: 408 / 500 batch step: 150\n",
            "w1: [25.75554769] w2: [-23.58877307] bias: [16.0918558] loss: 30.53243076510972\n",
            "Epoch: 408 / 500 batch step: 180\n",
            "w1: [25.82337776] w2: [-23.57172555] bias: [16.19459347] loss: 30.520241748402942\n",
            "Epoch: 408 / 500 batch step: 210\n",
            "w1: [25.86046701] w2: [-23.55131633] bias: [16.25398974] loss: 30.532521362324797\n",
            "Epoch: 408 / 500 batch step: 240\n",
            "w1: [25.89959698] w2: [-23.54541168] bias: [16.29593162] loss: 30.55117282978833\n",
            "Epoch: 408 / 500 batch step: 270\n",
            "w1: [25.91602391] w2: [-23.54554906] bias: [16.31299788] loss: 30.560909138171468\n",
            "Epoch: 408 / 500 batch step: 300\n",
            "w1: [25.89621429] w2: [-23.55184588] bias: [16.27379365] loss: 30.542451713427216\n",
            "Epoch: 408 / 500 batch step: 330\n",
            "w1: [25.85995749] w2: [-23.56454141] bias: [16.20227075] loss: 30.522383460372907\n",
            "Epoch: 408 / 500 batch step: 360\n",
            "w1: [25.87140878] w2: [-23.53489291] bias: [16.29190244] loss: 30.546238554899027\n",
            "Epoch: 408 / 500 batch step: 390\n",
            "w1: [25.84587056] w2: [-23.5464393] bias: [16.25805849] loss: 30.532309219204016\n",
            "Epoch: 408 / 500 batch step: 420\n",
            "w1: [25.79675183] w2: [-23.58952175] bias: [16.16363067] loss: 30.519856434406996\n",
            "Epoch: 408 / 500 batch step: 450\n",
            "w1: [25.77154569] w2: [-23.60701731] bias: [16.12075967] loss: 30.52611467606359\n",
            "Epoch: 408 / 500 batch step: 480\n",
            "w1: [25.75444442] w2: [-23.60863321] bias: [16.09434078] loss: 30.533317684106915\n",
            "Epoch: 409 / 500 batch step: 0\n",
            "w1: [25.74808869] w2: [-23.60958144] bias: [16.08108799] loss: 30.537563612476628\n",
            "Epoch: 409 / 500 batch step: 30\n",
            "w1: [25.74120849] w2: [-23.60967563] bias: [16.06737774] loss: 30.54253104165467\n",
            "Epoch: 409 / 500 batch step: 60\n",
            "w1: [25.71940777] w2: [-23.61682092] bias: [16.02581597] loss: 30.5623065944596\n",
            "Epoch: 409 / 500 batch step: 90\n",
            "w1: [25.71289795] w2: [-23.62080545] bias: [16.01052503] loss: 30.570908843704558\n",
            "Epoch: 409 / 500 batch step: 120\n",
            "w1: [25.72275811] w2: [-23.58995338] bias: [16.04708706] loss: 30.55064492508729\n",
            "Epoch: 409 / 500 batch step: 150\n",
            "w1: [25.7572705] w2: [-23.58864168] bias: [16.09091928] loss: 30.532396099039545\n",
            "Epoch: 409 / 500 batch step: 180\n",
            "w1: [25.82509796] w2: [-23.57159422] bias: [16.19365371] loss: 30.520210596070207\n",
            "Epoch: 409 / 500 batch step: 210\n",
            "w1: [25.8621845] w2: [-23.55118495] bias: [16.25304707] loss: 30.532490035000066\n",
            "Epoch: 409 / 500 batch step: 240\n",
            "w1: [25.90131163] w2: [-23.5452806] bias: [16.29498582] loss: 30.551140958810855\n",
            "Epoch: 409 / 500 batch step: 270\n",
            "w1: [25.91773685] w2: [-23.54541808] bias: [16.31204986] loss: 30.56087635172596\n",
            "Epoch: 409 / 500 batch step: 300\n",
            "w1: [25.89792713] w2: [-23.55171467] bias: [16.27284597] loss: 30.54241968844768\n",
            "Epoch: 409 / 500 batch step: 330\n",
            "w1: [25.86167054] w2: [-23.56440997] bias: [16.20132381] loss: 30.522352721322367\n",
            "Epoch: 409 / 500 batch step: 360\n",
            "w1: [25.87312173] w2: [-23.5347593] bias: [16.29095891] loss: 30.54620568922206\n",
            "Epoch: 409 / 500 batch step: 390\n",
            "w1: [25.84758408] w2: [-23.54630402] bias: [16.25711752] loss: 30.532277126419867\n",
            "Epoch: 409 / 500 batch step: 420\n",
            "w1: [25.79846534] w2: [-23.58938638] bias: [16.16268992] loss: 30.51982503929715\n",
            "Epoch: 409 / 500 batch step: 450\n",
            "w1: [25.77325898] w2: [-23.60688188] bias: [16.11981891] loss: 30.52608334204468\n",
            "Epoch: 409 / 500 batch step: 480\n",
            "w1: [25.75615829] w2: [-23.60849687] bias: [16.09340181] loss: 30.533285307622926\n",
            "Epoch: 410 / 500 batch step: 0\n",
            "w1: [25.74980285] w2: [-23.60944456] bias: [16.08015008] loss: 30.537530666183397\n",
            "Epoch: 410 / 500 batch step: 30\n",
            "w1: [25.74292307] w2: [-23.60953815] bias: [16.06644106] loss: 30.542497286091393\n",
            "Epoch: 410 / 500 batch step: 60\n",
            "w1: [25.72112236] w2: [-23.61668328] bias: [16.02487966] loss: 30.562271787583143\n",
            "Epoch: 410 / 500 batch step: 90\n",
            "w1: [25.7146119] w2: [-23.62066768] bias: [16.00958818] loss: 30.570874223228348\n",
            "Epoch: 410 / 500 batch step: 120\n",
            "w1: [25.72447292] w2: [-23.58981408] bias: [16.04615266] loss: 30.55060822762945\n",
            "Epoch: 410 / 500 batch step: 150\n",
            "w1: [25.75898455] w2: [-23.58850197] bias: [16.08998474] loss: 30.532361745038582\n",
            "Epoch: 410 / 500 batch step: 180\n",
            "w1: [25.82680941] w2: [-23.57145456] bias: [16.19271599] loss: 30.52017971209393\n",
            "Epoch: 410 / 500 batch step: 210\n",
            "w1: [25.86389327] w2: [-23.55104524] bias: [16.25210645] loss: 30.53245897908012\n",
            "Epoch: 410 / 500 batch step: 240\n",
            "w1: [25.9030176] w2: [-23.54514119] bias: [16.29404211] loss: 30.55110936351707\n",
            "Epoch: 410 / 500 batch step: 270\n",
            "w1: [25.91944113] w2: [-23.54527877] bias: [16.31110397] loss: 30.560843857931793\n",
            "Epoch: 410 / 500 batch step: 300\n",
            "w1: [25.89963132] w2: [-23.55157513] bias: [16.27190044] loss: 30.54238795460204\n",
            "Epoch: 410 / 500 batch step: 330\n",
            "w1: [25.86337495] w2: [-23.5642702] bias: [16.20037903] loss: 30.52232225637095\n",
            "Epoch: 410 / 500 batch step: 360\n",
            "w1: [25.87482605] w2: [-23.5346174] bias: [16.2900175] loss: 30.54617313291788\n",
            "Epoch: 410 / 500 batch step: 390\n",
            "w1: [25.84928892] w2: [-23.54616049] bias: [16.25617861] loss: 30.532245315803635\n",
            "Epoch: 410 / 500 batch step: 420\n",
            "w1: [25.80017017] w2: [-23.58924278] bias: [16.16175119] loss: 30.519793911625776\n",
            "Epoch: 410 / 500 batch step: 450\n",
            "w1: [25.77496357] w2: [-23.60673823] bias: [16.11888016] loss: 30.526052281667425\n",
            "Epoch: 410 / 500 batch step: 480\n",
            "w1: [25.75786345] w2: [-23.60835231] bias: [16.09246484] loss: 30.533253220511153\n",
            "Epoch: 411 / 500 batch step: 0\n",
            "w1: [25.75150832] w2: [-23.60929947] bias: [16.07921415] loss: 30.537498016614038\n",
            "Epoch: 411 / 500 batch step: 30\n",
            "w1: [25.74462895] w2: [-23.60939247] bias: [16.06550637] loss: 30.54246383377234\n",
            "Epoch: 411 / 500 batch step: 60\n",
            "w1: [25.72282826] w2: [-23.61653743] bias: [16.02394535] loss: 30.562237287923928\n",
            "Epoch: 411 / 500 batch step: 90\n",
            "w1: [25.71631719] w2: [-23.62052171] bias: [16.00865334] loss: 30.57083990522497\n",
            "Epoch: 411 / 500 batch step: 120\n",
            "w1: [25.72617904] w2: [-23.58966661] bias: [16.04522023] loss: 30.55057187473756\n",
            "Epoch: 411 / 500 batch step: 150\n",
            "w1: [25.76068991] w2: [-23.58835408] bias: [16.08905218] loss: 30.532327697738676\n",
            "Epoch: 411 / 500 batch step: 180\n",
            "w1: [25.82851222] w2: [-23.57130673] bias: [16.19178029] loss: 30.520149091787058\n",
            "Epoch: 411 / 500 batch step: 210\n",
            "w1: [25.86559343] w2: [-23.55089736] bias: [16.25116789] loss: 30.53242818983237\n",
            "Epoch: 411 / 500 batch step: 240\n",
            "w1: [25.90471498] w2: [-23.54499361] bias: [16.2931005] loss: 30.551078039117577\n",
            "Epoch: 411 / 500 batch step: 270\n",
            "w1: [25.92113686] w2: [-23.54513129] bias: [16.31016021] loss: 30.56081165172124\n",
            "Epoch: 411 / 500 batch step: 300\n",
            "w1: [25.90132696] w2: [-23.55142742] bias: [16.27095705] loss: 30.542356506822586\n",
            "Epoch: 411 / 500 batch step: 330\n",
            "w1: [25.86507081] w2: [-23.56412225] bias: [16.19943642] loss: 30.52229206071729\n",
            "Epoch: 411 / 500 batch step: 360\n",
            "w1: [25.87652181] w2: [-23.53446736] bias: [16.2890782] loss: 30.546140880624296\n",
            "Epoch: 411 / 500 batch step: 390\n",
            "w1: [25.8509852] w2: [-23.54600886] bias: [16.25524175] loss: 30.532213782472358\n",
            "Epoch: 411 / 500 batch step: 420\n",
            "w1: [25.80186641] w2: [-23.58909109] bias: [16.16081448] loss: 30.51976304675678\n",
            "Epoch: 411 / 500 batch step: 450\n",
            "w1: [25.77665957] w2: [-23.60658651] bias: [16.11794341] loss: 30.526021490180145\n",
            "Epoch: 411 / 500 batch step: 480\n",
            "w1: [25.75956003] w2: [-23.60819969] bias: [16.09152985] loss: 30.533221417769607\n",
            "Epoch: 412 / 500 batch step: 0\n",
            "w1: [25.75320519] w2: [-23.60914633] bias: [16.07828021] loss: 30.537465658653083\n",
            "Epoch: 412 / 500 batch step: 30\n",
            "w1: [25.74632623] w2: [-23.60923874] bias: [16.06457366] loss: 30.54243067949318\n",
            "Epoch: 412 / 500 batch step: 60\n",
            "w1: [25.72452558] w2: [-23.61638354] bias: [16.02301304] loss: 30.56220309024464\n",
            "Epoch: 412 / 500 batch step: 90\n",
            "w1: [25.71801389] w2: [-23.62036769] bias: [16.00772052] loss: 30.570805884539258\n",
            "Epoch: 412 / 500 batch step: 120\n",
            "w1: [25.72787657] w2: [-23.58951113] bias: [16.04428976] loss: 30.550535860559616\n",
            "Epoch: 412 / 500 batch step: 150\n",
            "w1: [25.76238671] w2: [-23.58819819] bias: [16.08812161] loss: 30.532293951901913\n",
            "Epoch: 412 / 500 batch step: 180\n",
            "w1: [25.83020649] w2: [-23.57115089] bias: [16.19084662] loss: 30.520118730581665\n",
            "Epoch: 412 / 500 batch step: 210\n",
            "w1: [25.86728507] w2: [-23.55074147] bias: [16.25023138] loss: 30.532397662644005\n",
            "Epoch: 412 / 500 batch step: 240\n",
            "w1: [25.90640387] w2: [-23.54483801] bias: [16.29216098] loss: 30.55104698094355\n",
            "Epoch: 412 / 500 batch step: 270\n",
            "w1: [25.92282412] w2: [-23.54497578] bias: [16.30921858] loss: 30.560779728151612\n",
            "Epoch: 412 / 500 batch step: 300\n",
            "w1: [25.90301415] w2: [-23.55127168] bias: [16.27001581] loss: 30.542325340166723\n",
            "Epoch: 412 / 500 batch step: 330\n",
            "w1: [25.86675824] w2: [-23.56396628] bias: [16.19849596] loss: 30.522262129680893\n",
            "Epoch: 412 / 500 batch step: 360\n",
            "w1: [25.87820912] w2: [-23.53430933] bias: [16.28814101] loss: 30.546108927108666\n",
            "Epoch: 412 / 500 batch step: 390\n",
            "w1: [25.85267301] w2: [-23.54584929] bias: [16.25430694] loss: 30.532182521664485\n",
            "Epoch: 412 / 500 batch step: 420\n",
            "w1: [25.80355416] w2: [-23.58893149] bias: [16.15987978] loss: 30.519732440171456\n",
            "Epoch: 412 / 500 batch step: 450\n",
            "w1: [25.77834707] w2: [-23.60642687] bias: [16.11700866] loss: 30.52599096295045\n",
            "Epoch: 412 / 500 batch step: 480\n",
            "w1: [25.7612481] w2: [-23.60803917] bias: [16.09059685] loss: 30.533189894519527\n",
            "Epoch: 413 / 500 batch step: 0\n",
            "w1: [25.75489356] w2: [-23.60898529] bias: [16.07734824] loss: 30.537433587310097\n",
            "Epoch: 413 / 500 batch step: 30\n",
            "w1: [25.74801502] w2: [-23.60907712] bias: [16.06364293] loss: 30.542397818175935\n",
            "Epoch: 413 / 500 batch step: 60\n",
            "w1: [25.72621441] w2: [-23.61622176] bias: [16.02208273] loss: 30.562169189434744\n",
            "Epoch: 413 / 500 batch step: 90\n",
            "w1: [25.71970212] w2: [-23.62020578] bias: [16.00678972] loss: 30.570772156141413\n",
            "Epoch: 413 / 500 batch step: 120\n",
            "w1: [25.7295656] w2: [-23.58934779] bias: [16.04336126] loss: 30.550500179380204\n",
            "Epoch: 413 / 500 batch step: 150\n",
            "w1: [25.76407502] w2: [-23.58803443] bias: [16.08719303] loss: 30.53226050241698\n",
            "Epoch: 413 / 500 batch step: 180\n",
            "w1: [25.83189231] w2: [-23.57098718] bias: [16.18991497] loss: 30.52008862402552\n",
            "Epoch: 413 / 500 batch step: 210\n",
            "w1: [25.86896829] w2: [-23.55057772] bias: [16.24929692] loss: 30.53236739301845\n",
            "Epoch: 413 / 500 batch step: 240\n",
            "w1: [25.90808437] w2: [-23.54467455] bias: [16.29122353] loss: 30.55101618444325\n",
            "Epoch: 413 / 500 batch step: 270\n",
            "w1: [25.92450301] w2: [-23.54481241] bias: [16.30827907] loss: 30.560748082401734\n",
            "Epoch: 413 / 500 batch step: 300\n",
            "w1: [25.90469298] w2: [-23.55110808] bias: [16.2690767] loss: 30.542294449813422\n",
            "Epoch: 413 / 500 batch step: 330\n",
            "w1: [25.86843731] w2: [-23.56380245] bias: [16.19755766] loss: 30.52223245869862\n",
            "Epoch: 413 / 500 batch step: 360\n",
            "w1: [25.87988808] w2: [-23.53414348] bias: [16.28720593] loss: 30.54607726726426\n",
            "Epoch: 413 / 500 batch step: 390\n",
            "w1: [25.85435243] w2: [-23.54568192] bias: [16.25337418] loss: 30.532151528736478\n",
            "Epoch: 413 / 500 batch step: 420\n",
            "w1: [25.80523351] w2: [-23.58876411] bias: [16.1589471] loss: 30.519702087465113\n",
            "Epoch: 413 / 500 batch step: 450\n",
            "w1: [25.78002616] w2: [-23.60625947] bias: [16.1160759] loss: 30.525960695461787\n",
            "Epoch: 413 / 500 batch step: 480\n",
            "w1: [25.76292776] w2: [-23.60787089] bias: [16.08966584] loss: 30.53315864600195\n",
            "Epoch: 414 / 500 batch step: 0\n",
            "w1: [25.75657352] w2: [-23.6088165] bias: [16.07641826] loss: 30.537401797716207\n",
            "Epoch: 414 / 500 batch step: 30\n",
            "w1: [25.74969541] w2: [-23.60890777] bias: [16.06271418] loss: 30.54236524486553\n",
            "Epoch: 414 / 500 batch step: 60\n",
            "w1: [25.72789485] w2: [-23.61605224] bias: [16.02115442] loss: 30.562135580506954\n",
            "Epoch: 414 / 500 batch step: 90\n",
            "w1: [25.72138197] w2: [-23.62003613] bias: [16.00586091] loss: 30.570738715123557\n",
            "Epoch: 414 / 500 batch step: 120\n",
            "w1: [25.73124623] w2: [-23.58917673] bias: [16.04243472] loss: 30.55046482561684\n",
            "Epoch: 414 / 500 batch step: 150\n",
            "w1: [25.76575494] w2: [-23.58786296] bias: [16.08626641] loss: 30.53222734429566\n",
            "Epoch: 414 / 500 batch step: 180\n",
            "w1: [25.83356977] w2: [-23.57081577] bias: [16.18898534] loss: 30.520058767778753\n",
            "Epoch: 414 / 500 batch step: 210\n",
            "w1: [25.87064317] w2: [-23.55040625] bias: [16.24836451] loss: 30.532337376572094\n",
            "Epoch: 414 / 500 batch step: 240\n",
            "w1: [25.90975656] w2: [-23.54450338] bias: [16.29028817] loss: 30.55098564517868\n",
            "Epoch: 414 / 500 batch step: 270\n",
            "w1: [25.92617363] w2: [-23.54464133] bias: [16.30734168] loss: 30.560716709768524\n",
            "Epoch: 414 / 500 batch step: 300\n",
            "w1: [25.90636354] w2: [-23.55093676] bias: [16.26813973] loss: 30.542263831059795\n",
            "Epoch: 414 / 500 batch step: 330\n",
            "w1: [25.87010812] w2: [-23.56363089] bias: [16.1966215] loss: 30.52220304332134\n",
            "Epoch: 414 / 500 batch step: 360\n",
            "w1: [25.88155876] w2: [-23.53396994] bias: [16.28627295] loss: 30.54604589610679\n",
            "Epoch: 414 / 500 batch step: 390\n",
            "w1: [25.85602356] w2: [-23.54550692] bias: [16.25244346] loss: 30.532120799159422\n",
            "Epoch: 414 / 500 batch step: 420\n",
            "w1: [25.80690455] w2: [-23.5885891] bias: [16.15801643] loss: 30.519671984343756\n",
            "Epoch: 414 / 500 batch step: 450\n",
            "w1: [25.78169694] w2: [-23.60608446] bias: [16.11514513] loss: 30.52593068331014\n",
            "Epoch: 414 / 500 batch step: 480\n",
            "w1: [25.76459911] w2: [-23.60769501] bias: [16.0887368] loss: 30.53312766757433\n",
            "Epoch: 415 / 500 batch step: 0\n",
            "w1: [25.75824516] w2: [-23.60864012] bias: [16.07549025] loss: 30.537370285120623\n",
            "Epoch: 415 / 500 batch step: 30\n",
            "w1: [25.75136748] w2: [-23.60873082] bias: [16.06178741] loss: 30.54233295472627\n",
            "Epoch: 415 / 500 batch step: 60\n",
            "w1: [25.72956699] w2: [-23.61587512] bias: [16.0202281] loss: 30.56210225859382\n",
            "Epoch: 415 / 500 batch step: 90\n",
            "w1: [25.72305352] w2: [-23.61985889] bias: [16.00493412] loss: 30.570705556696275\n",
            "Epoch: 415 / 500 batch step: 120\n",
            "w1: [25.73291856] w2: [-23.58899811] bias: [16.04151013] loss: 30.5504297938164\n",
            "Epoch: 415 / 500 batch step: 150\n",
            "w1: [25.76742657] w2: [-23.58768393] bias: [16.08534178] loss: 30.53219447266936\n",
            "Epoch: 415 / 500 batch step: 180\n",
            "w1: [25.83523897] w2: [-23.57063678] bias: [16.18805773] loss: 30.520029157610573\n",
            "Epoch: 415 / 500 batch step: 210\n",
            "w1: [25.87230982] w2: [-23.55022723] bias: [16.24743414] loss: 30.532307609030994\n",
            "Epoch: 415 / 500 batch step: 240\n",
            "w1: [25.91142054] w2: [-23.54432464] bias: [16.28935489] loss: 30.550955358822318\n",
            "Epoch: 415 / 500 batch step: 270\n",
            "w1: [25.92783605] w2: [-23.54446267] bias: [16.30640641] loss: 30.56068560566364\n",
            "Epoch: 415 / 500 batch step: 300\n",
            "w1: [25.90802593] w2: [-23.55075787] bias: [16.26720489] loss: 30.542233479317744\n",
            "Epoch: 415 / 500 batch step: 330\n",
            "w1: [25.87177076] w2: [-23.56345177] bias: [16.19568748] loss: 30.522173879210662\n",
            "Epoch: 415 / 500 batch step: 360\n",
            "w1: [25.88322127] w2: [-23.53378887] bias: [16.28534207] loss: 30.546014808771012\n",
            "Epoch: 415 / 500 batch step: 390\n",
            "w1: [25.8576865] w2: [-23.54532442] bias: [16.25151477] loss: 30.532090328515793\n",
            "Epoch: 415 / 500 batch step: 420\n",
            "w1: [25.80856739] w2: [-23.58840662] bias: [16.15708776] loss: 30.51964212662091\n",
            "Epoch: 415 / 500 batch step: 450\n",
            "w1: [25.7833595] w2: [-23.60590198] bias: [16.11421636] loss: 30.525900922200826\n",
            "Epoch: 415 / 500 batch step: 480\n",
            "w1: [25.76626224] w2: [-23.60751166] bias: [16.08780975] loss: 30.53309695470721\n",
            "Epoch: 416 / 500 batch step: 0\n",
            "w1: [25.75990858] w2: [-23.60845628] bias: [16.07456422] loss: 30.537339044887407\n",
            "Epoch: 416 / 500 batch step: 30\n",
            "w1: [25.75303133] w2: [-23.60854643] bias: [16.06086261] loss: 30.542300943038573\n",
            "Epoch: 416 / 500 batch step: 60\n",
            "w1: [25.73123092] w2: [-23.61569055] bias: [16.01930378] loss: 30.562069218944377\n",
            "Epoch: 416 / 500 batch step: 90\n",
            "w1: [25.72471687] w2: [-23.6196742] bias: [16.00400932] loss: 30.57067267618533\n",
            "Epoch: 416 / 500 batch step: 120\n",
            "w1: [25.73458266] w2: [-23.58881207] bias: [16.04058751] loss: 30.550395078651608\n",
            "Epoch: 416 / 500 batch step: 150\n",
            "w1: [25.76909] w2: [-23.58749748] bias: [16.08441912] loss: 30.53216188278586\n",
            "Epoch: 416 / 500 batch step: 180\n",
            "w1: [25.8369] w2: [-23.57045038] bias: [16.18713213] loss: 30.519999789396145\n",
            "Epoch: 416 / 500 batch step: 210\n",
            "w1: [25.87396831] w2: [-23.55004079] bias: [16.24650581] loss: 30.532278086227723\n",
            "Epoch: 416 / 500 batch step: 240\n",
            "w1: [25.91307639] w2: [-23.54413848] bias: [16.28842368] loss: 30.55092532115393\n",
            "Epoch: 416 / 500 batch step: 270\n",
            "w1: [25.92949038] w2: [-23.5442766] bias: [16.30547324] loss: 30.56065476561024\n",
            "Epoch: 416 / 500 batch step: 300\n",
            "w1: [25.90968022] w2: [-23.55057156] bias: [16.26627216] loss: 30.54220339011075\n",
            "Epoch: 416 / 500 batch step: 330\n",
            "w1: [25.87342532] w2: [-23.56326522] bias: [16.1947556] loss: 30.522144962135766\n",
            "Epoch: 416 / 500 batch step: 360\n",
            "w1: [25.88487569] w2: [-23.53360041] bias: [16.28441328] loss: 30.545984000507424\n",
            "Epoch: 416 / 500 batch step: 390\n",
            "w1: [25.85934132] w2: [-23.54513457] bias: [16.25058813] loss: 30.532060112496268\n",
            "Epoch: 416 / 500 batch step: 420\n",
            "w1: [25.8102221] w2: [-23.58821681] bias: [16.1561611] loss: 30.51961251021452\n",
            "Epoch: 416 / 500 batch step: 450\n",
            "w1: [25.78501393] w2: [-23.60571217] bias: [16.11328957] loss: 30.52587140794532\n",
            "Epoch: 416 / 500 batch step: 480\n",
            "w1: [25.76791723] w2: [-23.607321] bias: [16.08688468] loss: 30.53306650298108\n",
            "Epoch: 417 / 500 batch step: 0\n",
            "w1: [25.76156387] w2: [-23.60826514] bias: [16.07364015] loss: 30.537308072492227\n",
            "Epoch: 417 / 500 batch step: 30\n",
            "w1: [25.75468706] w2: [-23.60835473] bias: [16.05993979] loss: 30.54226920519573\n",
            "Epoch: 417 / 500 batch step: 60\n",
            "w1: [25.73288673] w2: [-23.61549869] bias: [16.01838144] loss: 30.562036456920904\n",
            "Epoch: 417 / 500 batch step: 90\n",
            "w1: [25.72637211] w2: [-23.6194822] bias: [16.00308652] loss: 30.570640069028457\n",
            "Epoch: 417 / 500 batch step: 120\n",
            "w1: [25.73623864] w2: [-23.58861875] bias: [16.03966684] loss: 30.55036067491769\n",
            "Epoch: 417 / 500 batch step: 150\n",
            "w1: [25.77074531] w2: [-23.58730375] bias: [16.08349843] loss: 30.532129570006028\n",
            "Epoch: 417 / 500 batch step: 180\n",
            "w1: [25.83855294] w2: [-23.57025671] bias: [16.18620854] loss: 30.519970659113536\n",
            "Epoch: 417 / 500 batch step: 210\n",
            "w1: [25.87561875] w2: [-23.54984708] bias: [16.24557952] loss: 30.532248804098334\n",
            "Epoch: 417 / 500 batch step: 240\n",
            "w1: [25.91472421] w2: [-23.54394505] bias: [16.28749454] loss: 30.550895528057556\n",
            "Epoch: 417 / 500 batch step: 270\n",
            "w1: [25.9311367] w2: [-23.54408324] bias: [16.30454218] loss: 30.560624185239888\n",
            "Epoch: 417 / 500 batch step: 300\n",
            "w1: [25.91132651] w2: [-23.55037797] bias: [16.26534156] loss: 30.54217355907072\n",
            "Epoch: 417 / 500 batch step: 330\n",
            "w1: [25.87507189] w2: [-23.56307139] bias: [16.19382584] loss: 30.522116287970327\n",
            "Epoch: 417 / 500 batch step: 360\n",
            "w1: [25.88652211] w2: [-23.5334047] bias: [16.28348658] loss: 30.545953466679077\n",
            "Epoch: 417 / 500 batch step: 390\n",
            "w1: [25.86098813] w2: [-23.54493751] bias: [16.24966352] loss: 30.5320301468967\n",
            "Epoch: 417 / 500 batch step: 420\n",
            "w1: [25.81186877] w2: [-23.58801981] bias: [16.15523644] loss: 30.519583131143982\n",
            "Epoch: 417 / 500 batch step: 450\n",
            "w1: [25.78666032] w2: [-23.60551518] bias: [16.11236477] loss: 30.525842136458287\n",
            "Epoch: 417 / 500 batch step: 480\n",
            "w1: [25.76956418] w2: [-23.60712317] bias: [16.08596158] loss: 30.533036308083286\n",
            "Epoch: 418 / 500 batch step: 0\n",
            "w1: [25.76321112] w2: [-23.60806682] bias: [16.07271806] loss: 30.537277363519223\n",
            "Epoch: 418 / 500 batch step: 30\n",
            "w1: [25.75633474] w2: [-23.60815588] bias: [16.05901894] loss: 30.54223773670075\n",
            "Epoch: 418 / 500 batch step: 60\n",
            "w1: [25.73453451] w2: [-23.61529965] bias: [16.0174611] loss: 30.56200396799581\n",
            "Epoch: 418 / 500 batch step: 90\n",
            "w1: [25.72801933] w2: [-23.61928304] bias: [16.00216572] loss: 30.570607730772213\n",
            "Epoch: 418 / 500 batch step: 120\n",
            "w1: [25.73788657] w2: [-23.5884183] bias: [16.03874812] loss: 30.550326577529052\n",
            "Epoch: 418 / 500 batch step: 150\n",
            "w1: [25.77239259] w2: [-23.5871029] bias: [16.08257971] loss: 30.53209752980072\n",
            "Epoch: 418 / 500 batch step: 180\n",
            "w1: [25.84019788] w2: [-23.57005589] bias: [16.18528696] loss: 30.519941762840766\n",
            "Epoch: 418 / 500 batch step: 210\n",
            "w1: [25.87726121] w2: [-23.54964624] bias: [16.24465525] loss: 30.532219758679382\n",
            "Epoch: 418 / 500 batch step: 240\n",
            "w1: [25.91636408] w2: [-23.54374448] bias: [16.28656746] loss: 30.550865975518484\n",
            "Epoch: 418 / 500 batch step: 270\n",
            "w1: [25.9327751] w2: [-23.54388275] bias: [16.30361323] loss: 30.560593860289472\n",
            "Epoch: 418 / 500 batch step: 300\n",
            "w1: [25.91296489] w2: [-23.55017724] bias: [16.26441307] loss: 30.542143981934956\n",
            "Epoch: 418 / 500 batch step: 330\n",
            "w1: [25.87671055] w2: [-23.56287042] bias: [16.19289822] loss: 30.522087852689545\n",
            "Epoch: 418 / 500 batch step: 360\n",
            "w1: [25.88816062] w2: [-23.53320189] bias: [16.28256196] loss: 30.545923202758498\n",
            "Epoch: 418 / 500 batch step: 390\n",
            "w1: [25.862627] w2: [-23.54473338] bias: [16.24874093] loss: 30.53200042761511\n",
            "Epoch: 418 / 500 batch step: 420\n",
            "w1: [25.8135075] w2: [-23.58781575] bias: [16.15431378] loss: 30.51955398552716\n",
            "Epoch: 418 / 500 batch step: 450\n",
            "w1: [25.78829876] w2: [-23.60531115] bias: [16.11144195] loss: 30.5258131037546\n",
            "Epoch: 418 / 500 batch step: 480\n",
            "w1: [25.77120318] w2: [-23.6069183] bias: [16.08504045] loss: 30.533006365805008\n",
            "Epoch: 419 / 500 batch step: 0\n",
            "w1: [25.76485041] w2: [-23.60786148] bias: [16.07179794] loss: 30.537246913658027\n",
            "Epoch: 419 / 500 batch step: 30\n",
            "w1: [25.75797446] w2: [-23.60795] bias: [16.05810005] loss: 30.542206533163363\n",
            "Epoch: 419 / 500 batch step: 60\n",
            "w1: [25.73617434] w2: [-23.6150936] bias: [16.01654273] loss: 30.561971747748597\n",
            "Epoch: 419 / 500 batch step: 90\n",
            "w1: [25.7296586] w2: [-23.61907686] bias: [16.00124691] loss: 30.570575657069014\n",
            "Epoch: 419 / 500 batch step: 120\n",
            "w1: [25.73952656] w2: [-23.58821086] bias: [16.03783135] loss: 30.55029278151614\n",
            "Epoch: 419 / 500 batch step: 150\n",
            "w1: [25.77403194] w2: [-23.58689504] bias: [16.08166295] loss: 30.53206575774775\n",
            "Epoch: 419 / 500 batch step: 180\n",
            "w1: [25.84183492] w2: [-23.56984809] bias: [16.18436738] loss: 30.51991309675292\n",
            "Epoch: 419 / 500 batch step: 210\n",
            "w1: [25.87889578] w2: [-23.5494384] bias: [16.24373302] loss: 30.53219094610507\n",
            "Epoch: 419 / 500 batch step: 240\n",
            "w1: [25.9179961] w2: [-23.54353691] bias: [16.28564245] loss: 30.55083665962038\n",
            "Epoch: 419 / 500 batch step: 270\n",
            "w1: [25.93440566] w2: [-23.54367525] bias: [16.30268636] loss: 30.560563786598284\n",
            "Epoch: 419 / 500 batch step: 300\n",
            "w1: [25.91459544] w2: [-23.54996952] bias: [16.26348669] loss: 30.542114654543205\n",
            "Epoch: 419 / 500 batch step: 330\n",
            "w1: [25.8783414] w2: [-23.56266245] bias: [16.19197272] loss: 30.52205965236725\n",
            "Epoch: 419 / 500 batch step: 360\n",
            "w1: [25.8897913] w2: [-23.53299211] bias: [16.28163943] loss: 30.54589320432464\n",
            "Epoch: 419 / 500 batch step: 390\n",
            "w1: [25.86425803] w2: [-23.54452232] bias: [16.24782037] loss: 30.531970950648812\n",
            "Epoch: 419 / 500 batch step: 420\n",
            "w1: [25.81513836] w2: [-23.58760478] bias: [16.15339311] loss: 30.51952506957766\n",
            "Epoch: 419 / 500 batch step: 450\n",
            "w1: [25.78992932] w2: [-23.60510021] bias: [16.11052112] loss: 30.52578430594652\n",
            "Epoch: 419 / 500 batch step: 480\n",
            "w1: [25.7728343] w2: [-23.60670653] bias: [16.08412129] loss: 30.532976672038398\n",
            "Epoch: 420 / 500 batch step: 0\n",
            "w1: [25.76648183] w2: [-23.60764925] bias: [16.07087978] loss: 30.53721671870083\n",
            "Epoch: 420 / 500 batch step: 30\n",
            "w1: [25.75960632] w2: [-23.60773724] bias: [16.05718313] loss: 30.54217559029705\n",
            "Epoch: 420 / 500 batch step: 60\n",
            "w1: [25.73780631] w2: [-23.61488065] bias: [16.01562635] loss: 30.56193979186288\n",
            "Epoch: 420 / 500 batch step: 90\n",
            "w1: [25.73129003] w2: [-23.6188638] bias: [16.0003301] loss: 30.570543843674162\n",
            "Epoch: 420 / 500 batch step: 120\n",
            "w1: [25.74115868] w2: [-23.58799655] bias: [16.03691654] loss: 30.550259282022317\n",
            "Epoch: 420 / 500 batch step: 150\n",
            "w1: [25.77566343] w2: [-23.58668033] bias: [16.08074816] loss: 30.532034249528937\n",
            "Epoch: 420 / 500 batch step: 180\n",
            "w1: [25.84346413] w2: [-23.56963342] bias: [16.1834498] loss: 30.519884657119373\n",
            "Epoch: 420 / 500 batch step: 210\n",
            "w1: [25.88052255] w2: [-23.54922371] bias: [16.24281281] loss: 30.532162362604435\n",
            "Epoch: 420 / 500 batch step: 240\n",
            "w1: [25.91962033] w2: [-23.54332249] bias: [16.28471949] loss: 30.550807576542507\n",
            "Epoch: 420 / 500 batch step: 270\n",
            "w1: [25.93602846] w2: [-23.54346089] bias: [16.30176159] loss: 30.56053396010513\n",
            "Epoch: 420 / 500 batch step: 300\n",
            "w1: [25.91621825] w2: [-23.54975492] bias: [16.26256241] loss: 30.542085572834786\n",
            "Epoch: 420 / 500 batch step: 330\n",
            "w1: [25.8799645] w2: [-23.56244762] bias: [16.19104933] loss: 30.52203168317311\n",
            "Epoch: 420 / 500 batch step: 360\n",
            "w1: [25.89141423] w2: [-23.5327755] bias: [16.28071897] loss: 30.54586346706001\n",
            "Epoch: 420 / 500 batch step: 390\n",
            "w1: [25.86588129] w2: [-23.54430446] bias: [16.24690184] loss: 30.53194171209167\n",
            "Epoch: 420 / 500 batch step: 420\n",
            "w1: [25.81676145] w2: [-23.58738703] bias: [16.15247444] loss: 30.51949637960201\n",
            "Epoch: 420 / 500 batch step: 450\n",
            "w1: [25.7915521] w2: [-23.60488249] bias: [16.10960226] loss: 30.525755739240914\n",
            "Epoch: 420 / 500 batch step: 480\n",
            "w1: [25.77445764] w2: [-23.60648799] bias: [16.08320411] loss: 30.532947222773714\n",
            "Epoch: 421 / 500 batch step: 0\n",
            "w1: [25.76810546] w2: [-23.60743025] bias: [16.06996358] loss: 30.53718677453949\n",
            "Epoch: 421 / 500 batch step: 30\n",
            "w1: [25.7612304] w2: [-23.60751772] bias: [16.05626817] loss: 30.542144903916146\n",
            "Epoch: 421 / 500 batch step: 60\n",
            "w1: [25.73943051] w2: [-23.61466096] bias: [16.01471194] loss: 30.561908096123528\n",
            "Epoch: 421 / 500 batch step: 90\n",
            "w1: [25.73291369] w2: [-23.61864398] bias: [15.99941527] loss: 30.570512286443005\n",
            "Epoch: 421 / 500 batch step: 120\n",
            "w1: [25.74278301] w2: [-23.58777552] bias: [16.03600367] loss: 30.550226074300838\n",
            "Epoch: 421 / 500 batch step: 150\n",
            "w1: [25.77728716] w2: [-23.58645889] bias: [16.07983533] loss: 30.532003000927247\n",
            "Epoch: 421 / 500 batch step: 180\n",
            "w1: [25.84508559] w2: [-23.56941202] bias: [16.18253422] loss: 30.519856440301123\n",
            "Epoch: 421 / 500 batch step: 210\n",
            "w1: [25.88214161] w2: [-23.54900229] bias: [16.24189463] loss: 30.53213400449865\n",
            "Epoch: 421 / 500 batch step: 240\n",
            "w1: [25.92123687] w2: [-23.54310133] bias: [16.28379858] loss: 30.550778722557023\n",
            "Epoch: 421 / 500 batch step: 270\n",
            "w1: [25.93764359] w2: [-23.54323981] bias: [16.30083891] loss: 30.560504376845596\n",
            "Epoch: 421 / 500 batch step: 300\n",
            "w1: [25.91783339] w2: [-23.5495336] bias: [16.26164024] loss: 30.542056732845836\n",
            "Epoch: 421 / 500 batch step: 330\n",
            "w1: [25.88157995] w2: [-23.56222605] bias: [16.19012805] loss: 30.522003941369903\n",
            "Epoch: 421 / 500 batch step: 360\n",
            "w1: [25.8930295] w2: [-23.53255218] bias: [16.27980058] loss: 30.54583398674783\n",
            "Epoch: 421 / 500 batch step: 390\n",
            "w1: [25.86749687] w2: [-23.54407994] bias: [16.24598532] loss: 30.531912708131298\n",
            "Epoch: 421 / 500 batch step: 420\n",
            "w1: [25.81837684] w2: [-23.58716263] bias: [16.15155776] loss: 30.51946791199706\n",
            "Epoch: 421 / 500 batch step: 450\n",
            "w1: [25.79316718] w2: [-23.60465814] bias: [16.10868537] loss: 30.525727399936596\n",
            "Epoch: 421 / 500 batch step: 480\n",
            "w1: [25.77607327] w2: [-23.60626283] bias: [16.08228888] loss: 30.532918014096623\n",
            "Epoch: 422 / 500 batch step: 0\n",
            "w1: [25.76972139] w2: [-23.60720464] bias: [16.06904934] loss: 30.537157077162817\n",
            "Epoch: 422 / 500 batch step: 30\n",
            "w1: [25.76284677] w2: [-23.60729159] bias: [16.05535517] loss: 30.54211446993315\n",
            "Epoch: 422 / 500 batch step: 60\n",
            "w1: [25.74104702] w2: [-23.61443464] bias: [16.01379952] loss: 30.561876656413908\n",
            "Epoch: 422 / 500 batch step: 90\n",
            "w1: [25.73452967] w2: [-23.61841754] bias: [15.99850242] loss: 30.570480981328192\n",
            "Epoch: 422 / 500 batch step: 120\n",
            "w1: [25.74439965] w2: [-23.58754789] bias: [16.03509274] loss: 30.550193153711994\n",
            "Epoch: 422 / 500 batch step: 150\n",
            "w1: [25.7789032] w2: [-23.58623086] bias: [16.07892446] loss: 30.531972007824024\n",
            "Epoch: 422 / 500 batch step: 180\n",
            "w1: [25.8466994] w2: [-23.56918403] bias: [16.18162064] loss: 30.519828442748132\n",
            "Epoch: 422 / 500 batch step: 210\n",
            "w1: [25.88375302] w2: [-23.54877427] bias: [16.24097846] loss: 30.53210586819846\n",
            "Epoch: 422 / 500 batch step: 240\n",
            "w1: [25.9228458] w2: [-23.54287358] bias: [16.28287973] loss: 30.550750094026313\n",
            "Epoch: 422 / 500 batch step: 270\n",
            "w1: [25.93925114] w2: [-23.54301212] bias: [16.29991831] loss: 30.56047503294932\n",
            "Epoch: 422 / 500 batch step: 300\n",
            "w1: [25.91944095] w2: [-23.54930567] bias: [16.26072015] loss: 30.542028130706598\n",
            "Epoch: 422 / 500 batch step: 330\n",
            "w1: [25.88318782] w2: [-23.56199789] bias: [16.18920888] loss: 30.52197642331089\n",
            "Epoch: 422 / 500 batch step: 360\n",
            "w1: [25.8946372] w2: [-23.5323223] bias: [16.27888425] loss: 30.54580475926925\n",
            "Epoch: 422 / 500 batch step: 390\n",
            "w1: [25.86910485] w2: [-23.54384888] bias: [16.24507081] loss: 30.531883935046505\n",
            "Epoch: 422 / 500 batch step: 420\n",
            "w1: [25.81998462] w2: [-23.58693171] bias: [16.15064306] loss: 30.519439663247404\n",
            "Epoch: 422 / 500 batch step: 450\n",
            "w1: [25.79477464] w2: [-23.60442727] bias: [16.10777046] loss: 30.525699284421716\n",
            "Epoch: 422 / 500 batch step: 480\n",
            "w1: [25.77768129] w2: [-23.60603116] bias: [16.08137562] loss: 30.53288904218553\n",
            "Epoch: 423 / 500 batch step: 0\n",
            "w1: [25.7713297] w2: [-23.60697252] bias: [16.06813706] loss: 30.53712762265392\n",
            "Epoch: 423 / 500 batch step: 30\n",
            "w1: [25.76445553] w2: [-23.60705896] bias: [16.05444413] loss: 30.542084284355955\n",
            "Epoch: 423 / 500 batch step: 60\n",
            "w1: [25.74265592] w2: [-23.61420183] bias: [16.01288906] loss: 30.56184546871316\n",
            "Epoch: 423 / 500 batch step: 90\n",
            "w1: [25.73613805] w2: [-23.61818461] bias: [15.99759156] loss: 30.570449924376987\n",
            "Epoch: 423 / 500 batch step: 120\n",
            "w1: [25.74600867] w2: [-23.5873138] bias: [16.03418375] loss: 30.55016051572024\n",
            "Epoch: 423 / 500 batch step: 150\n",
            "w1: [25.78051163] w2: [-23.58599637] bias: [16.07801555] loss: 30.531941266196288\n",
            "Epoch: 423 / 500 batch step: 180\n",
            "w1: [25.84830563] w2: [-23.56894958] bias: [16.18070904] loss: 30.51980066099681\n",
            "Epoch: 423 / 500 batch step: 210\n",
            "w1: [25.88535688] w2: [-23.5485398] bias: [16.24006431] loss: 30.53207795020154\n",
            "Epoch: 423 / 500 batch step: 240\n",
            "w1: [25.92444719] w2: [-23.54263936] bias: [16.28196292] loss: 30.550721687400458\n",
            "Epoch: 423 / 500 batch step: 270\n",
            "w1: [25.94085117] w2: [-23.54277797] bias: [16.29899978] loss: 30.56044592463739\n",
            "Epoch: 423 / 500 batch step: 300\n",
            "w1: [25.92104101] w2: [-23.54907128] bias: [16.25980216] loss: 30.541999762638795\n",
            "Epoch: 423 / 500 batch step: 330\n",
            "w1: [25.8847882] w2: [-23.56176325] bias: [16.18829181] loss: 30.521949125437242\n",
            "Epoch: 423 / 500 batch step: 360\n",
            "w1: [25.89623739] w2: [-23.53208598] bias: [16.27796999] loss: 30.545775780600717\n",
            "Epoch: 423 / 500 batch step: 390\n",
            "w1: [25.87070531] w2: [-23.54361142] bias: [16.24415832] loss: 30.531855389204708\n",
            "Epoch: 423 / 500 batch step: 420\n",
            "w1: [25.82158487] w2: [-23.58669441] bias: [16.14973035] loss: 30.51941162992286\n",
            "Epoch: 423 / 500 batch step: 450\n",
            "w1: [25.79637456] w2: [-23.60419003] bias: [16.10685752] loss: 30.525671389171244\n",
            "Epoch: 423 / 500 batch step: 480\n",
            "w1: [25.77928176] w2: [-23.60579312] bias: [16.08046432] loss: 30.532860303309004\n",
            "Epoch: 424 / 500 batch step: 0\n",
            "w1: [25.77293046] w2: [-23.60673404] bias: [16.06722674] loss: 30.537098407187536\n",
            "Epoch: 424 / 500 batch step: 30\n",
            "w1: [25.76605675] w2: [-23.60681998] bias: [16.05353505] loss: 30.54205434328526\n",
            "Epoch: 424 / 500 batch step: 60\n",
            "w1: [25.74425729] w2: [-23.61396266] bias: [16.01198057] loss: 30.5618145290936\n",
            "Epoch: 424 / 500 batch step: 90\n",
            "w1: [25.7377389] w2: [-23.61794531] bias: [15.99668267] loss: 30.570419111728686\n",
            "Epoch: 424 / 500 batch step: 120\n",
            "w1: [25.74761015] w2: [-23.58707337] bias: [16.03327671] loss: 30.550128155891436\n",
            "Epoch: 424 / 500 batch step: 150\n",
            "w1: [25.78211255] w2: [-23.58575553] bias: [16.07710859] loss: 30.531910772114145\n",
            "Epoch: 424 / 500 batch step: 180\n",
            "w1: [25.84990437] w2: [-23.56870878] bias: [16.17979944] loss: 30.519773091667577\n",
            "Epoch: 424 / 500 batch step: 210\n",
            "w1: [25.88695327] w2: [-23.54829898] bias: [16.23915216] loss: 30.532050247090112\n",
            "Epoch: 424 / 500 batch step: 240\n",
            "w1: [25.92604114] w2: [-23.54239881] bias: [16.28104815] loss: 30.550693499214752\n",
            "Epoch: 424 / 500 batch step: 270\n",
            "w1: [25.94244378] w2: [-23.54253747] bias: [16.29808333] loss: 30.560417048219794\n",
            "Epoch: 424 / 500 batch step: 300\n",
            "w1: [25.92263365] w2: [-23.54883055] bias: [16.25888625] loss: 30.54197162495312\n",
            "Epoch: 424 / 500 batch step: 330\n",
            "w1: [25.88638117] w2: [-23.56152227] bias: [16.18737684] loss: 30.5219220442756\n",
            "Epoch: 424 / 500 batch step: 360\n",
            "w1: [25.89783016] w2: [-23.53184335] bias: [16.27705779] loss: 30.545747046811396\n",
            "Epoch: 424 / 500 batch step: 390\n",
            "w1: [25.87229834] w2: [-23.54336768] bias: [16.24324784] loss: 30.531827067059467\n",
            "Epoch: 424 / 500 batch step: 420\n",
            "w1: [25.82317767] w2: [-23.58645084] bias: [16.14881962] loss: 30.519383808676068\n",
            "Epoch: 424 / 500 batch step: 450\n",
            "w1: [25.79796703] w2: [-23.60394652] bias: [16.10594654] loss: 30.525643710744507\n",
            "Epoch: 424 / 500 batch step: 480\n",
            "w1: [25.78087478] w2: [-23.60554882] bias: [16.07955498] loss: 30.5328317938233\n",
            "Epoch: 425 / 500 batch step: 0\n",
            "w1: [25.77452377] w2: [-23.60648931] bias: [16.06631837] loss: 30.53706942702757\n",
            "Epoch: 425 / 500 batch step: 30\n",
            "w1: [25.76765051] w2: [-23.60657476] bias: [16.05262791] loss: 30.542024642912036\n",
            "Epoch: 425 / 500 batch step: 60\n",
            "w1: [25.74585122] w2: [-23.61371724] bias: [16.01107406] loss: 30.561783833718135\n",
            "Epoch: 425 / 500 batch step: 90\n",
            "w1: [25.73933231] w2: [-23.61769978] bias: [15.99577576] loss: 30.57038853961205\n",
            "Epoch: 425 / 500 batch step: 120\n",
            "w1: [25.74920418] w2: [-23.58682672] bias: [16.0323716] loss: 30.550096069890195\n",
            "Epoch: 425 / 500 batch step: 150\n",
            "w1: [25.78370601] w2: [-23.58550849] bias: [16.07620358] loss: 30.53188052173825\n",
            "Epoch: 425 / 500 batch step: 180\n",
            "w1: [25.85149569] w2: [-23.56846177] bias: [16.17889182] loss: 30.51974573146244\n",
            "Epoch: 425 / 500 batch step: 210\n",
            "w1: [25.88854226] w2: [-23.54805196] bias: [16.23824203] loss: 30.53202275552853\n",
            "Epoch: 425 / 500 batch step: 240\n",
            "w1: [25.92762771] w2: [-23.54215204] bias: [16.28013542] loss: 30.550665526087325\n",
            "Epoch: 425 / 500 batch step: 270\n",
            "w1: [25.94402903] w2: [-23.54229076] bias: [16.29716895] loss: 30.56038840009301\n",
            "Epoch: 425 / 500 batch step: 300\n",
            "w1: [25.92421895] w2: [-23.5485836] bias: [16.25797242] loss: 30.541943714046784\n",
            "Epoch: 425 / 500 batch step: 330\n",
            "w1: [25.8879668] w2: [-23.56127508] bias: [16.18646396] loss: 30.521895176435628\n",
            "Epoch: 425 / 500 batch step: 360\n",
            "w1: [25.89941559] w2: [-23.53159453] bias: [16.27614764] loss: 30.545718554060606\n",
            "Epoch: 425 / 500 batch step: 390\n",
            "w1: [25.873884] w2: [-23.54311779] bias: [16.24233936] loss: 30.531798965148088\n",
            "Epoch: 425 / 500 batch step: 420\n",
            "w1: [25.82476309] w2: [-23.58620113] bias: [16.14791087] loss: 30.519356196240164\n",
            "Epoch: 425 / 500 batch step: 450\n",
            "w1: [25.79955212] w2: [-23.60369689] bias: [16.10503753] loss: 30.525616245782864\n",
            "Epoch: 425 / 500 batch step: 480\n",
            "w1: [25.78246042] w2: [-23.60529841] bias: [16.07864759] loss: 30.53280351016989\n",
            "Epoch: 426 / 500 batch step: 0\n",
            "w1: [25.7761097] w2: [-23.60623847] bias: [16.06541195] loss: 30.537040678524622\n",
            "Epoch: 426 / 500 batch step: 30\n",
            "w1: [25.76923689] w2: [-23.60632342] bias: [16.05172273] loss: 30.54199517951506\n",
            "Epoch: 426 / 500 batch step: 60\n",
            "w1: [25.74743777] w2: [-23.61346572] bias: [16.0101695] loss: 30.561753378837867\n",
            "Epoch: 426 / 500 batch step: 90\n",
            "w1: [25.74091836] w2: [-23.61744813] bias: [15.99487082] loss: 30.57035820434292\n",
            "Epoch: 426 / 500 batch step: 120\n",
            "w1: [25.75079084] w2: [-23.58657399] bias: [16.03146843] loss: 30.550064253477288\n",
            "Epoch: 426 / 500 batch step: 150\n",
            "w1: [25.78529212] w2: [-23.58525535] bias: [16.07530052] loss: 30.53185051131731\n",
            "Epoch: 426 / 500 batch step: 180\n",
            "w1: [25.85307967] w2: [-23.56820868] bias: [16.17798618] loss: 30.51971857716271\n",
            "Epoch: 426 / 500 batch step: 210\n",
            "w1: [25.89012393] w2: [-23.54779885] bias: [16.2373339] loss: 30.531995472260956\n",
            "Epoch: 426 / 500 batch step: 240\n",
            "w1: [25.92920699] w2: [-23.54189918] bias: [16.27922472] loss: 30.550637764716782\n",
            "Epoch: 426 / 500 batch step: 270\n",
            "w1: [25.94560701] w2: [-23.54203795] bias: [16.29625664] loss: 30.560359976737573\n",
            "Epoch: 426 / 500 batch step: 300\n",
            "w1: [25.92579698] w2: [-23.54833055] bias: [16.25706067] loss: 30.541916026401076\n",
            "Epoch: 426 / 500 batch step: 330\n",
            "w1: [25.88954517] w2: [-23.56102179] bias: [16.18555316] loss: 30.521868518607704\n",
            "Epoch: 426 / 500 batch step: 360\n",
            "w1: [25.90099376] w2: [-23.53133965] bias: [16.27523954] loss: 30.545690298595435\n",
            "Epoch: 426 / 500 batch step: 390\n",
            "w1: [25.87546238] w2: [-23.54286186] bias: [16.24143289] loss: 30.531771080089268\n",
            "Epoch: 426 / 500 batch step: 420\n",
            "w1: [25.82634122] w2: [-23.5859454] bias: [16.14700409] loss: 30.519328789426446\n",
            "Epoch: 426 / 500 batch step: 450\n",
            "w1: [25.8011299] w2: [-23.60344124] bias: [16.10413048] loss: 30.52558899100735\n",
            "Epoch: 426 / 500 batch step: 480\n",
            "w1: [25.78403875] w2: [-23.60504199] bias: [16.07774216] loss: 30.532775448873174\n",
            "Epoch: 427 / 500 batch step: 0\n",
            "w1: [25.77768832] w2: [-23.60598163] bias: [16.06450747] loss: 30.537012158113626\n",
            "Epoch: 427 / 500 batch step: 30\n",
            "w1: [25.77081597] w2: [-23.60606609] bias: [16.05081949] loss: 30.541965949458525\n",
            "Epoch: 427 / 500 batch step: 60\n",
            "w1: [25.74901703] w2: [-23.6132082] bias: [16.00926691] loss: 30.561723160789654\n",
            "Epoch: 427 / 500 batch step: 90\n",
            "w1: [25.74249713] w2: [-23.6171905] bias: [15.99396785] loss: 30.5703281023218\n",
            "Epoch: 427 / 500 batch step: 120\n",
            "w1: [25.75237019] w2: [-23.58631528] bias: [16.03056719] loss: 30.550032702507096\n",
            "Epoch: 427 / 500 batch step: 150\n",
            "w1: [25.78687093] w2: [-23.58499625] bias: [16.0743994] loss: 30.53182073718572\n",
            "Epoch: 427 / 500 batch step: 180\n",
            "w1: [25.85465638] w2: [-23.56794961] bias: [16.17708253] loss: 30.519691625626727\n",
            "Epoch: 427 / 500 batch step: 210\n",
            "w1: [25.89169836] w2: [-23.54753977] bias: [16.23642778] loss: 30.531968394109104\n",
            "Epoch: 427 / 500 batch step: 240\n",
            "w1: [25.93077904] w2: [-23.54164035] bias: [16.27831605] loss: 30.550610211879988\n",
            "Epoch: 427 / 500 batch step: 270\n",
            "w1: [25.94717779] w2: [-23.54177918] bias: [16.29534638] loss: 30.560331774715745\n",
            "Epoch: 427 / 500 batch step: 300\n",
            "w1: [25.92736781] w2: [-23.54807153] bias: [16.25615099] loss: 30.541888558579114\n",
            "Epoch: 427 / 500 batch step: 330\n",
            "w1: [25.89111635] w2: [-23.56076252] bias: [16.18464445] loss: 30.521842067560662\n",
            "Epoch: 427 / 500 batch step: 360\n",
            "w1: [25.90256473] w2: [-23.53107882] bias: [16.27433349] loss: 30.545662276748335\n",
            "Epoch: 427 / 500 batch step: 390\n",
            "w1: [25.87703356] w2: [-23.54260002] bias: [16.24052841] loss: 30.531743408580866\n",
            "Epoch: 427 / 500 batch step: 420\n",
            "w1: [25.82791213] w2: [-23.58568378] bias: [16.14609929] loss: 30.519301585122246\n",
            "Epoch: 427 / 500 batch step: 450\n",
            "w1: [25.80270046] w2: [-23.6031797] bias: [16.10322539] loss: 30.5255619432165\n",
            "Epoch: 427 / 500 batch step: 480\n",
            "w1: [25.78560985] w2: [-23.60477968] bias: [16.07683867] loss: 30.532747606538155\n",
            "Epoch: 428 / 500 batch step: 0\n",
            "w1: [25.77925972] w2: [-23.60571891] bias: [16.06360494] loss: 30.53698386231154\n",
            "Epoch: 428 / 500 batch step: 30\n",
            "w1: [25.77238783] w2: [-23.6058029] bias: [16.0499182] loss: 30.541936949189726\n",
            "Epoch: 428 / 500 batch step: 60\n",
            "w1: [25.75058907] w2: [-23.61294481] bias: [16.00836627] loss: 30.561693175993764\n",
            "Epoch: 428 / 500 batch step: 90\n",
            "w1: [25.74406868] w2: [-23.61692699] bias: [15.99306685] loss: 30.57029823003155\n",
            "Epoch: 428 / 500 batch step: 120\n",
            "w1: [25.75394231] w2: [-23.58605073] bias: [16.02966788] loss: 30.550001412925205\n",
            "Epoch: 428 / 500 batch step: 150\n",
            "w1: [25.78844254] w2: [-23.5847313] bias: [16.07350023] loss: 30.531791195761283\n",
            "Epoch: 428 / 500 batch step: 180\n",
            "w1: [25.85622591] w2: [-23.56768469] bias: [16.17618085] loss: 30.51966487378774\n",
            "Epoch: 428 / 500 batch step: 210\n",
            "w1: [25.89326562] w2: [-23.54727485] bias: [16.23552365] loss: 30.531941517970086\n",
            "Epoch: 428 / 500 batch step: 240\n",
            "w1: [25.93234396] w2: [-23.54137567] bias: [16.27740941] loss: 30.550582864429813\n",
            "Epoch: 428 / 500 batch step: 270\n",
            "w1: [25.94874145] w2: [-23.54151455] bias: [16.29443818] loss: 30.560303790669334\n",
            "Epoch: 428 / 500 batch step: 300\n",
            "w1: [25.92893153] w2: [-23.54780666] bias: [16.25524337] loss: 30.541861307223545\n",
            "Epoch: 428 / 500 batch step: 330\n",
            "w1: [25.89268042] w2: [-23.56049741] bias: [16.18373781] loss: 30.521815820139576\n",
            "Epoch: 428 / 500 batch step: 360\n",
            "w1: [25.90412858] w2: [-23.53081217] bias: [16.27342947] loss: 30.54563448493484\n",
            "Epoch: 428 / 500 batch step: 390\n",
            "w1: [25.8785976] w2: [-23.54233239] bias: [16.23962592] loss: 30.531715947397704\n",
            "Epoch: 428 / 500 batch step: 420\n",
            "w1: [25.82947589] w2: [-23.58541637] bias: [16.14519646] loss: 30.519274580288727\n",
            "Epoch: 428 / 500 batch step: 450\n",
            "w1: [25.80426387] w2: [-23.60291239] bias: [16.10232226] loss: 30.525535099284134\n",
            "Epoch: 428 / 500 batch step: 480\n",
            "w1: [25.78717381] w2: [-23.60451161] bias: [16.07593714] loss: 30.532719979848228\n",
            "Epoch: 429 / 500 batch step: 0\n",
            "w1: [25.78082396] w2: [-23.60545043] bias: [16.06270436] loss: 30.53695578771511\n",
            "Epoch: 429 / 500 batch step: 30\n",
            "w1: [25.77395253] w2: [-23.60553394] bias: [16.04901886] loss: 30.54190817523679\n",
            "Epoch: 429 / 500 batch step: 60\n",
            "w1: [25.75215397] w2: [-23.61267566] bias: [16.0074676] loss: 30.561663420951675\n",
            "Epoch: 429 / 500 batch step: 90\n",
            "w1: [25.7456331] w2: [-23.61665772] bias: [15.99216781] loss: 30.57026858403519\n",
            "Epoch: 429 / 500 batch step: 120\n",
            "w1: [25.75550729] w2: [-23.58578045] bias: [16.02877049] loss: 30.549970380766\n",
            "Epoch: 429 / 500 batch step: 150\n",
            "w1: [25.790007] w2: [-23.58446062] bias: [16.072603] loss: 30.531761883542895\n",
            "Epoch: 429 / 500 batch step: 180\n",
            "w1: [25.85778832] w2: [-23.56741405] bias: [16.17528114] loss: 30.519638318651737\n",
            "Epoch: 429 / 500 batch step: 210\n",
            "w1: [25.89482578] w2: [-23.54700419] bias: [16.23462151] loss: 30.531914840814274\n",
            "Epoch: 429 / 500 batch step: 240\n",
            "w1: [25.9339018] w2: [-23.54110525] bias: [16.27650479] loss: 30.550555719293076\n",
            "Epoch: 429 / 500 batch step: 270\n",
            "w1: [25.95029805] w2: [-23.54124418] bias: [16.29353203] loss: 30.560276021317446\n",
            "Epoch: 429 / 500 batch step: 300\n",
            "w1: [25.93048821] w2: [-23.54753606] bias: [16.25433782] loss: 30.541834269054373\n",
            "Epoch: 429 / 500 batch step: 330\n",
            "w1: [25.89423746] w2: [-23.56022655] bias: [16.18283324] loss: 30.521789773263656\n",
            "Epoch: 429 / 500 batch step: 360\n",
            "w1: [25.9056854] w2: [-23.5305398] bias: [16.2725275] loss: 30.545606919651345\n",
            "Epoch: 429 / 500 batch step: 390\n",
            "w1: [25.88015458] w2: [-23.54205907] bias: [16.23872543] loss: 30.53168869338943\n",
            "Epoch: 429 / 500 batch step: 420\n",
            "w1: [25.83103258] w2: [-23.5851433] bias: [16.14429559] loss: 30.519247771958824\n",
            "Epoch: 429 / 500 batch step: 450\n",
            "w1: [25.8058202] w2: [-23.60263943] bias: [16.10142108] loss: 30.525508456157297\n",
            "Epoch: 429 / 500 batch step: 480\n",
            "w1: [25.78873068] w2: [-23.60423789] bias: [16.07503754] loss: 30.53269256556306\n",
            "Epoch: 430 / 500 batch step: 0\n",
            "w1: [25.78238113] w2: [-23.60517631] bias: [16.06180571] loss: 30.536927930998694\n",
            "Epoch: 430 / 500 batch step: 30\n",
            "w1: [25.77551016] w2: [-23.60525935] bias: [16.04812145] loss: 30.541879624206523\n",
            "Epoch: 430 / 500 batch step: 60\n",
            "w1: [25.7537118] w2: [-23.61240087] bias: [16.00657087] loss: 30.561633892243854\n",
            "Epoch: 430 / 500 batch step: 90\n",
            "w1: [25.74719045] w2: [-23.61638281] bias: [15.99127073] loss: 30.570239160973657\n",
            "Epoch: 430 / 500 batch step: 120\n",
            "w1: [25.7570652] w2: [-23.58550455] bias: [16.02787503] loss: 30.549939602150335\n",
            "Epoch: 430 / 500 batch step: 150\n",
            "w1: [25.7915644] w2: [-23.58418432] bias: [16.0717077] loss: 30.531732797108393\n",
            "Epoch: 430 / 500 batch step: 180\n",
            "w1: [25.8593437] w2: [-23.56713778] bias: [16.1743834] loss: 30.51961195729542\n",
            "Epoch: 430 / 500 batch step: 210\n",
            "w1: [25.89637893] w2: [-23.54672792] bias: [16.23372137] loss: 30.531888359683247\n",
            "Epoch: 430 / 500 batch step: 240\n",
            "w1: [25.93545264] w2: [-23.54082922] bias: [16.27560219] loss: 30.55052877346844\n",
            "Epoch: 430 / 500 batch step: 270\n",
            "w1: [25.95184768] w2: [-23.5409682] bias: [16.29262793] loss: 30.560248463454425\n",
            "Epoch: 430 / 500 batch step: 300\n",
            "w1: [25.93203792] w2: [-23.54725983] bias: [16.25343432] loss: 30.54180744086689\n",
            "Epoch: 430 / 500 batch step: 330\n",
            "w1: [25.89578753] w2: [-23.55995008] bias: [16.18193075] loss: 30.52176392392417\n",
            "Epoch: 430 / 500 batch step: 360\n",
            "w1: [25.90723524] w2: [-23.53026185] bias: [16.27162755] loss: 30.54557957747292\n",
            "Epoch: 430 / 500 batch step: 390\n",
            "w1: [25.88170457] w2: [-23.5417802] bias: [16.23782692] loss: 30.53166164347847\n",
            "Epoch: 430 / 500 batch step: 420\n",
            "w1: [25.83258228] w2: [-23.58486469] bias: [16.14339668] loss: 30.519221157235243\n",
            "Epoch: 430 / 500 batch step: 450\n",
            "w1: [25.80736953] w2: [-23.60236091] bias: [16.10052184] loss: 30.525482010854198\n",
            "Epoch: 430 / 500 batch step: 480\n",
            "w1: [25.79028055] w2: [-23.60395863] bias: [16.07413989] loss: 30.53266536051646\n",
            "Epoch: 431 / 500 batch step: 0\n",
            "w1: [25.78393129] w2: [-23.60489665] bias: [16.060909] loss: 30.53690028891218\n",
            "Epoch: 431 / 500 batch step: 30\n",
            "w1: [25.77706078] w2: [-23.60497924] bias: [16.04722597] loss: 30.54185129278224\n",
            "Epoch: 431 / 500 batch step: 60\n",
            "w1: [25.75526263] w2: [-23.61212056] bias: [16.00567609] loss: 30.561604586527608\n",
            "Epoch: 431 / 500 batch step: 90\n",
            "w1: [25.74874082] w2: [-23.61610238] bias: [15.99037561] loss: 30.570209957563783\n",
            "Epoch: 431 / 500 batch step: 120\n",
            "w1: [25.7586161] w2: [-23.58522314] bias: [16.0269815] loss: 30.549909073283352\n",
            "Epoch: 431 / 500 batch step: 150\n",
            "w1: [25.79311481] w2: [-23.58390252] bias: [16.07081434] loss: 30.531703933112436\n",
            "Epoch: 431 / 500 batch step: 180\n",
            "w1: [25.86089211] w2: [-23.56685601] bias: [16.17348762] loss: 30.519585786864255\n",
            "Epoch: 431 / 500 batch step: 210\n",
            "w1: [25.89792513] w2: [-23.54644615] bias: [16.23282321] loss: 30.531862071687833\n",
            "Epoch: 431 / 500 batch step: 240\n",
            "w1: [25.93699655] w2: [-23.54054769] bias: [16.2747016] loss: 30.550502024024436\n",
            "Epoch: 431 / 500 batch step: 270\n",
            "w1: [25.9533904] w2: [-23.5406867] bias: [16.29172587] loss: 30.56022111394774\n",
            "Epoch: 431 / 500 batch step: 300\n",
            "w1: [25.93358072] w2: [-23.5469781] bias: [16.25253288] loss: 30.541780819529546\n",
            "Epoch: 431 / 500 batch step: 330\n",
            "w1: [25.89733071] w2: [-23.5596681] bias: [16.18103031] loss: 30.521738269182432\n",
            "Epoch: 431 / 500 batch step: 360\n",
            "w1: [25.90877818] w2: [-23.52997841] bias: [16.27072963] loss: 30.5455524550512\n",
            "Epoch: 431 / 500 batch step: 390\n",
            "w1: [25.88324765] w2: [-23.54149587] bias: [16.2369304] loss: 30.53163479465798\n",
            "Epoch: 431 / 500 batch step: 420\n",
            "w1: [25.83412504] w2: [-23.58458063] bias: [16.14249974] loss: 30.5191947332885\n",
            "Epoch: 431 / 500 batch step: 450\n",
            "w1: [25.80891193] w2: [-23.60207697] bias: [16.09962456] loss: 30.525455760462243\n",
            "Epoch: 431 / 500 batch step: 480\n",
            "w1: [25.79182349] w2: [-23.60367395] bias: [16.07324418] loss: 30.532638361614406\n",
            "Epoch: 432 / 500 batch step: 0\n",
            "w1: [25.78547451] w2: [-23.60461158] bias: [16.06001422] loss: 30.5368728582789\n",
            "Epoch: 432 / 500 batch step: 30\n",
            "w1: [25.77860447] w2: [-23.60469371] bias: [16.04633243] loss: 30.541823177721763\n",
            "Epoch: 432 / 500 batch step: 60\n",
            "w1: [25.75680654] w2: [-23.61183483] bias: [16.00478326] loss: 30.56157550053509\n",
            "Epoch: 432 / 500 batch step: 90\n",
            "w1: [25.75028426] w2: [-23.61581653] bias: [15.98948244] loss: 30.57018097059618\n",
            "Epoch: 432 / 500 batch step: 120\n",
            "w1: [25.76016007] w2: [-23.58493634] bias: [16.02608988] loss: 30.549878790452222\n",
            "Epoch: 432 / 500 batch step: 150\n",
            "w1: [25.7946583] w2: [-23.58361532] bias: [16.06992291] loss: 30.531675288284433\n",
            "Epoch: 432 / 500 batch step: 180\n",
            "w1: [25.86243362] w2: [-23.56656885] bias: [16.17259381] loss: 30.51955980457048\n",
            "Epoch: 432 / 500 batch step: 210\n",
            "w1: [25.89946445] w2: [-23.54615898] bias: [16.23192703] loss: 30.531835974006132\n",
            "Epoch: 432 / 500 batch step: 240\n",
            "w1: [25.93853361] w2: [-23.54026076] bias: [16.27380302] loss: 30.550475468097506\n",
            "Epoch: 432 / 500 batch step: 270\n",
            "w1: [25.95492628] w2: [-23.54039982] bias: [16.29082585] loss: 30.560193969736062\n",
            "Epoch: 432 / 500 batch step: 300\n",
            "w1: [25.9351167] w2: [-23.54669097] bias: [16.25163348] loss: 30.541754401982008\n",
            "Epoch: 432 / 500 batch step: 330\n",
            "w1: [25.89886706] w2: [-23.55938072] bias: [16.18013193] loss: 30.521712806167887\n",
            "Epoch: 432 / 500 batch step: 360\n",
            "w1: [25.9103143] w2: [-23.52968961] bias: [16.26983374] loss: 30.545525549112362\n",
            "Epoch: 432 / 500 batch step: 390\n",
            "w1: [25.88478388] w2: [-23.54120621] bias: [16.23603586] loss: 30.531608143989985\n",
            "Epoch: 432 / 500 batch step: 420\n",
            "w1: [25.83566095] w2: [-23.58429125] bias: [16.14160475] loss: 30.519168497355036\n",
            "Epoch: 432 / 500 batch step: 450\n",
            "w1: [25.81044746] w2: [-23.60178771] bias: [16.09872922] loss: 30.52542970213613\n",
            "Epoch: 432 / 500 batch step: 480\n",
            "w1: [25.79335956] w2: [-23.60338396] bias: [16.0723504] loss: 30.532611565833044\n",
            "Epoch: 433 / 500 batch step: 0\n",
            "w1: [25.78701087] w2: [-23.60432119] bias: [16.05912138] loss: 30.5368456359937\n",
            "Epoch: 433 / 500 batch step: 30\n",
            "w1: [25.78014131] w2: [-23.60440287] bias: [16.04544083] loss: 30.54179527585539\n",
            "Epoch: 433 / 500 batch step: 60\n",
            "w1: [25.7583436] w2: [-23.61154379] bias: [16.00389237] loss: 30.56154663107122\n",
            "Epoch: 433 / 500 batch step: 90\n",
            "w1: [25.75182086] w2: [-23.61552538] bias: [15.98859122] loss: 30.57015219693328\n",
            "Epoch: 433 / 500 batch step: 120\n",
            "w1: [25.76169718] w2: [-23.58464426] bias: [16.02520018] loss: 30.5498487500241\n",
            "Epoch: 433 / 500 batch step: 150\n",
            "w1: [25.79619494] w2: [-23.58332285] bias: [16.06903341] loss: 30.53164685942656\n",
            "Epoch: 433 / 500 batch step: 180\n",
            "w1: [25.8639683] w2: [-23.5662764] bias: [16.17170196] loss: 30.519534007691302\n",
            "Epoch: 433 / 500 batch step: 210\n",
            "w1: [25.90099696] w2: [-23.54586654] bias: [16.23103284] loss: 30.531810063881657\n",
            "Epoch: 433 / 500 batch step: 240\n",
            "w1: [25.94006388] w2: [-23.53996854] bias: [16.27290645] loss: 30.55044910289012\n",
            "Epoch: 433 / 500 batch step: 270\n",
            "w1: [25.9564554] w2: [-23.54010764] bias: [16.28992786] loss: 30.560167027827255\n",
            "Epoch: 433 / 500 batch step: 300\n",
            "w1: [25.93664591] w2: [-23.54639855] bias: [16.25073613] loss: 30.5417281852332\n",
            "Epoch: 433 / 500 batch step: 330\n",
            "w1: [25.90039666] w2: [-23.55908805] bias: [16.1792356] loss: 30.521687532076186\n",
            "Epoch: 433 / 500 batch step: 360\n",
            "w1: [25.91184365] w2: [-23.52939554] bias: [16.26893986] loss: 30.54549885645515\n",
            "Epoch: 433 / 500 batch step: 390\n",
            "w1: [25.88631334] w2: [-23.54091131] bias: [16.23514329] loss: 30.531581688603403\n",
            "Epoch: 433 / 500 batch step: 420\n",
            "w1: [25.83719008] w2: [-23.58399664] bias: [16.14071171] loss: 30.51914244673534\n",
            "Epoch: 433 / 500 batch step: 450\n",
            "w1: [25.8119762] w2: [-23.60149323] bias: [16.09783583] loss: 30.525403833095954\n",
            "Epoch: 433 / 500 batch step: 480\n",
            "w1: [25.79488884] w2: [-23.60308875] bias: [16.07145856] loss: 30.5325849702168\n",
            "Epoch: 434 / 500 batch step: 0\n",
            "w1: [25.78854044] w2: [-23.60402561] bias: [16.05823046] loss: 30.536818619020963\n",
            "Epoch: 434 / 500 batch step: 30\n",
            "w1: [25.78167134] w2: [-23.60410684] bias: [16.04455115] loss: 30.541767584083924\n",
            "Epoch: 434 / 500 batch step: 60\n",
            "w1: [25.75987387] w2: [-23.61124756] bias: [16.00300343] loss: 30.561517975011792\n",
            "Epoch: 434 / 500 batch step: 90\n",
            "w1: [25.75335069] w2: [-23.61522903] bias: [15.98770196] loss: 30.570123633507418\n",
            "Epoch: 434 / 500 batch step: 120\n",
            "w1: [25.7632275] w2: [-23.584347] bias: [16.0243124] loss: 30.549818948444003\n",
            "Epoch: 434 / 500 batch step: 150\n",
            "w1: [25.7977248] w2: [-23.5830252] bias: [16.06814584] loss: 30.531618643411807\n",
            "Epoch: 434 / 500 batch step: 180\n",
            "w1: [25.86549623] w2: [-23.56597878] bias: [16.17081207] loss: 30.51950839356703\n",
            "Epoch: 434 / 500 batch step: 210\n",
            "w1: [25.90252274] w2: [-23.54556892] bias: [16.23014062] loss: 30.531784338621545\n",
            "Epoch: 434 / 500 batch step: 240\n",
            "w1: [25.94158744] w2: [-23.53967116] bias: [16.27201187] loss: 30.550422925668965\n",
            "Epoch: 434 / 500 batch step: 270\n",
            "w1: [25.95797781] w2: [-23.53981029] bias: [16.28903191] loss: 30.560140285296562\n",
            "Epoch: 434 / 500 batch step: 300\n",
            "w1: [25.93816843] w2: [-23.54610096] bias: [16.24984082] loss: 30.541702166359457\n",
            "Epoch: 434 / 500 batch step: 330\n",
            "w1: [25.90191957] w2: [-23.55879021] bias: [16.17834132] loss: 30.521662444167397\n",
            "Epoch: 434 / 500 batch step: 360\n",
            "w1: [25.91336631] w2: [-23.52909632] bias: [16.268048] loss: 30.545472373948922\n",
            "Epoch: 434 / 500 batch step: 390\n",
            "w1: [25.88783609] w2: [-23.54061128] bias: [16.2342527] loss: 30.53155542569228\n",
            "Epoch: 434 / 500 batch step: 420\n",
            "w1: [25.83871248] w2: [-23.58369693] bias: [16.13982063] loss: 30.519116578792225\n",
            "Epoch: 434 / 500 batch step: 450\n",
            "w1: [25.81349823] w2: [-23.60119364] bias: [16.09694437] loss: 30.525378150625457\n",
            "Epoch: 434 / 500 batch step: 480\n",
            "w1: [25.79641139] w2: [-23.60278845] bias: [16.07056865] loss: 30.532558571876525\n",
            "Epoch: 435 / 500 batch step: 0\n",
            "w1: [25.79006328] w2: [-23.60372493] bias: [16.05734148] loss: 30.536791804392763\n",
            "Epoch: 435 / 500 batch step: 30\n",
            "w1: [25.78319466] w2: [-23.60380573] bias: [16.04366339] loss: 30.541740099376874\n",
            "Epoch: 435 / 500 batch step: 60\n",
            "w1: [25.76139742] w2: [-23.61094624] bias: [16.00211642] loss: 30.561489529301557\n",
            "Epoch: 435 / 500 batch step: 90\n",
            "w1: [25.7548738] w2: [-23.6149276] bias: [15.98681463] loss: 30.570095277318934\n",
            "Epoch: 435 / 500 batch step: 120\n",
            "w1: [25.7647511] w2: [-23.58404468] bias: [16.02342653] loss: 30.549789382232863\n",
            "Epoch: 435 / 500 batch step: 150\n",
            "w1: [25.79924795] w2: [-23.58272248] bias: [16.06726019] loss: 30.531590637182113\n",
            "Epoch: 435 / 500 batch step: 180\n",
            "w1: [25.86701747] w2: [-23.56567609] bias: [16.16992412] loss: 30.51948295959937\n",
            "Epoch: 435 / 500 batch step: 210\n",
            "w1: [25.90404184] w2: [-23.54526623] bias: [16.22925038] loss: 30.53175879559477\n",
            "Epoch: 435 / 500 batch step: 240\n",
            "w1: [25.94310434] w2: [-23.5393687] bias: [16.2711193] loss: 30.550396933763164\n",
            "Epoch: 435 / 500 batch step: 270\n",
            "w1: [25.9594936] w2: [-23.53950787] bias: [16.28813797] loss: 30.56011373928473\n",
            "Epoch: 435 / 500 batch step: 300\n",
            "w1: [25.93968433] w2: [-23.54579829] bias: [16.24894753] loss: 30.541676342502647\n",
            "Epoch: 435 / 500 batch step: 330\n",
            "w1: [25.90343586] w2: [-23.55848729] bias: [16.17744908] loss: 30.521637539764196\n",
            "Epoch: 435 / 500 batch step: 360\n",
            "w1: [25.91488235] w2: [-23.52879206] bias: [16.26715815] loss: 30.54544609853178\n",
            "Epoch: 435 / 500 batch step: 390\n",
            "w1: [25.88935221] w2: [-23.54030624] bias: [16.23336407] loss: 30.531529352513967\n",
            "Epoch: 435 / 500 batch step: 420\n",
            "w1: [25.84022824] w2: [-23.5833922] bias: [16.13893149] loss: 30.51909089094905\n",
            "Epoch: 435 / 500 batch step: 450\n",
            "w1: [25.81501359] w2: [-23.60088906] bias: [16.09605485] loss: 30.52535265207021\n",
            "Epoch: 435 / 500 batch step: 480\n",
            "w1: [25.79792729] w2: [-23.60248315] bias: [16.06968066] loss: 30.532532367987695\n",
            "Epoch: 436 / 500 batch step: 0\n",
            "w1: [25.79157947] w2: [-23.60341926] bias: [16.05645441] loss: 30.536765189207067\n",
            "Epoch: 436 / 500 batch step: 30\n",
            "w1: [25.78471132] w2: [-23.60349962] bias: [16.04277756] loss: 30.541712818770534\n",
            "Epoch: 436 / 500 batch step: 60\n",
            "w1: [25.76291433] w2: [-23.61063993] bias: [16.00123134] loss: 30.561461290952412\n",
            "Epoch: 436 / 500 batch step: 90\n",
            "w1: [25.75639027] w2: [-23.61462117] bias: [15.98592925] loss: 30.570067125434395\n",
            "Epoch: 436 / 500 batch step: 120\n",
            "w1: [25.76626804] w2: [-23.58373738] bias: [16.02254257] loss: 30.54976004798555\n",
            "Epoch: 436 / 500 batch step: 150\n",
            "w1: [25.80076446] w2: [-23.58241479] bias: [16.06637646] loss: 30.531562837746492\n",
            "Epoch: 436 / 500 batch step: 180\n",
            "w1: [25.86853209] w2: [-23.56536843] bias: [16.16903813] loss: 30.51945770324968\n",
            "Epoch: 436 / 500 batch step: 210\n",
            "w1: [25.90555435] w2: [-23.54495858] bias: [16.2283621] loss: 30.53173343223041\n",
            "Epoch: 436 / 500 batch step: 240\n",
            "w1: [25.94461466] w2: [-23.53906127] bias: [16.27022872] loss: 30.550371124562556\n",
            "Epoch: 436 / 500 batch step: 270\n",
            "w1: [25.96100281] w2: [-23.53920047] bias: [16.28724606] loss: 30.560087386996305\n",
            "Epoch: 436 / 500 batch step: 300\n",
            "w1: [25.94119367] w2: [-23.54549066] bias: [16.24805628] loss: 30.541650710868467\n",
            "Epoch: 436 / 500 batch step: 330\n",
            "w1: [25.90494559] w2: [-23.5581794] bias: [16.17655888] loss: 30.521612816250173\n",
            "Epoch: 436 / 500 batch step: 360\n",
            "w1: [25.91639183] w2: [-23.52848285] bias: [16.26627031] loss: 30.5454200272088\n",
            "Epoch: 436 / 500 batch step: 390\n",
            "w1: [25.89086174] w2: [-23.53999627] bias: [16.23247742] loss: 30.531503466387463\n",
            "Epoch: 436 / 500 batch step: 420\n",
            "w1: [25.84173741] w2: [-23.58308258] bias: [16.1380443] loss: 30.519065380688076\n",
            "Epoch: 436 / 500 batch step: 450\n",
            "w1: [25.81652237] w2: [-23.60057957] bias: [16.09516726] loss: 30.525327334835985\n",
            "Epoch: 436 / 500 batch step: 480\n",
            "w1: [25.7994366] w2: [-23.60217296] bias: [16.0687946] loss: 30.53250635578867\n",
            "Epoch: 437 / 500 batch step: 0\n",
            "w1: [25.79308906] w2: [-23.60310871] bias: [16.05556926] loss: 30.536738770625913\n",
            "Epoch: 437 / 500 batch step: 30\n",
            "w1: [25.78622139] w2: [-23.60318864] bias: [16.04189365] loss: 30.54168573936625\n",
            "Epoch: 437 / 500 batch step: 60\n",
            "w1: [25.76442466] w2: [-23.61032874] bias: [16.0003482] loss: 30.56143325704158\n",
            "Epoch: 437 / 500 batch step: 90\n",
            "w1: [25.75790016] w2: [-23.61430986] bias: [15.9850458] loss: 30.57003917498475\n",
            "Epoch: 437 / 500 batch step: 120\n",
            "w1: [25.7677784] w2: [-23.58342523] bias: [16.02166051] loss: 30.549730942368985\n",
            "Epoch: 437 / 500 batch step: 150\n",
            "w1: [25.80227438] w2: [-23.58210225] bias: [16.06549465] loss: 30.531535242179313\n",
            "Epoch: 437 / 500 batch step: 180\n",
            "w1: [25.87004015] w2: [-23.56505591] bias: [16.16815409] loss: 30.51943262203733\n",
            "Epoch: 437 / 500 batch step: 210\n",
            "w1: [25.90706031] w2: [-23.54464607] bias: [16.22747579] loss: 30.53170824601605\n",
            "Epoch: 437 / 500 batch step: 240\n",
            "w1: [25.94611846] w2: [-23.53874898] bias: [16.26934013] loss: 30.55034549551604\n",
            "Epoch: 437 / 500 batch step: 270\n",
            "w1: [25.96250553] w2: [-23.53888822] bias: [16.28635616] loss: 30.560061225697837\n",
            "Epoch: 437 / 500 batch step: 300\n",
            "w1: [25.94269651] w2: [-23.54517816] bias: [16.24716706] loss: 30.541625268724665\n",
            "Epoch: 437 / 500 batch step: 330\n",
            "w1: [25.90644884] w2: [-23.55786665] bias: [16.17567071] loss: 30.521588271068136\n",
            "Epoch: 437 / 500 batch step: 360\n",
            "w1: [25.91789481] w2: [-23.52816879] bias: [16.26538447] loss: 30.545394157050218\n",
            "Epoch: 437 / 500 batch step: 390\n",
            "w1: [25.89236477] w2: [-23.5396815] bias: [16.23159272] loss: 30.531477764691648\n",
            "Epoch: 437 / 500 batch step: 420\n",
            "w1: [25.84324006] w2: [-23.58276815] bias: [16.13715905] loss: 30.519040045548795\n",
            "Epoch: 437 / 500 batch step: 450\n",
            "w1: [25.81802462] w2: [-23.60026529] bias: [16.0942816] loss: 30.525302196387052\n",
            "Epoch: 437 / 500 batch step: 480\n",
            "w1: [25.80093938] w2: [-23.60185798] bias: [16.06791046] loss: 30.532480532579022\n",
            "Epoch: 438 / 500 batch step: 0\n",
            "w1: [25.79459214] w2: [-23.60279336] bias: [16.05468604] loss: 30.536712545873787\n",
            "Epoch: 438 / 500 batch step: 30\n",
            "w1: [25.78772494] w2: [-23.60287287] bias: [16.04101166] loss: 30.5416588583287\n",
            "Epoch: 438 / 500 batch step: 60\n",
            "w1: [25.76592846] w2: [-23.61001276] bias: [15.99946699] loss: 30.56140542470993\n",
            "Epoch: 438 / 500 batch step: 90\n",
            "w1: [25.75940354] w2: [-23.61399378] bias: [15.98416429] loss: 30.570011423163738\n",
            "Epoch: 438 / 500 batch step: 120\n",
            "w1: [25.76928223] w2: [-23.58310831] bias: [16.02078036] loss: 30.54970206212032\n",
            "Epoch: 438 / 500 batch step: 150\n",
            "w1: [25.8037778] w2: [-23.58178494] bias: [16.06461476] loss: 30.531507847618542\n",
            "Epoch: 438 / 500 batch step: 180\n",
            "w1: [25.87154172] w2: [-23.56473863] bias: [16.16727198] loss: 30.5194077135381\n",
            "Epoch: 438 / 500 batch step: 210\n",
            "w1: [25.9085598] w2: [-23.5443288] bias: [16.22659144] loss: 30.53168323449611\n",
            "Epoch: 438 / 500 batch step: 240\n",
            "w1: [25.94761581] w2: [-23.53843193] bias: [16.26845353] loss: 30.550320044129943\n",
            "Epoch: 438 / 500 batch step: 270\n",
            "w1: [25.96400181] w2: [-23.53857119] bias: [16.28546828] loss: 30.560035252716283\n",
            "Epoch: 438 / 500 batch step: 300\n",
            "w1: [25.94419292] w2: [-23.54486089] bias: [16.24627985] loss: 30.54160001339942\n",
            "Epoch: 438 / 500 batch step: 330\n",
            "w1: [25.90794566] w2: [-23.55754913] bias: [16.17478457] loss: 30.52156390171852\n",
            "Epoch: 438 / 500 batch step: 360\n",
            "w1: [25.91939136] w2: [-23.52785] bias: [16.26450063] loss: 30.545368485189723\n",
            "Epoch: 438 / 500 batch step: 390\n",
            "w1: [25.89386136] w2: [-23.53936201] bias: [16.23070998] loss: 30.531452244863736\n",
            "Epoch: 438 / 500 batch step: 420\n",
            "w1: [25.84473626] w2: [-23.58244901] bias: [16.13627574] loss: 30.519014883126413\n",
            "Epoch: 438 / 500 batch step: 450\n",
            "w1: [25.81952042] w2: [-23.59994631] bias: [16.09339787] loss: 30.525277234244598\n",
            "Epoch: 438 / 500 batch step: 480\n",
            "w1: [25.80243571] w2: [-23.60153831] bias: [16.06702825] loss: 30.53245489571786\n",
            "Epoch: 439 / 500 batch step: 0\n",
            "w1: [25.79608875] w2: [-23.60247333] bias: [16.05380472] loss: 30.53668651223589\n",
            "Epoch: 439 / 500 batch step: 30\n",
            "w1: [25.78922203] w2: [-23.60255242] bias: [16.04013158] loss: 30.541632172884217\n",
            "Epoch: 439 / 500 batch step: 60\n",
            "w1: [25.76742582] w2: [-23.6096921] bias: [15.9985877] loss: 30.561377791160275\n",
            "Epoch: 439 / 500 batch step: 90\n",
            "w1: [25.76090048] w2: [-23.613673] bias: [15.98328471] loss: 30.569983867226114\n",
            "Epoch: 439 / 500 batch step: 120\n",
            "w1: [25.77077961] w2: [-23.58278673] bias: [16.01990211] loss: 30.549673404045162\n",
            "Epoch: 439 / 500 batch step: 150\n",
            "w1: [25.80527477] w2: [-23.58146297] bias: [16.06373678] loss: 30.53148065126407\n",
            "Epoch: 439 / 500 batch step: 180\n",
            "w1: [25.87303686] w2: [-23.56441669] bias: [16.16639182] loss: 30.519382975382626\n",
            "Epoch: 439 / 500 batch step: 210\n",
            "w1: [25.91005288] w2: [-23.54400687] bias: [16.22570905] loss: 30.531658395270313\n",
            "Epoch: 439 / 500 batch step: 240\n",
            "w1: [25.94910676] w2: [-23.53811022] bias: [16.26756891] loss: 30.550294767966445\n",
            "Epoch: 439 / 500 batch step: 270\n",
            "w1: [25.96549172] w2: [-23.53824951] bias: [16.2845824] loss: 30.560009465437346\n",
            "Epoch: 439 / 500 batch step: 300\n",
            "w1: [25.94568296] w2: [-23.54453896] bias: [16.24539466] loss: 30.541574942279684\n",
            "Epoch: 439 / 500 batch step: 330\n",
            "w1: [25.90943612] w2: [-23.55722695] bias: [16.17390046] loss: 30.521539705757764\n",
            "Epoch: 439 / 500 batch step: 360\n",
            "w1: [25.92088155] w2: [-23.52752656] bias: [16.26361877] loss: 30.545343008822837\n",
            "Epoch: 439 / 500 batch step: 390\n",
            "w1: [25.89535156] w2: [-23.5390379] bias: [16.2298292] loss: 30.53142690439768\n",
            "Epoch: 439 / 500 batch step: 420\n",
            "w1: [25.84622607] w2: [-23.58212527] bias: [16.13539436] loss: 30.518989891070248\n",
            "Epoch: 439 / 500 batch step: 450\n",
            "w1: [25.82100982] w2: [-23.59962273] bias: [16.09251606] loss: 30.525252445985185\n",
            "Epoch: 439 / 500 batch step: 480\n",
            "w1: [25.80392564] w2: [-23.60121404] bias: [16.06614794] loss: 30.532429442622245\n",
            "Epoch: 440 / 500 batch step: 0\n",
            "w1: [25.79757896] w2: [-23.60214872] bias: [16.05292532] loss: 30.53666066705653\n",
            "Epoch: 440 / 500 batch step: 30\n",
            "w1: [25.79071272] w2: [-23.60222739] bias: [16.03925341] loss: 30.541605680319137\n",
            "Epoch: 440 / 500 batch step: 60\n",
            "w1: [25.76891679] w2: [-23.60936686] bias: [15.99771033] loss: 30.56135035365574\n",
            "Epoch: 440 / 500 batch step: 90\n",
            "w1: [25.76239103] w2: [-23.61334765] bias: [15.98240706] loss: 30.569956504486093\n",
            "Epoch: 440 / 500 batch step: 120\n",
            "w1: [25.77227059] w2: [-23.58246058] bias: [16.01902576] loss: 30.549644965015787\n",
            "Epoch: 440 / 500 batch step: 150\n",
            "w1: [25.80676535] w2: [-23.58113644] bias: [16.0628607] loss: 30.531453650376086\n",
            "Epoch: 440 / 500 batch step: 180\n",
            "w1: [25.87452564] w2: [-23.56409018] bias: [16.16551359] loss: 30.51935840525488\n",
            "Epoch: 440 / 500 batch step: 210\n",
            "w1: [25.91153961] w2: [-23.54368037] bias: [16.22482861] loss: 30.531633725992176\n",
            "Epoch: 440 / 500 batch step: 240\n",
            "w1: [25.95059139] w2: [-23.53778393] bias: [16.26668626] loss: 30.55026966464208\n",
            "Epoch: 440 / 500 batch step: 270\n",
            "w1: [25.96697531] w2: [-23.53792325] bias: [16.28369852] loss: 30.559983861303934\n",
            "Epoch: 440 / 500 batch step: 300\n",
            "w1: [25.9471667] w2: [-23.54421246] bias: [16.24451148] loss: 30.54155005280965\n",
            "Epoch: 440 / 500 batch step: 330\n",
            "w1: [25.91092028] w2: [-23.55690019] bias: [16.17301836] loss: 30.521515680796828\n",
            "Epoch: 440 / 500 batch step: 360\n",
            "w1: [25.92236543] w2: [-23.52719858] bias: [16.26273891] loss: 30.545317725205262\n",
            "Epoch: 440 / 500 batch step: 390\n",
            "w1: [25.89683545] w2: [-23.53870927] bias: [16.22895037] loss: 30.53140174084262\n",
            "Epoch: 440 / 500 batch step: 420\n",
            "w1: [25.84770956] w2: [-23.58179703] bias: [16.13451491] loss: 30.518965067082306\n",
            "Epoch: 440 / 500 batch step: 450\n",
            "w1: [25.82249289] w2: [-23.59929464] bias: [16.09163618] loss: 30.525227829239213\n",
            "Epoch: 440 / 500 batch step: 480\n",
            "w1: [25.80540923] w2: [-23.60088527] bias: [16.06526956] loss: 30.532404170765677\n",
            "Epoch: 441 / 500 batch step: 0\n",
            "w1: [25.79906284] w2: [-23.60181961] bias: [16.05204783] loss: 30.536635007737615\n",
            "Epoch: 441 / 500 batch step: 30\n",
            "w1: [25.79219708] w2: [-23.60189787] bias: [16.03837715] loss: 30.541579377978252\n",
            "Epoch: 441 / 500 batch step: 60\n",
            "w1: [25.77040143] w2: [-23.60903713] bias: [15.99683488] loss: 30.56132310951817\n",
            "Epoch: 441 / 500 batch step: 90\n",
            "w1: [25.76387527] w2: [-23.6130178] bias: [15.98153134] loss: 30.569929332315755\n",
            "Epoch: 441 / 500 batch step: 120\n",
            "w1: [25.77375524] w2: [-23.58212997] bias: [16.01815131] loss: 30.54961674196953\n",
            "Epoch: 441 / 500 batch step: 150\n",
            "w1: [25.80824961] w2: [-23.58080544] bias: [16.06198653] loss: 30.531426842273497\n",
            "Epoch: 441 / 500 batch step: 180\n",
            "w1: [25.87600812] w2: [-23.5637592] bias: [16.1646373] loss: 30.51933400089071\n",
            "Epoch: 441 / 500 batch step: 210\n",
            "w1: [25.91302006] w2: [-23.5433494] bias: [16.22395013] loss: 30.53160922436751\n",
            "Epoch: 441 / 500 batch step: 240\n",
            "w1: [25.95206975] w2: [-23.53745318] bias: [16.26580559] loss: 30.55024473182623\n",
            "Epoch: 441 / 500 batch step: 270\n",
            "w1: [25.96845266] w2: [-23.53759252] bias: [16.28281665] loss: 30.559958437814604\n",
            "Epoch: 441 / 500 batch step: 300\n",
            "w1: [25.9486442] w2: [-23.54388149] bias: [16.24363031] loss: 30.541525342489205\n",
            "Epoch: 441 / 500 batch step: 330\n",
            "w1: [25.9123982] w2: [-23.55656897] bias: [16.17213828] loss: 30.52149182449972\n",
            "Epoch: 441 / 500 batch step: 360\n",
            "w1: [25.92384307] w2: [-23.52686615] bias: [16.26186104] loss: 30.5452926316513\n",
            "Epoch: 441 / 500 batch step: 390\n",
            "w1: [25.89831308] w2: [-23.53837622] bias: [16.22807349] loss: 30.531376751801435\n",
            "Epoch: 441 / 500 batch step: 420\n",
            "w1: [25.84918677] w2: [-23.58146436] bias: [16.13363739] loss: 30.51894040891579\n",
            "Epoch: 441 / 500 batch step: 450\n",
            "w1: [25.82396969] w2: [-23.59896215] bias: [16.09075821] loss: 30.525203381689522\n",
            "Epoch: 441 / 500 batch step: 480\n",
            "w1: [25.80688656] w2: [-23.60055211] bias: [16.06439308] loss: 30.532379077676524\n",
            "Epoch: 442 / 500 batch step: 0\n",
            "w1: [25.80054045] w2: [-23.6014861] bias: [16.05117225] loss: 30.536609531737067\n",
            "Epoch: 442 / 500 batch step: 30\n",
            "w1: [25.79367518] w2: [-23.60156395] bias: [16.0375028] loss: 30.541553263263253\n",
            "Epoch: 442 / 500 batch step: 60\n",
            "w1: [25.77187981] w2: [-23.608703] bias: [15.99596135] loss: 30.561296056126615\n",
            "Epoch: 442 / 500 batch step: 90\n",
            "w1: [25.76535324] w2: [-23.61268356] bias: [15.98065753] loss: 30.569902348143557\n",
            "Epoch: 442 / 500 batch step: 120\n",
            "w1: [25.77523362] w2: [-23.58179498] bias: [16.01727875] loss: 30.549588731907093\n",
            "Epoch: 442 / 500 batch step: 150\n",
            "w1: [25.80972761] w2: [-23.58047006] bias: [16.06111427] loss: 30.53140022433242\n",
            "Epoch: 442 / 500 batch step: 180\n",
            "w1: [25.87748435] w2: [-23.56342384] bias: [16.16376294] loss: 30.519309760076407\n",
            "Epoch: 442 / 500 batch step: 210\n",
            "w1: [25.91449428] w2: [-23.54301406] bias: [16.22307359] loss: 30.531584888153024\n",
            "Epoch: 442 / 500 batch step: 240\n",
            "w1: [25.95354191] w2: [-23.53711805] bias: [16.26492689] loss: 30.5502199672397\n",
            "Epoch: 442 / 500 batch step: 270\n",
            "w1: [25.96992382] w2: [-23.53725742] bias: [16.28193676] loss: 30.5599331925221\n",
            "Epoch: 442 / 500 batch step: 300\n",
            "w1: [25.95011551] w2: [-23.54354614] bias: [16.24275113] loss: 30.541500808872428\n",
            "Epoch: 442 / 500 batch step: 330\n",
            "w1: [25.91386994] w2: [-23.55623336] bias: [16.1712602] loss: 30.521468134581994\n",
            "Epoch: 442 / 500 batch step: 360\n",
            "w1: [25.92531453] w2: [-23.52652937] bias: [16.26098514] loss: 30.54526772553236\n",
            "Epoch: 442 / 500 batch step: 390\n",
            "w1: [25.89978452] w2: [-23.53803883] bias: [16.22719855] loss: 30.531351934929237\n",
            "Epoch: 442 / 500 batch step: 420\n",
            "w1: [25.85065778] w2: [-23.58112738] bias: [16.1327618] loss: 30.518915914373725\n",
            "Epoch: 442 / 500 batch step: 450\n",
            "w1: [25.82544028] w2: [-23.59862534] bias: [16.08988216] loss: 30.52517910106987\n",
            "Epoch: 442 / 500 batch step: 480\n",
            "w1: [25.80835767] w2: [-23.60021463] bias: [16.06351851] loss: 30.53235416093664\n",
            "Epoch: 443 / 500 batch step: 0\n",
            "w1: [25.80201185] w2: [-23.60114828] bias: [16.05029856] loss: 30.536584236567375\n",
            "Epoch: 443 / 500 batch step: 30\n",
            "w1: [25.79514706] w2: [-23.60122574] bias: [16.03663035] loss: 30.541527333631247\n",
            "Epoch: 443 / 500 batch step: 60\n",
            "w1: [25.77335199] w2: [-23.60836457] bias: [15.99508973] loss: 30.56126919091584\n",
            "Epoch: 443 / 500 batch step: 90\n",
            "w1: [25.76682502] w2: [-23.61234503] bias: [15.97978565] loss: 30.569875549452806\n",
            "Epoch: 443 / 500 batch step: 120\n",
            "w1: [25.7767058] w2: [-23.5814557] bias: [16.01640808] loss: 30.549560931890976\n",
            "Epoch: 443 / 500 batch step: 150\n",
            "w1: [25.81119942] w2: [-23.5801304] bias: [16.06024391] loss: 30.53137379398464\n",
            "Epoch: 443 / 500 batch step: 180\n",
            "w1: [25.87895441] w2: [-23.5630842] bias: [16.1628905] loss: 30.519285680647354\n",
            "Epoch: 443 / 500 batch step: 210\n",
            "w1: [25.91596235] w2: [-23.54267444] bias: [16.222199] loss: 30.53156071515491\n",
            "Epoch: 443 / 500 batch step: 240\n",
            "w1: [25.95500792] w2: [-23.53677864] bias: [16.26405016] loss: 30.55019536865333\n",
            "Epoch: 443 / 500 batch step: 270\n",
            "w1: [25.97138884] w2: [-23.53691803] bias: [16.28105887] loss: 30.559908123031924\n",
            "Epoch: 443 / 500 batch step: 300\n",
            "w1: [25.9515807] w2: [-23.5432065] bias: [16.24187396] loss: 30.541476449566208\n",
            "Epoch: 443 / 500 batch step: 330\n",
            "w1: [25.91533557] w2: [-23.55589347] bias: [16.17038413] loss: 30.52144460880943\n",
            "Epoch: 443 / 500 batch step: 360\n",
            "w1: [25.92677986] w2: [-23.52618831] bias: [16.26011122] loss: 30.545243004275488\n",
            "Epoch: 443 / 500 batch step: 390\n",
            "w1: [25.90124982] w2: [-23.53769721] bias: [16.22632555] loss: 30.531327287932076\n",
            "Epoch: 443 / 500 batch step: 420\n",
            "w1: [25.85212265] w2: [-23.58078617] bias: [16.13188813] loss: 30.518891581307596\n",
            "Epoch: 443 / 500 batch step: 450\n",
            "w1: [25.82690472] w2: [-23.59828431] bias: [16.08900802] loss: 30.525154985163663\n",
            "Epoch: 443 / 500 batch step: 480\n",
            "w1: [25.80982263] w2: [-23.59987293] bias: [16.06264584] loss: 30.532329418179906\n",
            "Epoch: 444 / 500 batch step: 0\n",
            "w1: [25.80347709] w2: [-23.60080626] bias: [16.04942678] loss: 30.536559119794166\n",
            "Epoch: 444 / 500 batch step: 30\n",
            "w1: [25.79661279] w2: [-23.60088332] bias: [16.0357598] loss: 30.54150158659332\n",
            "Epoch: 444 / 500 batch step: 60\n",
            "w1: [25.77481802] w2: [-23.60802194] bias: [15.99422002] loss: 30.561242511374815\n",
            "Epoch: 444 / 500 batch step: 90\n",
            "w1: [25.76829066] w2: [-23.61200228] bias: [15.97891568] loss: 30.569848933780253\n",
            "Epoch: 444 / 500 batch step: 120\n",
            "w1: [25.77817182] w2: [-23.58111224] bias: [16.01553929] loss: 30.549533339043926\n",
            "Epoch: 444 / 500 batch step: 150\n",
            "w1: [25.81266508] w2: [-23.57978655] bias: [16.05937544] loss: 30.531347548716194\n",
            "Epoch: 444 / 500 batch step: 180\n",
            "w1: [25.88041835] w2: [-23.56274037] bias: [16.16201998] loss: 30.519261760486646\n",
            "Epoch: 444 / 500 batch step: 210\n",
            "w1: [25.9174243] w2: [-23.54233063] bias: [16.22132634] loss: 30.53153670322753\n",
            "Epoch: 444 / 500 batch step: 240\n",
            "w1: [25.95646785] w2: [-23.53643504] bias: [16.26317539] loss: 30.550170933886633\n",
            "Epoch: 444 / 500 batch step: 270\n",
            "w1: [25.9728478] w2: [-23.53657444] bias: [16.28018296] loss: 30.559883227000913\n",
            "Epoch: 444 / 500 batch step: 300\n",
            "w1: [25.95303982] w2: [-23.54286267] bias: [16.24099878] loss: 30.541452262228773\n",
            "Epoch: 444 / 500 batch step: 330\n",
            "w1: [25.91679513] w2: [-23.55554939] bias: [16.16951006] loss: 30.521421244996624\n",
            "Epoch: 444 / 500 batch step: 360\n",
            "w1: [25.92823913] w2: [-23.52584309] bias: [16.25923927] loss: 30.545218465361874\n",
            "Epoch: 444 / 500 batch step: 390\n",
            "w1: [25.90270904] w2: [-23.53735143] bias: [16.22545449] loss: 30.53130280856548\n",
            "Epoch: 444 / 500 batch step: 420\n",
            "w1: [25.85358143] w2: [-23.58044082] bias: [16.13101637] loss: 30.518867407616018\n",
            "Epoch: 444 / 500 batch step: 450\n",
            "w1: [25.82836308] w2: [-23.59793914] bias: [16.08813579] loss: 30.525131031802562\n",
            "Epoch: 444 / 500 batch step: 480\n",
            "w1: [25.81128151] w2: [-23.59952711] bias: [16.06177508] loss: 30.532304847090828\n",
            "Epoch: 445 / 500 batch step: 0\n",
            "w1: [25.80493625] w2: [-23.6004601] bias: [16.0485569] loss: 30.536534179034795\n",
            "Epoch: 445 / 500 batch step: 30\n",
            "w1: [25.79807243] w2: [-23.60053677] bias: [16.03489114] loss: 30.54147601971312\n",
            "Epoch: 445 / 500 batch step: 60\n",
            "w1: [25.77627796] w2: [-23.60767518] bias: [15.99335221] loss: 30.56121601504541\n",
            "Epoch: 445 / 500 batch step: 90\n",
            "w1: [25.76975022] w2: [-23.61165541] bias: [15.97804762] loss: 30.5698224987147\n",
            "Epoch: 445 / 500 batch step: 120\n",
            "w1: [25.77963176] w2: [-23.58076467] bias: [16.0146724] loss: 30.549505950547402\n",
            "Epoch: 445 / 500 batch step: 150\n",
            "w1: [25.81412466] w2: [-23.57943859] bias: [16.05850887] loss: 30.531321486065984\n",
            "Epoch: 445 / 500 batch step: 180\n",
            "w1: [25.88187623] w2: [-23.56239244] bias: [16.16115139] loss: 30.51923799752383\n",
            "Epoch: 445 / 500 batch step: 210\n",
            "w1: [25.91888022] w2: [-23.54198272] bias: [16.22045563] loss: 30.531512850272083\n",
            "Epoch: 445 / 500 batch step: 240\n",
            "w1: [25.95792175] w2: [-23.53608733] bias: [16.26230258] loss: 30.550146660806494\n",
            "Epoch: 445 / 500 batch step: 270\n",
            "w1: [25.97430075] w2: [-23.53622675] bias: [16.27930903] loss: 30.55985850213591\n",
            "Epoch: 445 / 500 batch step: 300\n",
            "w1: [25.95449294] w2: [-23.54251473] bias: [16.24012558] loss: 30.541428244568422\n",
            "Epoch: 445 / 500 batch step: 330\n",
            "w1: [25.91824869] w2: [-23.5552012] bias: [16.16863799] loss: 30.52139804100569\n",
            "Epoch: 445 / 500 batch step: 360\n",
            "w1: [25.92969239] w2: [-23.52549378] bias: [16.25836929] loss: 30.545194106325503\n",
            "Epoch: 445 / 500 batch step: 390\n",
            "w1: [25.90416224] w2: [-23.5370016] bias: [16.22458536] loss: 30.53127849463319\n",
            "Epoch: 445 / 500 batch step: 420\n",
            "w1: [25.85503419] w2: [-23.58009142] bias: [16.13014654] loss: 30.51884339124349\n",
            "Epoch: 445 / 500 batch step: 450\n",
            "w1: [25.8298154] w2: [-23.59758993] bias: [16.08726546] loss: 30.52510723886518\n",
            "Epoch: 445 / 500 batch step: 480\n",
            "w1: [25.81273435] w2: [-23.59917724] bias: [16.06090621] loss: 30.53228044540327\n",
            "Epoch: 446 / 500 batch step: 0\n",
            "w1: [25.80638937] w2: [-23.60010992] bias: [16.04768891] loss: 30.536509411957006\n",
            "Epoch: 446 / 500 batch step: 30\n",
            "w1: [25.79952605] w2: [-23.6001862] bias: [16.03402438] loss: 30.54145063060551\n",
            "Epoch: 446 / 500 batch step: 60\n",
            "w1: [25.77773189] w2: [-23.60732439] bias: [15.99248631] loss: 30.561189699520916\n",
            "Epoch: 446 / 500 batch step: 90\n",
            "w1: [25.77120376] w2: [-23.6113045] bias: [15.97718147] loss: 30.56979624189563\n",
            "Epoch: 446 / 500 batch step: 120\n",
            "w1: [25.78108566] w2: [-23.58041308] bias: [16.01380738] loss: 30.5494787636402\n",
            "Epoch: 446 / 500 batch step: 150\n",
            "w1: [25.81557822] w2: [-23.57908663] bias: [16.05764419] loss: 30.53129560362436\n",
            "Epoch: 446 / 500 batch step: 180\n",
            "w1: [25.8833281] w2: [-23.56204049] bias: [16.16028471] loss: 30.519214389733623\n",
            "Epoch: 446 / 500 batch step: 210\n",
            "w1: [25.92033014] w2: [-23.5416308] bias: [16.21958684] loss: 30.531489154235363\n",
            "Epoch: 446 / 500 batch step: 240\n",
            "w1: [25.95936968] w2: [-23.53573561] bias: [16.26143172] loss: 30.550122547325884\n",
            "Epoch: 446 / 500 batch step: 270\n",
            "w1: [25.97574774] w2: [-23.53587504] bias: [16.27843708] loss: 30.559833946192438\n",
            "Epoch: 446 / 500 batch step: 300\n",
            "w1: [25.95594011] w2: [-23.54216278] bias: [16.23925438] loss: 30.54140439434212\n",
            "Epoch: 446 / 500 batch step: 330\n",
            "w1: [25.9196963] w2: [-23.55484899] bias: [16.16776791] loss: 30.521374994745\n",
            "Epoch: 446 / 500 batch step: 360\n",
            "w1: [25.93113971] w2: [-23.52514048] bias: [16.25750128] loss: 30.545169924751775\n",
            "Epoch: 446 / 500 batch step: 390\n",
            "w1: [25.90560949] w2: [-23.53664779] bias: [16.22371816] loss: 30.53125434398587\n",
            "Epoch: 446 / 500 batch step: 420\n",
            "w1: [25.85648097] w2: [-23.57973805] bias: [16.12927861] loss: 30.51881953017909\n",
            "Epoch: 446 / 500 batch step: 450\n",
            "w1: [25.83126175] w2: [-23.59723676] bias: [16.08639704] loss: 30.52508360427584\n",
            "Epoch: 446 / 500 batch step: 480\n",
            "w1: [25.81418121] w2: [-23.59882343] bias: [16.06003924] loss: 30.532256210899103\n",
            "Epoch: 447 / 500 batch step: 0\n",
            "w1: [25.80783652] w2: [-23.59975578] bias: [16.04682281] loss: 30.536484816277603\n",
            "Epoch: 447 / 500 batch step: 30\n",
            "w1: [25.80097368] w2: [-23.59983168] bias: [16.03315951] loss: 30.541425416935194\n",
            "Epoch: 447 / 500 batch step: 60\n",
            "w1: [25.77917984] w2: [-23.60696965] bias: [15.99162231] loss: 30.561163562444797\n",
            "Epoch: 447 / 500 batch step: 90\n",
            "w1: [25.77265133] w2: [-23.61094966] bias: [15.97631723] loss: 30.56977016101188\n",
            "Epoch: 447 / 500 batch step: 120\n",
            "w1: [25.7825336] w2: [-23.58005757] bias: [16.01294424] loss: 30.549451775616916\n",
            "Epoch: 447 / 500 batch step: 150\n",
            "w1: [25.81702582] w2: [-23.57873074] bias: [16.05678139] loss: 30.531269899031834\n",
            "Epoch: 447 / 500 batch step: 180\n",
            "w1: [25.88477403] w2: [-23.56168462] bias: [16.15941994] loss: 30.519190935134684\n",
            "Epoch: 447 / 500 batch step: 210\n",
            "w1: [25.92177413] w2: [-23.54127495] bias: [16.21871999] loss: 30.53146561310851\n",
            "Epoch: 447 / 500 batch step: 240\n",
            "w1: [25.96081169] w2: [-23.53537996] bias: [16.26056281] loss: 30.550098591402644\n",
            "Epoch: 447 / 500 batch step: 270\n",
            "w1: [25.97718883] w2: [-23.53551941] bias: [16.27756711] loss: 30.559809556973423\n",
            "Epoch: 447 / 500 batch step: 300\n",
            "w1: [25.95738138] w2: [-23.5418069] bias: [16.23838515] loss: 30.54138070935429\n",
            "Epoch: 447 / 500 batch step: 330\n",
            "w1: [25.92113803] w2: [-23.55449285] bias: [16.16689981] loss: 30.521352104167946\n",
            "Epoch: 447 / 500 batch step: 360\n",
            "w1: [25.93258113] w2: [-23.52478327] bias: [16.25663522] loss: 30.54514591827622\n",
            "Epoch: 447 / 500 batch step: 390\n",
            "w1: [25.90705083] w2: [-23.53629009] bias: [16.22285289] loss: 30.531230354519867\n",
            "Epoch: 447 / 500 batch step: 420\n",
            "w1: [25.85792184] w2: [-23.57938081] bias: [16.12841259] loss: 30.518795822455353\n",
            "Epoch: 447 / 500 batch step: 450\n",
            "w1: [25.83270218] w2: [-23.59687972] bias: [16.08553052] loss: 30.52506012600336\n",
            "Epoch: 447 / 500 batch step: 480\n",
            "w1: [25.81562216] w2: [-23.59846574] bias: [16.05917416] loss: 30.53223214140697\n",
            "Epoch: 448 / 500 batch step: 0\n",
            "w1: [25.80927775] w2: [-23.59939778] bias: [16.0459586] loss: 30.536460389761203\n",
            "Epoch: 448 / 500 batch step: 30\n",
            "w1: [25.8024154] w2: [-23.59947331] bias: [16.03229653] loss: 30.5414003764155\n",
            "Epoch: 448 / 500 batch step: 60\n",
            "w1: [25.78062188] w2: [-23.60661106] bias: [15.99076021] loss: 30.56113760150936\n",
            "Epoch: 448 / 500 batch step: 90\n",
            "w1: [25.774093] w2: [-23.61059095] bias: [15.97545489] loss: 30.569744253800412\n",
            "Epoch: 448 / 500 batch step: 120\n",
            "w1: [25.78397561] w2: [-23.57969822] bias: [16.01208298] loss: 30.54942498382664\n",
            "Epoch: 448 / 500 batch step: 150\n",
            "w1: [25.8184675] w2: [-23.578371] bias: [16.05592049] loss: 30.531244369977774\n",
            "Epoch: 448 / 500 batch step: 180\n",
            "w1: [25.88621407] w2: [-23.5613249] bias: [16.15855709] loss: 30.519167631788445\n",
            "Epoch: 448 / 500 batch step: 210\n",
            "w1: [25.92321225] w2: [-23.54091525] bias: [16.21785506] loss: 30.53144222492583\n",
            "Epoch: 448 / 500 batch step: 240\n",
            "w1: [25.96224784] w2: [-23.53502047] bias: [16.25969585] loss: 30.55007479103826\n",
            "Epoch: 448 / 500 batch step: 270\n",
            "w1: [25.97862408] w2: [-23.53515993] bias: [16.2766991] loss: 30.559785332327944\n",
            "Epoch: 448 / 500 batch step: 300\n",
            "w1: [25.95881682] w2: [-23.54144717] bias: [16.23751789] loss: 30.541357187455528\n",
            "Epoch: 448 / 500 batch step: 330\n",
            "w1: [25.92257392] w2: [-23.55413287] bias: [16.16603369] loss: 30.52132936727168\n",
            "Epoch: 448 / 500 batch step: 360\n",
            "w1: [25.93401671] w2: [-23.52442223] bias: [16.25577112] loss: 30.54512208458316\n",
            "Epoch: 448 / 500 batch step: 390\n",
            "w1: [25.90848631] w2: [-23.53592859] bias: [16.22198954] loss: 30.531206524175985\n",
            "Epoch: 448 / 500 batch step: 420\n",
            "w1: [25.85935686] w2: [-23.57901978] bias: [16.12754848] loss: 30.518772266147025\n",
            "Epoch: 448 / 500 batch step: 450\n",
            "w1: [25.83413675] w2: [-23.59651888] bias: [16.08466589] loss: 30.52503680205984\n",
            "Epoch: 448 / 500 batch step: 480\n",
            "w1: [25.81705724] w2: [-23.59810428] bias: [16.05831098] loss: 30.53220823480105\n",
            "Epoch: 449 / 500 batch step: 0\n",
            "w1: [25.81071311] w2: [-23.59903601] bias: [16.04509628] loss: 30.53643613021897\n",
            "Epoch: 449 / 500 batch step: 30\n",
            "w1: [25.80385126] w2: [-23.59911116] bias: [16.03143543] loss: 30.541375506807064\n",
            "Epoch: 449 / 500 batch step: 60\n",
            "w1: [25.78205806] w2: [-23.60624868] bias: [15.98989999] loss: 30.56111181445449\n",
            "Epoch: 449 / 500 batch step: 90\n",
            "w1: [25.77552882] w2: [-23.61022847] bias: [15.97459445] loss: 30.569718518045015\n",
            "Epoch: 449 / 500 batch step: 120\n",
            "w1: [25.78541177] w2: [-23.57933511] bias: [16.0112236] loss: 30.5493983856716\n",
            "Epoch: 449 / 500 batch step: 150\n",
            "w1: [25.81990334] w2: [-23.57800751] bias: [16.05506146] loss: 30.531219014199163\n",
            "Epoch: 449 / 500 batch step: 180\n",
            "w1: [25.88764827] w2: [-23.56096142] bias: [16.15769614] loss: 30.519144477797937\n",
            "Epoch: 449 / 500 batch step: 210\n",
            "w1: [25.92464455] w2: [-23.54055181] bias: [16.21699205] loss: 30.53141898776363\n",
            "Epoch: 449 / 500 batch step: 240\n",
            "w1: [25.9636782] w2: [-23.53465721] bias: [16.25883084] loss: 30.550051144276697\n",
            "Epoch: 449 / 500 batch step: 270\n",
            "w1: [25.98005354] w2: [-23.53479669] bias: [16.27583305] loss: 30.559761270150055\n",
            "Epoch: 449 / 500 batch step: 300\n",
            "w1: [25.96024647] w2: [-23.54108369] bias: [16.23665261] loss: 30.541333826541422\n",
            "Epoch: 449 / 500 batch step: 330\n",
            "w1: [25.92400403] w2: [-23.55376912] bias: [16.16516955] loss: 30.52130678209603\n",
            "Epoch: 449 / 500 batch step: 360\n",
            "w1: [25.93544651] w2: [-23.52405746] bias: [16.25490897] loss: 30.54509842140452\n",
            "Epoch: 449 / 500 batch step: 390\n",
            "w1: [25.90991601] w2: [-23.53556338] bias: [16.22112811] loss: 30.531182850938336\n",
            "Epoch: 449 / 500 batch step: 420\n",
            "w1: [25.86078607] w2: [-23.57865503] bias: [16.12668627] loss: 30.518748859369968\n",
            "Epoch: 449 / 500 batch step: 450\n",
            "w1: [25.83556551] w2: [-23.59615435] bias: [16.08380316] loss: 30.525013630499547\n",
            "Epoch: 449 / 500 batch step: 480\n",
            "w1: [25.81848652] w2: [-23.59773911] bias: [16.05744967] loss: 30.532184488999878\n",
            "Epoch: 450 / 500 batch step: 0\n",
            "w1: [25.81214267] w2: [-23.59867053] bias: [16.04423584] loss: 30.5364120355074\n",
            "Epoch: 450 / 500 batch step: 30\n",
            "w1: [25.80528131] w2: [-23.59874531] bias: [16.03057622] loss: 30.541350805916665\n",
            "Epoch: 450 / 500 batch step: 60\n",
            "w1: [25.78348845] w2: [-23.60588262] bias: [15.98904167] loss: 30.561086199066484\n",
            "Epoch: 450 / 500 batch step: 90\n",
            "w1: [25.77695884] w2: [-23.6098623] bias: [15.97373591] loss: 30.569692951575128\n",
            "Epoch: 450 / 500 batch step: 120\n",
            "w1: [25.78684211] w2: [-23.57896832] bias: [16.01036608] loss: 30.549371978605834\n",
            "Epoch: 450 / 500 batch step: 150\n",
            "w1: [25.82133337] w2: [-23.57764034] bias: [16.05420432] loss: 30.531193829479356\n",
            "Epoch: 450 / 500 batch step: 180\n",
            "w1: [25.88907669] w2: [-23.56059427] bias: [16.15683709] loss: 30.51912147130669\n",
            "Epoch: 450 / 500 batch step: 210\n",
            "w1: [25.92607109] w2: [-23.54018468] bias: [16.21613097] loss: 30.531395899739113\n",
            "Epoch: 450 / 500 batch step: 240\n",
            "w1: [25.9651028] w2: [-23.53429029] bias: [16.25796776] loss: 30.550027649203315\n",
            "Epoch: 450 / 500 batch step: 270\n",
            "w1: [25.98147727] w2: [-23.53442977] bias: [16.27496896] loss: 30.559737368377572\n",
            "Epoch: 450 / 500 batch step: 300\n",
            "w1: [25.96167039] w2: [-23.54071652] bias: [16.23578929] loss: 30.541310624551357\n",
            "Epoch: 450 / 500 batch step: 330\n",
            "w1: [25.92542842] w2: [-23.5534017] bias: [16.16430738] loss: 30.521284346722304\n",
            "Epoch: 450 / 500 batch step: 360\n",
            "w1: [25.93687058] w2: [-23.52368902] bias: [16.25404876] loss: 30.545074926518577\n",
            "Epoch: 450 / 500 batch step: 390\n",
            "w1: [25.91133996] w2: [-23.53519452] bias: [16.22026859] loss: 30.5311593328332\n",
            "Epoch: 450 / 500 batch step: 420\n",
            "w1: [25.86220953] w2: [-23.57828666] bias: [16.12582596] loss: 30.51872560028006\n",
            "Epoch: 450 / 500 batch step: 450\n",
            "w1: [25.83698853] w2: [-23.59578618] bias: [16.08294232] loss: 30.524990609417763\n",
            "Epoch: 450 / 500 batch step: 480\n",
            "w1: [25.81991004] w2: [-23.59737032] bias: [16.05659026] loss: 30.532160901965206\n",
            "Epoch: 451 / 500 batch step: 0\n",
            "w1: [25.81356648] w2: [-23.59830144] bias: [16.04337728] loss: 30.536388103527212\n",
            "Epoch: 451 / 500 batch step: 30\n",
            "w1: [25.80670561] w2: [-23.59837586] bias: [16.02971888] loss: 30.541326271596\n",
            "Epoch: 451 / 500 batch step: 60\n",
            "w1: [25.78491308] w2: [-23.60551295] bias: [15.98818524] loss: 30.561060753176804\n",
            "Epoch: 451 / 500 batch step: 90\n",
            "w1: [25.77838311] w2: [-23.60949252] bias: [15.97287925] loss: 30.569667552264658\n",
            "Epoch: 451 / 500 batch step: 120\n",
            "w1: [25.78826671] w2: [-23.57859793] bias: [16.00951043] loss: 30.549345760133935\n",
            "Epoch: 451 / 500 batch step: 150\n",
            "w1: [25.82275767] w2: [-23.57726958] bias: [16.05334905] loss: 30.53116881364693\n",
            "Epoch: 451 / 500 batch step: 180\n",
            "w1: [25.89049939] w2: [-23.56022353] bias: [16.15597994] loss: 30.519098610497636\n",
            "Epoch: 451 / 500 batch step: 210\n",
            "w1: [25.92749191] w2: [-23.53981396] bias: [16.21527179] loss: 30.531372959009243\n",
            "Epoch: 451 / 500 batch step: 240\n",
            "w1: [25.96652171] w2: [-23.53391976] bias: [16.25710661] loss: 30.550004303943712\n",
            "Epoch: 451 / 500 batch step: 270\n",
            "w1: [25.98289531] w2: [-23.53405925] bias: [16.27410683] loss: 30.559713624990973\n",
            "Epoch: 451 / 500 batch step: 300\n",
            "w1: [25.96308863] w2: [-23.54034576] bias: [16.23492793] loss: 30.54128757946741\n",
            "Epoch: 451 / 500 batch step: 330\n",
            "w1: [25.92684713] w2: [-23.55303068] bias: [16.16344718] loss: 30.521262059272225\n",
            "Epoch: 451 / 500 batch step: 360\n",
            "w1: [25.93828897] w2: [-23.523317] bias: [16.2531905] loss: 30.545051597748817\n",
            "Epoch: 451 / 500 batch step: 390\n",
            "w1: [25.91275823] w2: [-23.53482211] bias: [16.21941099] loss: 30.531135967927902\n",
            "Epoch: 451 / 500 batch step: 420\n",
            "w1: [25.8636273] w2: [-23.57791474] bias: [16.12496755] loss: 30.51870248707211\n",
            "Epoch: 451 / 500 batch step: 450\n",
            "w1: [25.83840584] w2: [-23.59541448] bias: [16.08208336] loss: 30.5249677369497\n",
            "Epoch: 451 / 500 batch step: 480\n",
            "w1: [25.82132786] w2: [-23.59699799] bias: [16.05573272] loss: 30.53213747170082\n",
            "Epoch: 452 / 500 batch step: 0\n",
            "w1: [25.81498458] w2: [-23.59792882] bias: [16.04252059] loss: 30.536364332222128\n",
            "Epoch: 452 / 500 batch step: 30\n",
            "w1: [25.8081242] w2: [-23.59800287] bias: [16.02886342] loss: 30.541301901740567\n",
            "Epoch: 452 / 500 batch step: 60\n",
            "w1: [25.78633202] w2: [-23.60513974] bias: [15.98733069] loss: 30.56103547466096\n",
            "Epoch: 452 / 500 batch step: 90\n",
            "w1: [25.7798017] w2: [-23.6091192] bias: [15.97202449] loss: 30.56964231803086\n",
            "Epoch: 452 / 500 batch step: 120\n",
            "w1: [25.78968561] w2: [-23.57822403] bias: [16.00865665] loss: 30.549319727809806\n",
            "Epoch: 452 / 500 batch step: 150\n",
            "w1: [25.82417627] w2: [-23.5768953] bias: [16.05249565] loss: 30.53114396457451\n",
            "Epoch: 452 / 500 batch step: 180\n",
            "w1: [25.89191641] w2: [-23.55984926] bias: [16.15512468] loss: 30.51907589359206\n",
            "Epoch: 452 / 500 batch step: 210\n",
            "w1: [25.92890707] w2: [-23.53943973] bias: [16.21441453] loss: 30.53135016376975\n",
            "Epoch: 452 / 500 batch step: 240\n",
            "w1: [25.96793497] w2: [-23.53354572] bias: [16.2562474] loss: 30.549981106662678\n",
            "Epoch: 452 / 500 batch step: 270\n",
            "w1: [25.98430772] w2: [-23.53368521] bias: [16.27324665] loss: 30.55969003801228\n",
            "Epoch: 452 / 500 batch step: 300\n",
            "w1: [25.96450125] w2: [-23.53997147] bias: [16.23406853] loss: 30.541264689313213\n",
            "Epoch: 452 / 500 batch step: 330\n",
            "w1: [25.92826022] w2: [-23.55265614] bias: [16.16258895] loss: 30.521239917906833\n",
            "Epoch: 452 / 500 batch step: 360\n",
            "w1: [25.93970174] w2: [-23.52294149] bias: [16.25233418] loss: 30.545028432962766\n",
            "Epoch: 452 / 500 batch step: 390\n",
            "w1: [25.91417086] w2: [-23.53444622] bias: [16.21855529] loss: 30.531112754329776\n",
            "Epoch: 452 / 500 batch step: 420\n",
            "w1: [25.86503942] w2: [-23.57753934] bias: [16.12411103] loss: 30.51867951797882\n",
            "Epoch: 452 / 500 batch step: 450\n",
            "w1: [25.83981751] w2: [-23.59503931] bias: [16.08122629] loss: 30.524945011269484\n",
            "Epoch: 452 / 500 batch step: 480\n",
            "w1: [25.82274004] w2: [-23.59662221] bias: [16.05487706] loss: 30.532114196251563\n",
            "Epoch: 453 / 500 batch step: 0\n",
            "w1: [25.81639703] w2: [-23.59755274] bias: [16.04166578] loss: 30.536340719577847\n",
            "Epoch: 453 / 500 batch step: 30\n",
            "w1: [25.80953716] w2: [-23.59762644] bias: [16.02800983] loss: 30.541277694288542\n",
            "Epoch: 453 / 500 batch step: 60\n",
            "w1: [25.78774532] w2: [-23.60476308] bias: [15.98647802] loss: 30.561010361437397\n",
            "Epoch: 453 / 500 batch step: 90\n",
            "w1: [25.78121465] w2: [-23.60874243] bias: [15.97117161] loss: 30.569617246833193\n",
            "Epoch: 453 / 500 batch step: 120\n",
            "w1: [25.79109886] w2: [-23.5778467] bias: [16.00780473] loss: 30.54929387923547\n",
            "Epoch: 453 / 500 batch step: 150\n",
            "w1: [25.82558923] w2: [-23.57651759] bias: [16.05164412] loss: 30.531119280177673\n",
            "Epoch: 453 / 500 batch step: 180\n",
            "w1: [25.89332781] w2: [-23.55947156] bias: [16.15427132] loss: 30.519053318848567\n",
            "Epoch: 453 / 500 batch step: 210\n",
            "w1: [25.93031663] w2: [-23.53906206] bias: [16.21355918] loss: 30.53132751225403\n",
            "Epoch: 453 / 500 batch step: 240\n",
            "w1: [25.96934264] w2: [-23.53316824] bias: [16.25539011] loss: 30.549958055563184\n",
            "Epoch: 453 / 500 batch step: 270\n",
            "w1: [25.98571456] w2: [-23.53330774] bias: [16.27238842] loss: 30.55966660550398\n",
            "Epoch: 453 / 500 batch step: 300\n",
            "w1: [25.9659083] w2: [-23.53959375] bias: [16.23321108] loss: 30.54124195215289\n",
            "Epoch: 453 / 500 batch step: 330\n",
            "w1: [25.92966775] w2: [-23.55227816] bias: [16.16173267] loss: 30.52121792082548\n",
            "Epoch: 453 / 500 batch step: 360\n",
            "w1: [25.94110893] w2: [-23.52256256] bias: [16.25147979] loss: 30.545005430070887\n",
            "Epoch: 453 / 500 batch step: 390\n",
            "w1: [25.9155779] w2: [-23.53406692] bias: [16.2177015] loss: 30.53108969018506\n",
            "Epoch: 453 / 500 batch step: 420\n",
            "w1: [25.86644596] w2: [-23.57716056] bias: [16.12325639] loss: 30.518656691269804\n",
            "Epoch: 453 / 500 batch step: 450\n",
            "w1: [25.84122358] w2: [-23.59466074] bias: [16.0803711] loss: 30.524922430589076\n",
            "Epoch: 453 / 500 batch step: 480\n",
            "w1: [25.82414662] w2: [-23.59624304] bias: [16.05402327] loss: 30.532091073702155\n",
            "Epoch: 454 / 500 batch step: 0\n",
            "w1: [25.81780389] w2: [-23.59717328] bias: [16.04081284] loss: 30.53631726362092\n",
            "Epoch: 454 / 500 batch step: 30\n",
            "w1: [25.81094451] w2: [-23.59724662] bias: [16.02715811] loss: 30.541253647219687\n",
            "Epoch: 454 / 500 batch step: 60\n",
            "w1: [25.78915303] w2: [-23.60438304] bias: [15.98562723] loss: 30.56098541146638\n",
            "Epoch: 454 / 500 batch step: 90\n",
            "w1: [25.78262201] w2: [-23.60836229] bias: [15.97032062] loss: 30.569592336672265\n",
            "Epoch: 454 / 500 batch step: 120\n",
            "w1: [25.79250652] w2: [-23.577466] bias: [16.00695467] loss: 30.549268212059886\n",
            "Epoch: 454 / 500 batch step: 150\n",
            "w1: [25.8269966] w2: [-23.57613651] bias: [16.05079446] loss: 30.531094758413843\n",
            "Epoch: 454 / 500 batch step: 180\n",
            "w1: [25.89473364] w2: [-23.5590905] bias: [16.15341985] loss: 30.519030884562124\n",
            "Epoch: 454 / 500 batch step: 210\n",
            "w1: [25.93172063] w2: [-23.53868104] bias: [16.21270572] loss: 30.53130500273222\n",
            "Epoch: 454 / 500 batch step: 240\n",
            "w1: [25.97074477] w2: [-23.5327874] bias: [16.25453474] loss: 30.549935148885343\n",
            "Epoch: 454 / 500 batch step: 270\n",
            "w1: [25.98711587] w2: [-23.5329269] bias: [16.27153212] loss: 30.559643325568008\n",
            "Epoch: 454 / 500 batch step: 300\n",
            "w1: [25.96730983] w2: [-23.53921267] bias: [16.23235559] loss: 30.54121936609004\n",
            "Epoch: 454 / 500 batch step: 330\n",
            "w1: [25.93106975] w2: [-23.55189682] bias: [16.16087834] loss: 30.521196066264807\n",
            "Epoch: 454 / 500 batch step: 360\n",
            "w1: [25.9425106] w2: [-23.52218028] bias: [16.25062733] loss: 30.54498258702553\n",
            "Epoch: 454 / 500 batch step: 390\n",
            "w1: [25.91697942] w2: [-23.53368431] bias: [16.21684961] loss: 30.531066773677953\n",
            "Epoch: 454 / 500 batch step: 420\n",
            "w1: [25.86784695] w2: [-23.57677846] bias: [16.12240364] loss: 30.518634005250558\n",
            "Epoch: 454 / 500 batch step: 450\n",
            "w1: [25.84262411] w2: [-23.59427887] bias: [16.07951779] loss: 30.52489999315732\n",
            "Epoch: 454 / 500 batch step: 480\n",
            "w1: [25.82554766] w2: [-23.59586056] bias: [16.05317136] loss: 30.532068102176257\n",
            "Epoch: 455 / 500 batch step: 0\n",
            "w1: [25.81920521] w2: [-23.59679052] bias: [16.03996177] loss: 30.536293962417727\n",
            "Epoch: 455 / 500 batch step: 30\n",
            "w1: [25.81234633] w2: [-23.59686351] bias: [16.02630826] loss: 30.541229758554312\n",
            "Epoch: 455 / 500 batch step: 60\n",
            "w1: [25.7905552] w2: [-23.6039997] bias: [15.98477831] loss: 30.560960622748965\n",
            "Epoch: 455 / 500 batch step: 90\n",
            "w1: [25.78402384] w2: [-23.60797885] bias: [15.9694715] loss: 30.569567585588832\n",
            "Epoch: 455 / 500 batch step: 120\n",
            "w1: [25.79390863] w2: [-23.57708201] bias: [16.00610646] loss: 30.549242723977823\n",
            "Epoch: 455 / 500 batch step: 150\n",
            "w1: [25.82839844] w2: [-23.57575215] bias: [16.04994666] loss: 30.531070397281237\n",
            "Epoch: 455 / 500 batch step: 180\n",
            "w1: [25.89613396] w2: [-23.55870615] bias: [16.15257026] loss: 30.51900858906303\n",
            "Epoch: 455 / 500 batch step: 210\n",
            "w1: [25.93311912] w2: [-23.53829672] bias: [16.21185417] loss: 30.531282633510177\n",
            "Epoch: 455 / 500 batch step: 240\n",
            "w1: [25.97214142] w2: [-23.53240327] bias: [16.2536813] loss: 30.549912384905465\n",
            "Epoch: 455 / 500 batch step: 270\n",
            "w1: [25.9885117] w2: [-23.53254278] bias: [16.27067777] loss: 30.559620196344692\n",
            "Epoch: 455 / 500 batch step: 300\n",
            "w1: [25.96870588] w2: [-23.5388283] bias: [16.23150203] loss: 30.54119692926667\n",
            "Epoch: 455 / 500 batch step: 330\n",
            "w1: [25.93246628] w2: [-23.55151219] bias: [16.16002596] loss: 30.521174352497756\n",
            "Epoch: 455 / 500 batch step: 360\n",
            "w1: [25.94390681] w2: [-23.52179473] bias: [16.24977679] loss: 30.544959901819837\n",
            "Epoch: 455 / 500 batch step: 390\n",
            "w1: [25.91837545] w2: [-23.53329844] bias: [16.21599962] loss: 30.531044003029592\n",
            "Epoch: 455 / 500 batch step: 420\n",
            "w1: [25.86924246] w2: [-23.57639312] bias: [16.12155278] loss: 30.518611458261553\n",
            "Epoch: 455 / 500 batch step: 450\n",
            "w1: [25.84401915] w2: [-23.59389376] bias: [16.07866635] loss: 30.52487769725898\n",
            "Epoch: 455 / 500 batch step: 480\n",
            "w1: [25.8269432] w2: [-23.59547485] bias: [16.05232131] loss: 30.532045279835426\n",
            "Epoch: 456 / 500 batch step: 0\n",
            "w1: [25.82060103] w2: [-23.59640452] bias: [16.03911256] loss: 30.536270814073482\n",
            "Epoch: 456 / 500 batch step: 30\n",
            "w1: [25.81374264] w2: [-23.59647718] bias: [16.02546027] loss: 30.541206026352246\n",
            "Epoch: 456 / 500 batch step: 60\n",
            "w1: [25.79195188] w2: [-23.60361314] bias: [15.98393126] loss: 30.56093599332596\n",
            "Epoch: 456 / 500 batch step: 90\n",
            "w1: [25.78542019] w2: [-23.60759218] bias: [15.96862426] loss: 30.569542991662697\n",
            "Epoch: 456 / 500 batch step: 120\n",
            "w1: [25.79530525] w2: [-23.57669482] bias: [16.00526011] loss: 30.549217412728748\n",
            "Epoch: 456 / 500 batch step: 150\n",
            "w1: [25.8297948] w2: [-23.57536458] bias: [16.04910073] loss: 30.531046194817886\n",
            "Epoch: 456 / 500 batch step: 180\n",
            "w1: [25.8975288] w2: [-23.5583186] bias: [16.15172255] loss: 30.518986430716044\n",
            "Epoch: 456 / 500 batch step: 210\n",
            "w1: [25.93451216] w2: [-23.5379092] bias: [16.21100452] loss: 30.531260402928535\n",
            "Epoch: 456 / 500 batch step: 240\n",
            "w1: [25.97353262] w2: [-23.53201594] bias: [16.25282977] loss: 30.549889761935074\n",
            "Epoch: 456 / 500 batch step: 270\n",
            "w1: [25.98990211] w2: [-23.53215544] bias: [16.26982535] loss: 30.559597216011806\n",
            "Epoch: 456 / 500 batch step: 300\n",
            "w1: [25.97009651] w2: [-23.53844071] bias: [16.23065042] loss: 30.541174639862273\n",
            "Epoch: 456 / 500 batch step: 330\n",
            "w1: [25.9338574] w2: [-23.55112435] bias: [16.15917553] loss: 30.521152777832626\n",
            "Epoch: 456 / 500 batch step: 360\n",
            "w1: [25.94529758] w2: [-23.52140599] bias: [16.24892818] loss: 30.544937372486743\n",
            "Epoch: 456 / 500 batch step: 390\n",
            "w1: [25.91976605] w2: [-23.5329094] bias: [16.21515151] loss: 30.531021376497105\n",
            "Epoch: 456 / 500 batch step: 420\n",
            "w1: [25.87063252] w2: [-23.57600461] bias: [16.12070379] loss: 30.518589048677327\n",
            "Epoch: 456 / 500 batch step: 450\n",
            "w1: [25.84540875] w2: [-23.59350549] bias: [16.07781678] loss: 30.524855541213746\n",
            "Epoch: 456 / 500 batch step: 480\n",
            "w1: [25.8283333] w2: [-23.59508598] bias: [16.05147313] loss: 30.532022604878165\n",
            "Epoch: 457 / 500 batch step: 0\n",
            "w1: [25.82199141] w2: [-23.59601538] bias: [16.03826521] loss: 30.536247816731212\n",
            "Epoch: 457 / 500 batch step: 30\n",
            "w1: [25.81513352] w2: [-23.59608769] bias: [16.02461414] loss: 30.54118244871183\n",
            "Epoch: 457 / 500 batch step: 60\n",
            "w1: [25.79334312] w2: [-23.60322343] bias: [15.98308608] loss: 30.560911521276932\n",
            "Epoch: 457 / 500 batch step: 90\n",
            "w1: [25.7868111] w2: [-23.60720236] bias: [15.96777889] loss: 30.56951855301179\n",
            "Epoch: 457 / 500 batch step: 120\n",
            "w1: [25.79669643] w2: [-23.57630449] bias: [16.0044156] loss: 30.549192276095738\n",
            "Epoch: 457 / 500 batch step: 150\n",
            "w1: [25.83118572] w2: [-23.57497388] bias: [16.04825665] loss: 30.53102214910055\n",
            "Epoch: 457 / 500 batch step: 180\n",
            "w1: [25.89891822] w2: [-23.5579279] bias: [16.15087672] loss: 30.518964407919448\n",
            "Epoch: 457 / 500 batch step: 210\n",
            "w1: [25.93589979] w2: [-23.53751855] bias: [16.21015676] loss: 30.531238309361843\n",
            "Epoch: 457 / 500 batch step: 240\n",
            "w1: [25.97491843] w2: [-23.53162546] bias: [16.25198015] loss: 30.549867278320015\n",
            "Epoch: 457 / 500 batch step: 270\n",
            "w1: [25.99128713] w2: [-23.53176496] bias: [16.26897486] loss: 30.559574382783605\n",
            "Epoch: 457 / 500 batch step: 300\n",
            "w1: [25.97148176] w2: [-23.53804999] bias: [16.22980074] loss: 30.541152496092828\n",
            "Epoch: 457 / 500 batch step: 330\n",
            "w1: [25.93524314] w2: [-23.55073337] bias: [16.15832704] loss: 30.521131340612193\n",
            "Epoch: 457 / 500 batch step: 360\n",
            "w1: [25.94668299] w2: [-23.52101412] bias: [16.24808149] loss: 30.544914997097997\n",
            "Epoch: 457 / 500 batch step: 390\n",
            "w1: [25.92115127] w2: [-23.53251725] bias: [16.2143053] loss: 30.530998892372693\n",
            "Epoch: 457 / 500 batch step: 420\n",
            "w1: [25.8720172] w2: [-23.57561301] bias: [16.11985668] loss: 30.51856677490552\n",
            "Epoch: 457 / 500 batch step: 450\n",
            "w1: [25.84679295] w2: [-23.59311412] bias: [16.07696909] loss: 30.52483352337541\n",
            "Epoch: 457 / 500 batch step: 480\n",
            "w1: [25.829718] w2: [-23.59469403] bias: [16.05062681] loss: 30.532000075538964\n",
            "Epoch: 458 / 500 batch step: 0\n",
            "w1: [25.82337639] w2: [-23.59562315] bias: [16.03741972] loss: 30.536224968570824\n",
            "Epoch: 458 / 500 batch step: 30\n",
            "w1: [25.816519] w2: [-23.59569512] bias: [16.02376986] loss: 30.54115902376898\n",
            "Epoch: 458 / 500 batch step: 60\n",
            "w1: [25.79472898] w2: [-23.60283063] bias: [15.98224277] loss: 30.560887204719226\n",
            "Epoch: 458 / 500 batch step: 90\n",
            "w1: [25.78819663] w2: [-23.60680946] bias: [15.96693539] loss: 30.56949426779119\n",
            "Epoch: 458 / 500 batch step: 120\n",
            "w1: [25.79808222] w2: [-23.57591109] bias: [16.00357295] loss: 30.549167311904473\n",
            "Epoch: 458 / 500 batch step: 150\n",
            "w1: [25.83257125] w2: [-23.57458011] bias: [16.04741442] loss: 30.530998258243844\n",
            "Epoch: 458 / 500 batch step: 180\n",
            "w1: [25.90030227] w2: [-23.55753415] bias: [16.15003277] loss: 30.51894251910417\n",
            "Epoch: 458 / 500 batch step: 210\n",
            "w1: [25.93728207] w2: [-23.53712483] bias: [16.20931088] loss: 30.53121635121763\n",
            "Epoch: 458 / 500 batch step: 240\n",
            "w1: [25.97629889] w2: [-23.53123192] bias: [16.25113243] loss: 30.54984493243957\n",
            "Epoch: 458 / 500 batch step: 270\n",
            "w1: [25.99266683] w2: [-23.53137142] bias: [16.2681263] loss: 30.559551694909903\n",
            "Epoch: 458 / 500 batch step: 300\n",
            "w1: [25.97286169] w2: [-23.5376562] bias: [16.22895299] loss: 30.541130496209885\n",
            "Epoch: 458 / 500 batch step: 330\n",
            "w1: [25.93662356] w2: [-23.55033932] bias: [16.15748048] loss: 30.521110039212726\n",
            "Epoch: 458 / 500 batch step: 360\n",
            "w1: [25.94806307] w2: [-23.52061921] bias: [16.24723671] loss: 30.5448927737632\n",
            "Epoch: 458 / 500 batch step: 390\n",
            "w1: [25.92253114] w2: [-23.53212207] bias: [16.21346097] loss: 30.530976548982697\n",
            "Epoch: 458 / 500 batch step: 420\n",
            "w1: [25.87339653] w2: [-23.57521838] bias: [16.11901144] loss: 30.51854463538608\n",
            "Epoch: 458 / 500 batch step: 450\n",
            "w1: [25.84817181] w2: [-23.59271974] bias: [16.07612325] loss: 30.524811642130896\n",
            "Epoch: 458 / 500 batch step: 480\n",
            "w1: [25.83109736] w2: [-23.59429906] bias: [16.04978234] loss: 30.53197769008743\n",
            "Epoch: 459 / 500 batch step: 0\n",
            "w1: [25.82475602] w2: [-23.59522791] bias: [16.03657609] loss: 30.536202267808193\n",
            "Epoch: 459 / 500 batch step: 30\n",
            "w1: [25.81789914] w2: [-23.59529954] bias: [16.02292745] loss: 30.541135749696195\n",
            "Epoch: 459 / 500 batch step: 60\n",
            "w1: [25.79610949] w2: [-23.60243483] bias: [15.98140131] loss: 30.560863041807043\n",
            "Epoch: 459 / 500 batch step: 90\n",
            "w1: [25.78957682] w2: [-23.60641355] bias: [15.96609376] loss: 30.56947013419217\n",
            "Epoch: 459 / 500 batch step: 120\n",
            "w1: [25.79946266] w2: [-23.5755147] bias: [16.00273214] loss: 30.54914251802216\n",
            "Epoch: 459 / 500 batch step: 150\n",
            "w1: [25.83395144] w2: [-23.57418334] bias: [16.04657405] loss: 30.530974520399226\n",
            "Epoch: 459 / 500 batch step: 180\n",
            "w1: [25.901681] w2: [-23.55713739] bias: [16.14919069] loss: 30.518920762732915\n",
            "Epoch: 459 / 500 batch step: 210\n",
            "w1: [25.93865903] w2: [-23.53672811] bias: [16.2084669] loss: 30.531194526935554\n",
            "Epoch: 459 / 500 batch step: 240\n",
            "w1: [25.97767406] w2: [-23.53083539] bias: [16.25028662] loss: 30.549822722705553\n",
            "Epoch: 459 / 500 batch step: 270\n",
            "w1: [25.99404124] w2: [-23.53097488] bias: [16.26727965] loss: 30.559529150675125\n",
            "Epoch: 459 / 500 batch step: 300\n",
            "w1: [25.97423634] w2: [-23.53725942] bias: [16.22810716] loss: 30.54110863849967\n",
            "Epoch: 459 / 500 batch step: 330\n",
            "w1: [25.93799871] w2: [-23.54994228] bias: [16.15663586] loss: 30.521088872043205\n",
            "Epoch: 459 / 500 batch step: 360\n",
            "w1: [25.94943786] w2: [-23.52022131] bias: [16.24639383] loss: 30.544870700628824\n",
            "Epoch: 459 / 500 batch step: 390\n",
            "w1: [25.92390574] w2: [-23.53172393] bias: [16.21261853] loss: 30.530954344686783\n",
            "Epoch: 459 / 500 batch step: 420\n",
            "w1: [25.87477057] w2: [-23.5748208] bias: [16.11816807] loss: 30.518522628590357\n",
            "Epoch: 459 / 500 batch step: 450\n",
            "w1: [25.84954537] w2: [-23.5923224] bias: [16.07527928] loss: 30.524789895899485\n",
            "Epoch: 459 / 500 batch step: 480\n",
            "w1: [25.83247142] w2: [-23.59390114] bias: [16.04893974] loss: 30.531955446827315\n",
            "Epoch: 460 / 500 batch step: 0\n",
            "w1: [25.82613036] w2: [-23.59482972] bias: [16.03573431] loss: 30.53617971269421\n",
            "Epoch: 460 / 500 batch step: 30\n",
            "w1: [25.81927397] w2: [-23.59490103] bias: [16.02208688] loss: 30.541112624701718\n",
            "Epoch: 460 / 500 batch step: 60\n",
            "w1: [25.7974847] w2: [-23.60203608] bias: [15.98056171] loss: 30.560839030730506\n",
            "Epoch: 460 / 500 batch step: 90\n",
            "w1: [25.79095171] w2: [-23.6060147] bias: [15.96525398] loss: 30.569446150441337\n",
            "Epoch: 460 / 500 batch step: 120\n",
            "w1: [25.8008378] w2: [-23.57511538] bias: [16.00189316] loss: 30.549117892356584\n",
            "Epoch: 460 / 500 batch step: 150\n",
            "w1: [25.83532635] w2: [-23.57378366] bias: [16.04573552] loss: 30.53095093375413\n",
            "Epoch: 460 / 500 batch step: 180\n",
            "w1: [25.90305445] w2: [-23.55673771] bias: [16.14835047] loss: 30.518899137299346\n",
            "Epoch: 460 / 500 batch step: 210\n",
            "w1: [25.94003073] w2: [-23.53632848] bias: [16.20762479] loss: 30.531172834986574\n",
            "Epoch: 460 / 500 batch step: 240\n",
            "w1: [25.97904398] w2: [-23.53043592] bias: [16.24944271] loss: 30.549800647561504\n",
            "Epoch: 460 / 500 batch step: 270\n",
            "w1: [25.99541042] w2: [-23.53057541] bias: [16.26643492] loss: 30.559506748397535\n",
            "Epoch: 460 / 500 batch step: 300\n",
            "w1: [25.97560575] w2: [-23.5368597] bias: [16.22726326] loss: 30.541086921282204\n",
            "Epoch: 460 / 500 batch step: 330\n",
            "w1: [25.93936862] w2: [-23.54954231] bias: [16.15579316] loss: 30.521067837544408\n",
            "Epoch: 460 / 500 batch step: 360\n",
            "w1: [25.95080743] w2: [-23.51982051] bias: [16.24555287] loss: 30.54484877587736\n",
            "Epoch: 460 / 500 batch step: 390\n",
            "w1: [25.92527509] w2: [-23.5313229] bias: [16.21177796] loss: 30.53093227787704\n",
            "Epoch: 460 / 500 batch step: 420\n",
            "w1: [25.87613936] w2: [-23.57442033] bias: [16.11732656] loss: 30.51850075302036\n",
            "Epoch: 460 / 500 batch step: 450\n",
            "w1: [25.85091368] w2: [-23.59192218] bias: [16.07443717] loss: 30.52476828313189\n",
            "Epoch: 460 / 500 batch step: 480\n",
            "w1: [25.83384023] w2: [-23.59350035] bias: [16.04809898] loss: 30.53193334409574\n",
            "Epoch: 461 / 500 batch step: 0\n",
            "w1: [25.82749944] w2: [-23.59442866] bias: [16.03489437] loss: 30.536157301513963\n",
            "Epoch: 461 / 500 batch step: 30\n",
            "w1: [25.82064356] w2: [-23.59449964] bias: [16.02124816] loss: 30.541089647028585\n",
            "Epoch: 461 / 500 batch step: 60\n",
            "w1: [25.79885467] w2: [-23.60163447] bias: [15.97972397] loss: 30.560815169714783\n",
            "Epoch: 461 / 500 batch step: 90\n",
            "w1: [25.79232137] w2: [-23.60561298] bias: [15.96441607] loss: 30.569422314799713\n",
            "Epoch: 461 / 500 batch step: 120\n",
            "w1: [25.80220769] w2: [-23.5747132] bias: [16.00105603] loss: 30.549093432855134\n",
            "Epoch: 461 / 500 batch step: 150\n",
            "w1: [25.836696] w2: [-23.57338111] bias: [16.04489884] loss: 30.530927496531046\n",
            "Epoch: 461 / 500 batch step: 180\n",
            "w1: [25.90442268] w2: [-23.55633518] bias: [16.14751212] loss: 30.51887764132729\n",
            "Epoch: 461 / 500 batch step: 210\n",
            "w1: [25.94139722] w2: [-23.53592598] bias: [16.20678456] loss: 30.531151273872137\n",
            "Epoch: 461 / 500 batch step: 240\n",
            "w1: [25.9804087] w2: [-23.53003361] bias: [16.2486007] loss: 30.549778705481845\n",
            "Epoch: 461 / 500 batch step: 270\n",
            "w1: [25.9967744] w2: [-23.53017309] bias: [16.26559211] loss: 30.559484486428243\n",
            "Epoch: 461 / 500 batch step: 300\n",
            "w1: [25.97696998] w2: [-23.53645713] bias: [16.22642128] loss: 30.541065342910432\n",
            "Epoch: 461 / 500 batch step: 330\n",
            "w1: [25.94073335] w2: [-23.54913948] bias: [16.15495239] loss: 30.52104693418816\n",
            "Epoch: 461 / 500 batch step: 360\n",
            "w1: [25.95217181] w2: [-23.51941686] bias: [16.2447138] loss: 30.5448269977264\n",
            "Epoch: 461 / 500 batch step: 390\n",
            "w1: [25.92663924] w2: [-23.53091905] bias: [16.21093927] loss: 30.530910346977166\n",
            "Epoch: 461 / 500 batch step: 420\n",
            "w1: [25.87750295] w2: [-23.57401705] bias: [16.11648692] loss: 30.51847900720787\n",
            "Epoch: 461 / 500 batch step: 450\n",
            "w1: [25.85227678] w2: [-23.59151915] bias: [16.07359691] loss: 30.524746802309537\n",
            "Epoch: 461 / 500 batch step: 480\n",
            "w1: [25.83520383] w2: [-23.59309674] bias: [16.04726008] loss: 30.5319113802623\n",
            "Epoch: 462 / 500 batch step: 0\n",
            "w1: [25.82886331] w2: [-23.5940248] bias: [16.03405629] loss: 30.53613503258583\n",
            "Epoch: 462 / 500 batch step: 30\n",
            "w1: [25.82200793] w2: [-23.59409546] bias: [16.02041128] loss: 30.541066814953794\n",
            "Epoch: 462 / 500 batch step: 60\n",
            "w1: [25.80021944] w2: [-23.60123005] bias: [15.97888808] loss: 30.560791457019192\n",
            "Epoch: 462 / 500 batch step: 90\n",
            "w1: [25.79368582] w2: [-23.60520846] bias: [15.96358001] loss: 30.56939862556191\n",
            "Epoch: 462 / 500 batch step: 120\n",
            "w1: [25.80357237] w2: [-23.57430824] bias: [16.00022073] loss: 30.54906913750385\n",
            "Epoch: 462 / 500 batch step: 150\n",
            "w1: [25.83806046] w2: [-23.57297578] bias: [16.044064] loss: 30.530904206986666\n",
            "Epoch: 462 / 500 batch step: 180\n",
            "w1: [25.90578571] w2: [-23.55592985] bias: [16.14667564] loss: 30.518856273369916\n",
            "Epoch: 462 / 500 batch step: 210\n",
            "w1: [25.94275853] w2: [-23.5355207] bias: [16.20594621] loss: 30.531129842123402\n",
            "Epoch: 462 / 500 batch step: 240\n",
            "w1: [25.98176826] w2: [-23.5296285] bias: [16.24776057] loss: 30.549756894971097\n",
            "Epoch: 462 / 500 batch step: 270\n",
            "w1: [25.99813324] w2: [-23.52976797] bias: [16.2647512] loss: 30.55946236315052\n",
            "Epoch: 462 / 500 batch step: 300\n",
            "w1: [25.97832907] w2: [-23.53605177] bias: [16.22558121] loss: 30.541043901769438\n",
            "Epoch: 462 / 500 batch step: 330\n",
            "w1: [25.94209295] w2: [-23.54873385] bias: [16.15411353] loss: 30.521026160476467\n",
            "Epoch: 462 / 500 batch step: 360\n",
            "w1: [25.95353105] w2: [-23.51901044] bias: [16.24387663] loss: 30.5448053644278\n",
            "Epoch: 462 / 500 batch step: 390\n",
            "w1: [25.92799824] w2: [-23.53051243] bias: [16.21010245] loss: 30.53088855044168\n",
            "Epoch: 462 / 500 batch step: 420\n",
            "w1: [25.87886138] w2: [-23.57361101] bias: [16.11564913] loss: 30.518457389713735\n",
            "Epoch: 462 / 500 batch step: 450\n",
            "w1: [25.85363473] w2: [-23.59111337] bias: [16.07275851] loss: 30.524725451943713\n",
            "Epoch: 462 / 500 batch step: 480\n",
            "w1: [25.83656227] w2: [-23.5926904] bias: [16.04642302] loss: 30.531889553728284\n",
            "Epoch: 463 / 500 batch step: 0\n",
            "w1: [25.83022203] w2: [-23.5936182] bias: [16.03322004] loss: 30.53611290426069\n",
            "Epoch: 463 / 500 batch step: 30\n",
            "w1: [25.82336715] w2: [-23.59368853] bias: [16.01957624] loss: 30.541044126787455\n",
            "Epoch: 463 / 500 batch step: 60\n",
            "w1: [25.80157905] w2: [-23.6008229] bias: [15.97805403] loss: 30.560767890936425\n",
            "Epoch: 463 / 500 batch step: 90\n",
            "w1: [25.79504513] w2: [-23.6048012] bias: [15.96274581] loss: 30.56937508105526\n",
            "Epoch: 463 / 500 batch step: 120\n",
            "w1: [25.8049319] w2: [-23.57390055] bias: [15.99938727] loss: 30.549045004326533\n",
            "Epoch: 463 / 500 batch step: 150\n",
            "w1: [25.83941977] w2: [-23.57256772] bias: [16.043231] loss: 30.53088106341105\n",
            "Epoch: 463 / 500 batch step: 180\n",
            "w1: [25.90714361] w2: [-23.5555218] bias: [16.145841] loss: 30.51883503200901\n",
            "Epoch: 463 / 500 batch step: 210\n",
            "w1: [25.94411472] w2: [-23.5351127] bias: [16.20510973] loss: 30.531108538300426\n",
            "Epoch: 463 / 500 batch step: 240\n",
            "w1: [25.98312271] w2: [-23.52922066] bias: [16.24692233] loss: 30.549735214563125\n",
            "Epoch: 463 / 500 batch step: 270\n",
            "w1: [25.99948698] w2: [-23.52936013] bias: [16.2639122] loss: 30.559440376978877\n",
            "Epoch: 463 / 500 batch step: 300\n",
            "w1: [25.97968306] w2: [-23.53564368] bias: [16.22474305] loss: 30.541022596275603\n",
            "Epoch: 463 / 500 batch step: 330\n",
            "w1: [25.94344744] w2: [-23.54832551] bias: [16.15327658] loss: 30.52100551494079\n",
            "Epoch: 463 / 500 batch step: 360\n",
            "w1: [25.95488519] w2: [-23.51860131] bias: [16.24304135] loss: 30.544783874266802\n",
            "Epoch: 463 / 500 batch step: 390\n",
            "w1: [25.92935214] w2: [-23.53010312] bias: [16.2092675] loss: 30.53086688675513\n",
            "Epoch: 463 / 500 batch step: 420\n",
            "w1: [25.8802147] w2: [-23.57320229] bias: [16.1148132] loss: 30.518435899127084\n",
            "Epoch: 463 / 500 batch step: 450\n",
            "w1: [25.85498756] w2: [-23.59070491] bias: [16.07192195] loss: 30.524704230574834\n",
            "Epoch: 463 / 500 batch step: 480\n",
            "w1: [25.83791559] w2: [-23.59228137] bias: [16.0455878] loss: 30.531867862925836\n",
            "Epoch: 464 / 500 batch step: 0\n",
            "w1: [25.83157563] w2: [-23.59320892] bias: [16.03238563] loss: 30.536090914921115\n",
            "Epoch: 464 / 500 batch step: 30\n",
            "w1: [25.82472126] w2: [-23.59327894] bias: [16.01874305] loss: 30.54102158087199\n",
            "Epoch: 464 / 500 batch step: 60\n",
            "w1: [25.80293354] w2: [-23.60041307] bias: [15.97722183] loss: 30.560744469791647\n",
            "Epoch: 464 / 500 batch step: 90\n",
            "w1: [25.79639932] w2: [-23.60439127] bias: [15.96191345] loss: 30.56935167963905\n",
            "Epoch: 464 / 500 batch step: 120\n",
            "w1: [25.80628631] w2: [-23.5734902] bias: [15.99855563] loss: 30.54902103138384\n",
            "Epoch: 464 / 500 batch step: 150\n",
            "w1: [25.84077396] w2: [-23.57215701] bias: [16.04239984] loss: 30.530858064126797\n",
            "Epoch: 464 / 500 batch step: 180\n",
            "w1: [25.90849642] w2: [-23.5551111] bias: [16.14500823] loss: 30.518813915854228\n",
            "Epoch: 464 / 500 batch step: 210\n",
            "w1: [25.94546582] w2: [-23.53470203] bias: [16.20427511] loss: 30.53108736099147\n",
            "Epoch: 464 / 500 batch step: 240\n",
            "w1: [25.98447209] w2: [-23.52881017] bias: [16.24608598] loss: 30.54971366282034\n",
            "Epoch: 464 / 500 batch step: 270\n",
            "w1: [26.00083566] w2: [-23.52894963] bias: [16.2630751] loss: 30.559418526358353\n",
            "Epoch: 464 / 500 batch step: 300\n",
            "w1: [25.98103199] w2: [-23.53523293] bias: [16.22390679] loss: 30.541001424875816\n",
            "Epoch: 464 / 500 batch step: 330\n",
            "w1: [25.94479689] w2: [-23.5479145] bias: [16.15244154] loss: 30.520984996141273\n",
            "Epoch: 464 / 500 batch step: 360\n",
            "w1: [25.95623427] w2: [-23.51818953] bias: [16.24220796] loss: 30.544762525561257\n",
            "Epoch: 464 / 500 batch step: 390\n",
            "w1: [25.93070097] w2: [-23.52969119] bias: [16.20843441] loss: 30.53084535443133\n",
            "Epoch: 464 / 500 batch step: 420\n",
            "w1: [25.88156295] w2: [-23.57279095] bias: [16.11397912] loss: 30.51841453406462\n",
            "Epoch: 464 / 500 batch step: 450\n",
            "w1: [25.85633532] w2: [-23.59029383] bias: [16.07108724] loss: 30.524683136771685\n",
            "Epoch: 464 / 500 batch step: 480\n",
            "w1: [25.83926384] w2: [-23.59186973] bias: [16.04475442] loss: 30.531846306317238\n",
            "Epoch: 465 / 500 batch step: 0\n",
            "w1: [25.83292415] w2: [-23.59279703] bias: [16.03155306] loss: 30.536069062980555\n",
            "Epoch: 465 / 500 batch step: 30\n",
            "w1: [25.82607029] w2: [-23.59286674] bias: [16.01791168] loss: 30.540999175581312\n",
            "Epoch: 465 / 500 batch step: 60\n",
            "w1: [25.80428298] w2: [-23.60000064] bias: [15.97639147] loss: 30.560721191941763\n",
            "Epoch: 465 / 500 batch step: 90\n",
            "w1: [25.79774846] w2: [-23.60397874] bias: [15.96108293] loss: 30.569328419703705\n",
            "Epoch: 465 / 500 batch step: 120\n",
            "w1: [25.80763565] w2: [-23.57307726] bias: [15.99772581] loss: 30.548997216772417\n",
            "Epoch: 465 / 500 batch step: 150\n",
            "w1: [25.8421231] w2: [-23.5717437] bias: [16.0415705] loss: 30.530835207488266\n",
            "Epoch: 465 / 500 batch step: 180\n",
            "w1: [25.90984418] w2: [-23.5546978] bias: [16.1441773] loss: 30.518792923542346\n",
            "Epoch: 465 / 500 batch step: 210\n",
            "w1: [25.94681189] w2: [-23.53428878] bias: [16.20344236] loss: 30.53106630881226\n",
            "Epoch: 465 / 500 batch step: 240\n",
            "w1: [25.98581645] w2: [-23.52839709] bias: [16.2452515] loss: 30.549692238333016\n",
            "Epoch: 465 / 500 batch step: 270\n",
            "w1: [26.00217933] w2: [-23.52853653] bias: [16.26223989] loss: 30.559396809763744\n",
            "Epoch: 465 / 500 batch step: 300\n",
            "w1: [25.98237592] w2: [-23.53481959] bias: [16.22307243] loss: 30.54098038604677\n",
            "Epoch: 465 / 500 batch step: 330\n",
            "w1: [25.94614133] w2: [-23.54750089] bias: [16.15160841] loss: 30.520964602666016\n",
            "Epoch: 465 / 500 batch step: 360\n",
            "w1: [25.95757835] w2: [-23.51777518] bias: [16.24137646] loss: 30.544741316660826\n",
            "Epoch: 465 / 500 batch step: 390\n",
            "w1: [25.93204479] w2: [-23.52927669] bias: [16.20760318] loss: 30.53082395201266\n",
            "Epoch: 465 / 500 batch step: 420\n",
            "w1: [25.88290618] w2: [-23.57237705] bias: [16.11314689] loss: 30.5183932931699\n",
            "Epoch: 465 / 500 batch step: 450\n",
            "w1: [25.85767806] w2: [-23.5898802] bias: [16.07025437] loss: 30.524662169130714\n",
            "Epoch: 465 / 500 batch step: 480\n",
            "w1: [25.84060707] w2: [-23.59145554] bias: [16.04392288] loss: 30.531824882394126\n",
            "Epoch: 466 / 500 batch step: 0\n",
            "w1: [25.83426765] w2: [-23.59238259] bias: [16.03072233] loss: 30.53604734688261\n",
            "Epoch: 466 / 500 batch step: 30\n",
            "w1: [25.82741429] w2: [-23.59245199] bias: [16.01708215] loss: 30.540976909320083\n",
            "Epoch: 466 / 500 batch step: 60\n",
            "w1: [25.80562738] w2: [-23.59958566] bias: [15.97556295] loss: 30.560698055774612\n",
            "Epoch: 466 / 500 batch step: 90\n",
            "w1: [25.79909257] w2: [-23.60356366] bias: [15.96025426] loss: 30.56930529967004\n",
            "Epoch: 466 / 500 batch step: 120\n",
            "w1: [25.80897996] w2: [-23.57266179] bias: [15.99689782] loss: 30.548973558624073\n",
            "Epoch: 466 / 500 batch step: 150\n",
            "w1: [25.84346721] w2: [-23.57132786] bias: [16.040743] loss: 30.530812491880777\n",
            "Epoch: 466 / 500 batch step: 180\n",
            "w1: [25.91118693] w2: [-23.55428196] bias: [16.14334822] loss: 30.51877205373661\n",
            "Epoch: 466 / 500 batch step: 210\n",
            "w1: [25.94815296] w2: [-23.53387299] bias: [16.20261147] loss: 30.531045380405295\n",
            "Epoch: 466 / 500 batch step: 240\n",
            "w1: [25.98715582] w2: [-23.52798147] bias: [16.24441891] loss: 30.549670939718578\n",
            "Epoch: 466 / 500 batch step: 270\n",
            "w1: [26.00351802] w2: [-23.5281209] bias: [16.26140658] loss: 30.559375225698837\n",
            "Epoch: 466 / 500 batch step: 300\n",
            "w1: [25.98371488] w2: [-23.53440371] bias: [16.22223997] loss: 30.54095947829415\n",
            "Epoch: 466 / 500 batch step: 330\n",
            "w1: [25.9474808] w2: [-23.54708476] bias: [16.15077718] loss: 30.520944333130362\n",
            "Epoch: 466 / 500 batch step: 360\n",
            "w1: [25.95891746] w2: [-23.5173583] bias: [16.24054683] loss: 30.5447202459462\n",
            "Epoch: 466 / 500 batch step: 390\n",
            "w1: [25.93338363] w2: [-23.52885968] bias: [16.20677381] loss: 30.530802678069282\n",
            "Epoch: 466 / 500 batch step: 420\n",
            "w1: [25.88424443] w2: [-23.57196065] bias: [16.1123165] loss: 30.518372175112642\n",
            "Epoch: 466 / 500 batch step: 450\n",
            "w1: [25.85901581] w2: [-23.58946407] bias: [16.06942334] loss: 30.52464132627533\n",
            "Epoch: 466 / 500 batch step: 480\n",
            "w1: [25.84194531] w2: [-23.59103887] bias: [16.04309317] loss: 30.53180358967676\n",
            "Epoch: 467 / 500 batch step: 0\n",
            "w1: [25.83560617] w2: [-23.59196567] bias: [16.02989342] loss: 30.536025765100263\n",
            "Epoch: 467 / 500 batch step: 30\n",
            "w1: [25.82875331] w2: [-23.59203476] bias: [16.01625445] loss: 30.54095478052296\n",
            "Epoch: 467 / 500 batch step: 60\n",
            "w1: [25.80696681] w2: [-23.5991682] bias: [15.97473626] loss: 30.560675059708217\n",
            "Epoch: 467 / 500 batch step: 90\n",
            "w1: [25.8004317] w2: [-23.60314609] bias: [15.95942743] loss: 30.56928231798851\n",
            "Epoch: 467 / 500 batch step: 120\n",
            "w1: [25.81031929] w2: [-23.57224384] bias: [15.99607165] loss: 30.548950055104935\n",
            "Epoch: 467 / 500 batch step: 150\n",
            "w1: [25.84480634] w2: [-23.57090955] bias: [16.03991731] loss: 30.530789915719875\n",
            "Epoch: 467 / 500 batch step: 180\n",
            "w1: [25.91252471] w2: [-23.55386366] bias: [16.14252098] loss: 30.518751305126013\n",
            "Epoch: 467 / 500 batch step: 210\n",
            "w1: [25.94948908] w2: [-23.53345474] bias: [16.20178243] loss: 30.53102457443913\n",
            "Epoch: 467 / 500 batch step: 240\n",
            "w1: [25.98849025] w2: [-23.52756338] bias: [16.24358818] loss: 30.549649765620877\n",
            "Epoch: 467 / 500 batch step: 270\n",
            "w1: [26.00485179] w2: [-23.5277028] bias: [16.26057515] loss: 30.559353772695744\n",
            "Epoch: 467 / 500 batch step: 300\n",
            "w1: [25.98504891] w2: [-23.53398536] bias: [16.2214094] loss: 30.54093870015198\n",
            "Epoch: 467 / 500 batch step: 330\n",
            "w1: [25.94881536] w2: [-23.54666615] bias: [16.14994784] loss: 30.52092418617621\n",
            "Epoch: 467 / 500 batch step: 360\n",
            "w1: [25.96025165] w2: [-23.51693897] bias: [16.23971908] loss: 30.544699311828364\n",
            "Epoch: 467 / 500 batch step: 390\n",
            "w1: [25.93471754] w2: [-23.52844024] bias: [16.20594629] loss: 30.53078153119853\n",
            "Epoch: 467 / 500 batch step: 420\n",
            "w1: [25.88557774] w2: [-23.57154182] bias: [16.11148796] loss: 30.518351178588073\n",
            "Epoch: 467 / 500 batch step: 450\n",
            "w1: [25.86034863] w2: [-23.58904551] bias: [16.06859414] loss: 30.524620606855198\n",
            "Epoch: 467 / 500 batch step: 480\n",
            "w1: [25.84327861] w2: [-23.59061976] bias: [16.04226529] loss: 30.53178242671335\n",
            "Epoch: 468 / 500 batch step: 0\n",
            "w1: [25.83693974] w2: [-23.59154633] bias: [16.02906634] loss: 30.536004316135198\n",
            "Epoch: 468 / 500 batch step: 30\n",
            "w1: [25.83008739] w2: [-23.59161512] bias: [16.01542857] loss: 30.540932787653823\n",
            "Epoch: 468 / 500 batch step: 60\n",
            "w1: [25.8083013] w2: [-23.59874832] bias: [15.9739114] loss: 30.560652202190077\n",
            "Epoch: 468 / 500 batch step: 90\n",
            "w1: [25.80176591] w2: [-23.60272611] bias: [15.95860243] loss: 30.56925947313848\n",
            "Epoch: 468 / 500 batch step: 120\n",
            "w1: [25.81165368] w2: [-23.57182349] bias: [15.9952473] loss: 30.54892670441469\n",
            "Epoch: 468 / 500 batch step: 150\n",
            "w1: [25.84614054] w2: [-23.57048883] bias: [16.03909346] loss: 30.530767477450627\n",
            "Epoch: 468 / 500 batch step: 180\n",
            "w1: [25.91385757] w2: [-23.55344295] bias: [16.14169558] loss: 30.518730676424685\n",
            "Epoch: 468 / 500 batch step: 210\n",
            "w1: [25.95082029] w2: [-23.53303407] bias: [16.20095525] loss: 30.531003889607753\n",
            "Epoch: 468 / 500 batch step: 240\n",
            "w1: [25.98981979] w2: [-23.52714288] bias: [16.24275932] loss: 30.54962871470957\n",
            "Epoch: 468 / 500 batch step: 270\n",
            "w1: [26.00618067] w2: [-23.52728228] bias: [16.2597456] loss: 30.559332449314123\n",
            "Epoch: 468 / 500 batch step: 300\n",
            "w1: [25.98637806] w2: [-23.5335646] bias: [16.22058072] loss: 30.540918050181872\n",
            "Epoch: 468 / 500 batch step: 330\n",
            "w1: [25.95014503] w2: [-23.54624513] bias: [16.1491204] loss: 30.520904160471353\n",
            "Epoch: 468 / 500 batch step: 360\n",
            "w1: [25.96158095] w2: [-23.51651724] bias: [16.23889321] loss: 30.544678512747854\n",
            "Epoch: 468 / 500 batch step: 390\n",
            "w1: [25.93604656] w2: [-23.52801841] bias: [16.20512062] loss: 30.530760510024155\n",
            "Epoch: 468 / 500 batch step: 420\n",
            "w1: [25.88690615] w2: [-23.57112061] bias: [16.11066125] loss: 30.518330302316258\n",
            "Epoch: 468 / 500 batch step: 450\n",
            "w1: [25.86167654] w2: [-23.58862458] bias: [16.06776678] loss: 30.52460000954561\n",
            "Epoch: 468 / 500 batch step: 480\n",
            "w1: [25.84460701] w2: [-23.59019829] bias: [16.04143924] loss: 30.531761392079336\n",
            "Epoch: 469 / 500 batch step: 0\n",
            "w1: [25.83826841] w2: [-23.59112462] bias: [16.02824108] loss: 30.535982998517053\n",
            "Epoch: 469 / 500 batch step: 30\n",
            "w1: [25.83141657] w2: [-23.5911931] bias: [16.01460452] loss: 30.540910929205154\n",
            "Epoch: 469 / 500 batch step: 60\n",
            "w1: [25.80963089] w2: [-23.59832607] bias: [15.97308837] loss: 30.560629481696438\n",
            "Epoch: 469 / 500 batch step: 90\n",
            "w1: [25.80309522] w2: [-23.60230376] bias: [15.95777926] loss: 30.569236763627547\n",
            "Epoch: 469 / 500 batch step: 120\n",
            "w1: [25.81298316] w2: [-23.57140078] bias: [15.99442476] loss: 30.54890350478576\n",
            "Epoch: 469 / 500 batch step: 150\n",
            "w1: [25.84746984] w2: [-23.57006576] bias: [16.03827142] loss: 30.530745175546844\n",
            "Epoch: 469 / 500 batch step: 180\n",
            "w1: [25.91518556] w2: [-23.55301988] bias: [16.14087202] loss: 30.518710166371207\n",
            "Epoch: 469 / 500 batch step: 210\n",
            "w1: [25.95214663] w2: [-23.53261106] bias: [16.20012991] loss: 30.53098332462992\n",
            "Epoch: 469 / 500 batch step: 240\n",
            "w1: [25.99114447] w2: [-23.52672003] bias: [16.24193232] loss: 30.54960778567944\n",
            "Epoch: 469 / 500 batch step: 270\n",
            "w1: [26.00750471] w2: [-23.52685942] bias: [16.25891794] loss: 30.559311254140585\n",
            "Epoch: 469 / 500 batch step: 300\n",
            "w1: [25.98770237] w2: [-23.53314148] bias: [16.21975392] loss: 30.540897526972387\n",
            "Epoch: 469 / 500 batch step: 330\n",
            "w1: [25.95146986] w2: [-23.54582176] bias: [16.14829484] loss: 30.52088425470882\n",
            "Epoch: 469 / 500 batch step: 360\n",
            "w1: [25.96290541] w2: [-23.51609318] bias: [16.2380692] loss: 30.54465784717408\n",
            "Epoch: 469 / 500 batch step: 390\n",
            "w1: [25.93737073] w2: [-23.52759427] bias: [16.2042968] loss: 30.53073961319572\n",
            "Epoch: 469 / 500 batch step: 420\n",
            "w1: [25.88822971] w2: [-23.57069709] bias: [16.10983638] loss: 30.518309545041507\n",
            "Epoch: 469 / 500 batch step: 450\n",
            "w1: [25.8629996] w2: [-23.58820134] bias: [16.06694124] loss: 30.524579533046843\n",
            "Epoch: 469 / 500 batch step: 480\n",
            "w1: [25.84593055] w2: [-23.58977451] bias: [16.04061501] loss: 30.531740484376723\n",
            "Epoch: 470 / 500 batch step: 0\n",
            "w1: [25.83959222] w2: [-23.5907006] bias: [16.02741764] loss: 30.53596181080278\n",
            "Epoch: 470 / 500 batch step: 30\n",
            "w1: [25.83274089] w2: [-23.59076879] bias: [16.01378228] loss: 30.540889203697258\n",
            "Epoch: 470 / 500 batch step: 60\n",
            "w1: [25.81095563] w2: [-23.59790153] bias: [15.97226716] loss: 30.56060689673159\n",
            "Epoch: 470 / 500 batch step: 90\n",
            "w1: [25.80441967] w2: [-23.60187911] bias: [15.95695792] loss: 30.56921418799083\n",
            "Epoch: 470 / 500 batch step: 120\n",
            "w1: [25.81430779] w2: [-23.57097579] bias: [15.99360403] loss: 30.54888045448258\n",
            "Epoch: 470 / 500 batch step: 150\n",
            "w1: [25.8487943] w2: [-23.56964041] bias: [16.03745119] loss: 30.53072300851046\n",
            "Epoch: 470 / 500 batch step: 180\n",
            "w1: [25.9165087] w2: [-23.55259453] bias: [16.14005029] loss: 30.51868977372803\n",
            "Epoch: 470 / 500 batch step: 210\n",
            "w1: [25.95346814] w2: [-23.53218576] bias: [16.19930642] loss: 30.530962878248545\n",
            "Epoch: 470 / 500 batch step: 240\n",
            "w1: [25.99246433] w2: [-23.52629489] bias: [16.24110719] loss: 30.549586977249778\n",
            "Epoch: 470 / 500 batch step: 270\n",
            "w1: [26.00882394] w2: [-23.52643426] bias: [16.25809215] loss: 30.559290185787994\n",
            "Epoch: 470 / 500 batch step: 300\n",
            "w1: [25.98902187] w2: [-23.53271608] bias: [16.218929] loss: 30.540877129138355\n",
            "Epoch: 470 / 500 batch step: 330\n",
            "w1: [25.95278989] w2: [-23.54539609] bias: [16.14747116] loss: 30.52086446760624\n",
            "Epoch: 470 / 500 batch step: 360\n",
            "w1: [25.96422507] w2: [-23.51566683] bias: [16.23724705] loss: 30.544637313604596\n",
            "Epoch: 470 / 500 batch step: 390\n",
            "w1: [25.93869009] w2: [-23.52716786] bias: [16.20347481] loss: 30.530718839387962\n",
            "Epoch: 470 / 500 batch step: 420\n",
            "w1: [25.88954845] w2: [-23.57027131] bias: [16.10901334] loss: 30.518288905531705\n",
            "Epoch: 470 / 500 batch step: 450\n",
            "w1: [25.86431784] w2: [-23.58777584] bias: [16.06611754] loss: 30.52455917608349\n",
            "Epoch: 470 / 500 batch step: 480\n",
            "w1: [25.84724928] w2: [-23.58934847] bias: [16.0397926] loss: 30.53171970223346\n",
            "Epoch: 471 / 500 batch step: 0\n",
            "w1: [25.84091122] w2: [-23.59027434] bias: [16.02659602] loss: 30.535940751575957\n",
            "Epoch: 471 / 500 batch step: 30\n",
            "w1: [25.83406039] w2: [-23.59034223] bias: [16.01296186] loss: 30.540867609677647\n",
            "Epoch: 471 / 500 batch step: 60\n",
            "w1: [25.81227555] w2: [-23.59747473] bias: [15.97144778] loss: 30.560584445827214\n",
            "Epoch: 471 / 500 batch step: 90\n",
            "w1: [25.80573932] w2: [-23.60145222] bias: [15.95613841] loss: 30.569191744790327\n",
            "Epoch: 471 / 500 batch step: 120\n",
            "w1: [25.8156276] w2: [-23.57054856] bias: [15.9927851] loss: 30.54885755180085\n",
            "Epoch: 471 / 500 batch step: 150\n",
            "w1: [25.85011394] w2: [-23.56921281] bias: [16.03663278] loss: 30.530700974870815\n",
            "Epoch: 471 / 500 batch step: 180\n",
            "w1: [25.91782704] w2: [-23.55216694] bias: [16.13923039] loss: 30.518669497280836\n",
            "Epoch: 471 / 500 batch step: 210\n",
            "w1: [25.95478487] w2: [-23.53175822] bias: [16.19848477] loss: 30.530942549230083\n",
            "Epoch: 471 / 500 batch step: 240\n",
            "w1: [25.99377942] w2: [-23.52586751] bias: [16.24028391] loss: 30.549566288163756\n",
            "Epoch: 471 / 500 batch step: 270\n",
            "w1: [26.0101384] w2: [-23.52600687] bias: [16.25726823] loss: 30.55926924289482\n",
            "Epoch: 471 / 500 batch step: 300\n",
            "w1: [25.99033662] w2: [-23.53228844] bias: [16.21810596] loss: 30.540856855320243\n",
            "Epoch: 471 / 500 batch step: 330\n",
            "w1: [25.95410516] w2: [-23.54496819] bias: [16.14664936] loss: 30.52084479790523\n",
            "Epoch: 471 / 500 batch step: 360\n",
            "w1: [25.96553996] w2: [-23.51523827] bias: [16.23642677] loss: 30.54461691056445\n",
            "Epoch: 471 / 500 batch step: 390\n",
            "w1: [25.94000468] w2: [-23.52673924] bias: [16.20265467] loss: 30.530698187300114\n",
            "Epoch: 471 / 500 batch step: 420\n",
            "w1: [25.89086242] w2: [-23.56984333] bias: [16.10819212] loss: 30.518268382577794\n",
            "Epoch: 471 / 500 batch step: 450\n",
            "w1: [25.8656313] w2: [-23.58734814] bias: [16.06529565] loss: 30.524538937403907\n",
            "Epoch: 471 / 500 batch step: 480\n",
            "w1: [25.84856322] w2: [-23.58892025] bias: [16.03897201] loss: 30.53169904430275\n",
            "Epoch: 472 / 500 batch step: 0\n",
            "w1: [25.84222543] w2: [-23.58984588] bias: [16.02577621] loss: 30.53591981944616\n",
            "Epoch: 472 / 500 batch step: 30\n",
            "w1: [25.83537511] w2: [-23.58991349] bias: [16.01214325] loss: 30.540846145720373\n",
            "Epoch: 472 / 500 batch step: 60\n",
            "w1: [25.8135907] w2: [-23.59704575] bias: [15.97063021] loss: 30.56056212754172\n",
            "Epoch: 472 / 500 batch step: 90\n",
            "w1: [25.80705419] w2: [-23.60102314] bias: [15.95532071] loss: 30.56916943261425\n",
            "Epoch: 472 / 500 batch step: 120\n",
            "w1: [25.81694264] w2: [-23.57011915] bias: [15.99196798] loss: 30.54883479506683\n",
            "Epoch: 472 / 500 batch step: 150\n",
            "w1: [25.8514288] w2: [-23.56878305] bias: [16.03581618] loss: 30.530679073184018\n",
            "Epoch: 472 / 500 batch step: 180\n",
            "w1: [25.91914063] w2: [-23.55173718] bias: [16.13841232] loss: 30.51864933583797\n",
            "Epoch: 472 / 500 batch step: 210\n",
            "w1: [25.95609684] w2: [-23.53132851] bias: [16.19766496] loss: 30.53092233636392\n",
            "Epoch: 472 / 500 batch step: 240\n",
            "w1: [25.99508977] w2: [-23.52543796] bias: [16.23946248] loss: 30.54954571718787\n",
            "Epoch: 472 / 500 batch step: 270\n",
            "w1: [26.01144814] w2: [-23.52557729] bias: [16.25644617] loss: 30.559248424124533\n",
            "Epoch: 472 / 500 batch step: 300\n",
            "w1: [25.99164664] w2: [-23.53185862] bias: [16.21728479] loss: 30.54083670418351\n",
            "Epoch: 472 / 500 batch step: 330\n",
            "w1: [25.95541572] w2: [-23.54453812] bias: [16.14582944] loss: 30.52082524437081\n",
            "Epoch: 472 / 500 batch step: 360\n",
            "w1: [25.96685014] w2: [-23.51480754] bias: [16.23560834] loss: 30.544596636605533\n",
            "Epoch: 472 / 500 batch step: 390\n",
            "w1: [25.94131454] w2: [-23.52630847] bias: [16.20183636] loss: 30.530677655655396\n",
            "Epoch: 472 / 500 batch step: 420\n",
            "w1: [25.89217165] w2: [-23.56941321] bias: [16.10737273] loss: 30.518247974993105\n",
            "Epoch: 472 / 500 batch step: 450\n",
            "w1: [25.86694003] w2: [-23.5869183] bias: [16.06447558] loss: 30.524518815779583\n",
            "Epoch: 472 / 500 batch step: 480\n",
            "w1: [25.84987243] w2: [-23.58848988] bias: [16.03815323] loss: 30.531678509262505\n",
            "Epoch: 473 / 500 batch step: 0\n",
            "w1: [25.84353491] w2: [-23.58941529] bias: [16.02495821] loss: 30.535899013048333\n",
            "Epoch: 473 / 500 batch step: 30\n",
            "w1: [25.8366851] w2: [-23.58948261] bias: [16.01132645] loss: 30.54082481042538\n",
            "Epoch: 473 / 500 batch step: 60\n",
            "w1: [25.81490112] w2: [-23.59661464] bias: [15.96981445] loss: 30.560539940459616\n",
            "Epoch: 473 / 500 batch step: 90\n",
            "w1: [25.80836433] w2: [-23.60059192] bias: [15.95450484] loss: 30.569147250076416\n",
            "Epoch: 473 / 500 batch step: 120\n",
            "w1: [25.81825293] w2: [-23.56968763] bias: [15.99115266] loss: 30.548812182636617\n",
            "Epoch: 473 / 500 batch step: 150\n",
            "w1: [25.85273894] w2: [-23.56835116] bias: [16.03500138] loss: 30.530657302032296\n",
            "Epoch: 473 / 500 batch step: 180\n",
            "w1: [25.92044949] w2: [-23.5513053] bias: [16.13759607] loss: 30.518629288229885\n",
            "Epoch: 473 / 500 batch step: 210\n",
            "w1: [25.95740411] w2: [-23.53089668] bias: [16.19684698] loss: 30.530902238461845\n",
            "Epoch: 473 / 500 batch step: 240\n",
            "w1: [25.99639542] w2: [-23.52500628] bias: [16.2386429] loss: 30.549525263111295\n",
            "Epoch: 473 / 500 batch step: 270\n",
            "w1: [26.01275319] w2: [-23.5251456] bias: [16.25562598] loss: 30.559227728165\n",
            "Epoch: 473 / 500 batch step: 300\n",
            "w1: [25.99295197] w2: [-23.53142668] bias: [16.21646548] loss: 30.540816674418036\n",
            "Epoch: 473 / 500 batch step: 330\n",
            "w1: [25.95672158] w2: [-23.54410592] bias: [16.14501138] loss: 30.52080580579079\n",
            "Epoch: 473 / 500 batch step: 360\n",
            "w1: [25.96815562] w2: [-23.5143747] bias: [16.23479176] loss: 30.54457649030596\n",
            "Epoch: 473 / 500 batch step: 390\n",
            "w1: [25.9426197] w2: [-23.52587561] bias: [16.20101988] loss: 30.530657243200334\n",
            "Epoch: 473 / 500 batch step: 420\n",
            "w1: [25.89347619] w2: [-23.568981] bias: [16.10655517] loss: 30.518227681612874\n",
            "Epoch: 473 / 500 batch step: 450\n",
            "w1: [25.86824405] w2: [-23.58648638] bias: [16.06365733] loss: 30.524498810004605\n",
            "Epoch: 473 / 500 batch step: 480\n",
            "w1: [25.85117694] w2: [-23.58805744] bias: [16.03733626] loss: 30.53165809581471\n",
            "Epoch: 474 / 500 batch step: 0\n",
            "w1: [25.84483969] w2: [-23.58898262] bias: [16.02414202] loss: 30.535878331042177\n",
            "Epoch: 474 / 500 batch step: 30\n",
            "w1: [25.83799039] w2: [-23.58904965] bias: [16.01051145] loss: 30.54080360241792\n",
            "Epoch: 474 / 500 batch step: 60\n",
            "w1: [25.81620683] w2: [-23.59618145] bias: [15.96900051] loss: 30.560517883190865\n",
            "Epoch: 474 / 500 batch step: 90\n",
            "w1: [25.80966978] w2: [-23.60015863] bias: [15.95369077] loss: 30.569125195815612\n",
            "Epoch: 474 / 500 batch step: 120\n",
            "w1: [25.81955853] w2: [-23.56925403] bias: [15.99033914] loss: 30.548789712895495\n",
            "Epoch: 474 / 500 batch step: 150\n",
            "w1: [25.85404438] w2: [-23.56791721] bias: [16.03418839] loss: 30.530635660023414\n",
            "Epoch: 474 / 500 batch step: 180\n",
            "w1: [25.92175368] w2: [-23.55087135] bias: [16.13678163] loss: 30.51860935330855\n",
            "Epoch: 474 / 500 batch step: 210\n",
            "w1: [25.9587067] w2: [-23.53046279] bias: [16.19603083] loss: 30.530882254357465\n",
            "Epoch: 474 / 500 batch step: 240\n",
            "w1: [25.99769642] w2: [-23.52457254] bias: [16.23782517] loss: 30.54950492474539\n",
            "Epoch: 474 / 500 batch step: 270\n",
            "w1: [26.01405359] w2: [-23.52471184] bias: [16.25480765] loss: 30.55920715372785\n",
            "Epoch: 474 / 500 batch step: 300\n",
            "w1: [25.99425266] w2: [-23.53099267] bias: [16.21564803] loss: 30.540796764737514\n",
            "Epoch: 474 / 500 batch step: 330\n",
            "w1: [25.95802281] w2: [-23.54367165] bias: [16.14419519] loss: 30.520786480975254\n",
            "Epoch: 474 / 500 batch step: 360\n",
            "w1: [25.96945647] w2: [-23.51393981] bias: [16.23397703] loss: 30.5445564702694\n",
            "Epoch: 474 / 500 batch step: 390\n",
            "w1: [25.94392022] w2: [-23.52544071] bias: [16.20020522] loss: 30.53063694870426\n",
            "Epoch: 474 / 500 batch step: 420\n",
            "w1: [25.89477607] w2: [-23.56854675] bias: [16.10573941] loss: 30.518207501293656\n",
            "Epoch: 474 / 500 batch step: 450\n",
            "w1: [25.86954342] w2: [-23.58605242] bias: [16.06284089] loss: 30.52447891889506\n",
            "Epoch: 474 / 500 batch step: 480\n",
            "w1: [25.85247678] w2: [-23.58762296] bias: [16.0365211] loss: 30.531637802684813\n",
            "Epoch: 475 / 500 batch step: 0\n",
            "w1: [25.8461398] w2: [-23.58854793] bias: [16.02332764] loss: 30.53585777211156\n",
            "Epoch: 475 / 500 batch step: 30\n",
            "w1: [25.83929101] w2: [-23.58861468] bias: [16.00969826] loss: 30.540782520347918\n",
            "Epoch: 475 / 500 batch step: 60\n",
            "w1: [25.81750789] w2: [-23.59574623] bias: [15.96818837] loss: 30.56049595437032\n",
            "Epoch: 475 / 500 batch step: 90\n",
            "w1: [25.81097058] w2: [-23.59972332] bias: [15.95287852] loss: 30.569103268495038\n",
            "Epoch: 475 / 500 batch step: 120\n",
            "w1: [25.82085947] w2: [-23.56881842] bias: [15.98952741] loss: 30.54876738425724\n",
            "Epoch: 475 / 500 batch step: 150\n",
            "w1: [25.85534517] w2: [-23.56748124] bias: [16.03337719] loss: 30.53061414579001\n",
            "Epoch: 475 / 500 batch step: 180\n",
            "w1: [25.92305322] w2: [-23.55043538] bias: [16.13596901] loss: 30.51858952994696\n",
            "Epoch: 475 / 500 batch step: 210\n",
            "w1: [25.96000467] w2: [-23.53002688] bias: [16.19521651] loss: 30.530862382905664\n",
            "Epoch: 475 / 500 batch step: 240\n",
            "w1: [25.99899279] w2: [-23.52413679] bias: [16.23700927] loss: 30.549484700923113\n",
            "Epoch: 475 / 500 batch step: 270\n",
            "w1: [26.01534938] w2: [-23.52427606] bias: [16.25399117] loss: 30.559186699547993\n",
            "Epoch: 475 / 500 batch step: 300\n",
            "w1: [25.99554874] w2: [-23.53055665] bias: [16.21483244] loss: 30.540776973878856\n",
            "Epoch: 475 / 500 batch step: 330\n",
            "w1: [25.95931943] w2: [-23.54323537] bias: [16.14338086] loss: 30.520767268755964\n",
            "Epoch: 475 / 500 batch step: 360\n",
            "w1: [25.9707527] w2: [-23.51350292] bias: [16.23316414] loss: 30.544536575124546\n",
            "Epoch: 475 / 500 batch step: 390\n",
            "w1: [25.94521611] w2: [-23.52500382] bias: [16.19939239] loss: 30.53061677095872\n",
            "Epoch: 475 / 500 batch step: 420\n",
            "w1: [25.89607133] w2: [-23.56811052] bias: [16.10492548] loss: 30.518187432912807\n",
            "Epoch: 475 / 500 batch step: 450\n",
            "w1: [25.87083817] w2: [-23.58561649] bias: [16.06202626] loss: 30.524459141288524\n",
            "Epoch: 475 / 500 batch step: 480\n",
            "w1: [25.85377201] w2: [-23.58718651] bias: [16.03570774] loss: 30.531617628621234\n",
            "Epoch: 476 / 500 batch step: 0\n",
            "w1: [25.8474353] w2: [-23.58811126] bias: [16.02251505] loss: 30.535837334963936\n",
            "Epoch: 476 / 500 batch step: 30\n",
            "w1: [25.84058701] w2: [-23.58817773] bias: [16.00888686] loss: 30.540761562889415\n",
            "Epoch: 476 / 500 batch step: 60\n",
            "w1: [25.81880433] w2: [-23.59530905] bias: [15.96737804] loss: 30.56047415265711\n",
            "Epoch: 476 / 500 batch step: 90\n",
            "w1: [25.81226676] w2: [-23.59928604] bias: [15.95206808] loss: 30.569081466801673\n",
            "Epoch: 476 / 500 batch step: 120\n",
            "w1: [25.82215578] w2: [-23.56838086] bias: [15.98871747] loss: 30.548745195163512\n",
            "Epoch: 476 / 500 batch step: 150\n",
            "w1: [25.85664133] w2: [-23.56704332] bias: [16.03256779] loss: 30.53059275798907\n",
            "Epoch: 476 / 500 batch step: 180\n",
            "w1: [25.92434815] w2: [-23.54999746] bias: [16.13515821] loss: 30.518569817038564\n",
            "Epoch: 476 / 500 batch step: 210\n",
            "w1: [25.96129804] w2: [-23.52958901] bias: [16.19440401] loss: 30.530842622982053\n",
            "Epoch: 476 / 500 batch step: 240\n",
            "w1: [26.00028458] w2: [-23.52369907] bias: [16.23619522] loss: 30.549464590498506\n",
            "Epoch: 476 / 500 batch step: 270\n",
            "w1: [26.0166406] w2: [-23.52383833] bias: [16.25317654] loss: 30.559166364382957\n",
            "Epoch: 476 / 500 batch step: 300\n",
            "w1: [25.99684025] w2: [-23.53011867] bias: [16.21401871] loss: 30.540757300601676\n",
            "Epoch: 476 / 500 batch step: 330\n",
            "w1: [25.96061147] w2: [-23.54279713] bias: [16.14256838] loss: 30.520748167985875\n",
            "Epoch: 476 / 500 batch step: 360\n",
            "w1: [25.97204436] w2: [-23.51306408] bias: [16.23235309] loss: 30.544516803524473\n",
            "Epoch: 476 / 500 batch step: 390\n",
            "w1: [25.94650743] w2: [-23.52456499] bias: [16.19858138] loss: 30.530596708776947\n",
            "Epoch: 476 / 500 batch step: 420\n",
            "w1: [25.89736201] w2: [-23.56767236] bias: [16.10411335] loss: 30.51816747536796\n",
            "Epoch: 476 / 500 batch step: 450\n",
            "w1: [25.87212833] w2: [-23.58517862] bias: [16.06121344] loss: 30.524439476043526\n",
            "Epoch: 476 / 500 batch step: 480\n",
            "w1: [25.85506264] w2: [-23.58674813] bias: [16.03489618] loss: 30.53159757239477\n",
            "Epoch: 477 / 500 batch step: 0\n",
            "w1: [25.8487262] w2: [-23.58767267] bias: [16.02170426] loss: 30.535817018329798\n",
            "Epoch: 477 / 500 batch step: 30\n",
            "w1: [25.84187843] w2: [-23.58773886] bias: [16.00807726] loss: 30.540740728739966\n",
            "Epoch: 477 / 500 batch step: 60\n",
            "w1: [25.82009618] w2: [-23.59486994] bias: [15.9665695] loss: 30.56045247673407\n",
            "Epoch: 477 / 500 batch step: 90\n",
            "w1: [25.81355835] w2: [-23.59884683] bias: [15.95125943] loss: 30.56905978944578\n",
            "Epoch: 477 / 500 batch step: 120\n",
            "w1: [25.82344751] w2: [-23.56794138] bias: [15.98790932] loss: 30.54872314408321\n",
            "Epoch: 477 / 500 batch step: 150\n",
            "w1: [25.85793292] w2: [-23.56660349] bias: [16.03176019] loss: 30.53057149530132\n",
            "Epoch: 477 / 500 batch step: 180\n",
            "w1: [25.92563852] w2: [-23.54955763] bias: [16.13434921] loss: 30.51855021349681\n",
            "Epoch: 477 / 500 batch step: 210\n",
            "w1: [25.96258684] w2: [-23.52914924] bias: [16.19359333] loss: 30.53082297348253\n",
            "Epoch: 477 / 500 batch step: 240\n",
            "w1: [26.00157183] w2: [-23.52325945] bias: [16.23538299] loss: 30.549444592346152\n",
            "Epoch: 477 / 500 batch step: 270\n",
            "w1: [26.01792728] w2: [-23.52339868] bias: [16.25236376] loss: 30.559146147012417\n",
            "Epoch: 477 / 500 batch step: 300\n",
            "w1: [25.99812722] w2: [-23.52967878] bias: [16.21320682] loss: 30.54073774368772\n",
            "Epoch: 477 / 500 batch step: 330\n",
            "w1: [25.96189899] w2: [-23.54235698] bias: [16.14175776] loss: 30.520729177538563\n",
            "Epoch: 477 / 500 batch step: 360\n",
            "w1: [25.97333149] w2: [-23.51262334] bias: [16.23154388] loss: 30.544497154146107\n",
            "Epoch: 477 / 500 batch step: 390\n",
            "w1: [25.94779421] w2: [-23.52412428] bias: [16.19777219] loss: 30.530576760993345\n",
            "Epoch: 477 / 500 batch step: 420\n",
            "w1: [25.89864814] w2: [-23.56723232] bias: [16.10330303] loss: 30.518147627576532\n",
            "Epoch: 477 / 500 batch step: 450\n",
            "w1: [25.87341395] w2: [-23.58473888] bias: [16.06040241] loss: 30.52441992203903\n",
            "Epoch: 477 / 500 batch step: 480\n",
            "w1: [25.85634873] w2: [-23.58630789] bias: [16.03408642] loss: 30.531577632798033\n",
            "Epoch: 478 / 500 batch step: 0\n",
            "w1: [25.85001256] w2: [-23.58723221] bias: [16.02089527] loss: 30.53579682096212\n",
            "Epoch: 478 / 500 batch step: 30\n",
            "w1: [25.84316529] w2: [-23.58729813] bias: [16.00726946] loss: 30.540720016620146\n",
            "Epoch: 478 / 500 batch step: 60\n",
            "w1: [25.82138349] w2: [-23.59442897] bias: [15.96576276] loss: 30.56043092530721\n",
            "Epoch: 478 / 500 batch step: 90\n",
            "w1: [25.81484541] w2: [-23.59840577] bias: [15.95045259] loss: 30.569038235160296\n",
            "Epoch: 478 / 500 batch step: 120\n",
            "w1: [25.82473469] w2: [-23.56750005] bias: [15.98710296] loss: 30.548701229511835\n",
            "Epoch: 478 / 500 batch step: 150\n",
            "w1: [25.85921996] w2: [-23.5661618] bias: [16.03095437] loss: 30.530550356430677\n",
            "Epoch: 478 / 500 batch step: 180\n",
            "w1: [25.92692435] w2: [-23.54911594] bias: [16.13354201] loss: 30.518530718254592\n",
            "Epoch: 478 / 500 batch step: 210\n",
            "w1: [25.96387113] w2: [-23.52870761] bias: [16.19278447] loss: 30.530803433322703\n",
            "Epoch: 478 / 500 batch step: 240\n",
            "w1: [26.00285456] w2: [-23.52281798] bias: [16.23457259] loss: 30.549424705360728\n",
            "Epoch: 478 / 500 batch step: 270\n",
            "w1: [26.01920945] w2: [-23.52295718] bias: [16.25155282] loss: 30.559126046237655\n",
            "Epoch: 478 / 500 batch step: 300\n",
            "w1: [25.9994097] w2: [-23.52923703] bias: [16.21239678] loss: 30.540718301940355\n",
            "Epoch: 478 / 500 batch step: 330\n",
            "w1: [25.96318201] w2: [-23.54191497] bias: [16.14094899] loss: 30.52071029630776\n",
            "Epoch: 478 / 500 batch step: 360\n",
            "w1: [25.97461412] w2: [-23.51218076] bias: [16.2307365] loss: 30.544477625689662\n",
            "Epoch: 478 / 500 batch step: 390\n",
            "w1: [25.94907649] w2: [-23.52368174] bias: [16.19696481] loss: 30.530556926462953\n",
            "Epoch: 478 / 500 batch step: 420\n",
            "w1: [25.89992976] w2: [-23.56679045] bias: [16.10249451] loss: 30.51812788847524\n",
            "Epoch: 478 / 500 batch step: 450\n",
            "w1: [25.87469505] w2: [-23.58429732] bias: [16.05959319] loss: 30.52440047817394\n",
            "Epoch: 478 / 500 batch step: 480\n",
            "w1: [25.85763031] w2: [-23.58586582] bias: [16.03327845] loss: 30.531557808645\n",
            "Epoch: 479 / 500 batch step: 0\n",
            "w1: [25.8512944] w2: [-23.58678993] bias: [16.02008806] loss: 30.535776741635836\n",
            "Epoch: 479 / 500 batch step: 30\n",
            "w1: [25.84444765] w2: [-23.58685558] bias: [16.00646344] loss: 30.540699425272937\n",
            "Epoch: 479 / 500 batch step: 60\n",
            "w1: [25.82266629] w2: [-23.59398619] bias: [15.96495782] loss: 30.560409497105134\n",
            "Epoch: 479 / 500 batch step: 90\n",
            "w1: [25.81612796] w2: [-23.59796288] bias: [15.94964755] loss: 30.569016802700336\n",
            "Epoch: 479 / 500 batch step: 120\n",
            "w1: [25.82601735] w2: [-23.56705692] bias: [15.98629837] loss: 30.54867944997095\n",
            "Epoch: 479 / 500 batch step: 150\n",
            "w1: [25.8605025] w2: [-23.56571831] bias: [16.03015034] loss: 30.53052934010373\n",
            "Epoch: 479 / 500 batch step: 180\n",
            "w1: [25.92820569] w2: [-23.54867245] bias: [16.13273662] loss: 30.518511330263824\n",
            "Epoch: 479 / 500 batch step: 210\n",
            "w1: [25.96515093] w2: [-23.52826418] bias: [16.19197742] loss: 30.530784001437464\n",
            "Epoch: 479 / 500 batch step: 240\n",
            "w1: [26.00413282] w2: [-23.52237469] bias: [16.23376402] loss: 30.549404928456454\n",
            "Epoch: 479 / 500 batch step: 270\n",
            "w1: [26.02048716] w2: [-23.52251387] bias: [16.25074372] loss: 30.55910606088102\n",
            "Epoch: 479 / 500 batch step: 300\n",
            "w1: [26.00068771] w2: [-23.52879348] bias: [16.21158858] loss: 30.54069897418403\n",
            "Epoch: 479 / 500 batch step: 330\n",
            "w1: [25.96446057] w2: [-23.54147115] bias: [16.14014205] loss: 30.52069152320687\n",
            "Epoch: 479 / 500 batch step: 360\n",
            "w1: [25.97589228] w2: [-23.51173639] bias: [16.22993095] loss: 30.544458216878066\n",
            "Epoch: 479 / 500 batch step: 390\n",
            "w1: [25.95035429] w2: [-23.52323742] bias: [16.19615923] loss: 30.530537204061\n",
            "Epoch: 479 / 500 batch step: 420\n",
            "w1: [25.90120691] w2: [-23.56634681] bias: [16.10168779] loss: 30.51810825701961\n",
            "Epoch: 479 / 500 batch step: 450\n",
            "w1: [25.87597168] w2: [-23.58385398] bias: [16.05878576] loss: 30.52438114336664\n",
            "Epoch: 479 / 500 batch step: 480\n",
            "w1: [25.85890741] w2: [-23.58542198] bias: [16.03247228] loss: 30.53153809877046\n",
            "Epoch: 480 / 500 batch step: 0\n",
            "w1: [25.85257177] w2: [-23.58634588] bias: [16.01928265] loss: 30.535756779147324\n",
            "Epoch: 480 / 500 batch step: 30\n",
            "w1: [25.84572552] w2: [-23.58641127] bias: [16.00565921] loss: 30.540678953463278\n",
            "Epoch: 480 / 500 batch step: 60\n",
            "w1: [25.82394462] w2: [-23.59354163] bias: [15.96415467] loss: 30.56038819087855\n",
            "Epoch: 480 / 500 batch step: 90\n",
            "w1: [25.81740603] w2: [-23.59751823] bias: [15.9488443] loss: 30.568995490842664\n",
            "Epoch: 480 / 500 batch step: 120\n",
            "w1: [25.82729554] w2: [-23.56661202] bias: [15.98549557] loss: 30.54865780400755\n",
            "Epoch: 480 / 500 batch step: 150\n",
            "w1: [25.86178056] w2: [-23.56527306] bias: [16.02934809] loss: 30.53050844506919\n",
            "Epoch: 480 / 500 batch step: 180\n",
            "w1: [25.92948256] w2: [-23.5482272] bias: [16.13193303] loss: 30.51849204849495\n",
            "Epoch: 480 / 500 batch step: 210\n",
            "w1: [25.96642629] w2: [-23.52781899] bias: [16.19117217] loss: 30.530764676780482\n",
            "Epoch: 480 / 500 batch step: 240\n",
            "w1: [26.00540663] w2: [-23.52192965] bias: [16.23295727] loss: 30.54938526056664\n",
            "Epoch: 480 / 500 batch step: 270\n",
            "w1: [26.02176044] w2: [-23.5220688] bias: [16.24993645] loss: 30.559086189785454\n",
            "Epoch: 480 / 500 batch step: 300\n",
            "w1: [26.00196129] w2: [-23.52834816] bias: [16.21078222] loss: 30.54067975926381\n",
            "Epoch: 480 / 500 batch step: 330\n",
            "w1: [25.9657347] w2: [-23.54102558] bias: [16.13933696] loss: 30.520672857168453\n",
            "Epoch: 480 / 500 batch step: 360\n",
            "w1: [25.97716602] w2: [-23.51129027] bias: [16.22912721] loss: 30.544438926456493\n",
            "Epoch: 480 / 500 batch step: 390\n",
            "w1: [25.95162766] w2: [-23.52279136] bias: [16.19535547] loss: 30.530517592682358\n",
            "Epoch: 480 / 500 batch step: 420\n",
            "w1: [25.90247962] w2: [-23.56590144] bias: [16.10088287] loss: 30.51808873218356\n",
            "Epoch: 480 / 500 batch step: 450\n",
            "w1: [25.87724387] w2: [-23.58340891] bias: [16.05798012] loss: 30.524361916554476\n",
            "Epoch: 480 / 500 batch step: 480\n",
            "w1: [25.86018007] w2: [-23.58497642] bias: [16.03166789] loss: 30.531518502029517\n",
            "Epoch: 481 / 500 batch step: 0\n",
            "w1: [25.85384469] w2: [-23.58590012] bias: [16.01847901] loss: 30.53573693231388\n",
            "Epoch: 481 / 500 batch step: 30\n",
            "w1: [25.84699896] w2: [-23.58596523] bias: [16.00485676] loss: 30.540658599977505\n",
            "Epoch: 481 / 500 batch step: 60\n",
            "w1: [25.8252185] w2: [-23.59309536] bias: [15.9633533] loss: 30.56036700539977\n",
            "Epoch: 481 / 500 batch step: 90\n",
            "w1: [25.81867968] w2: [-23.59707186] bias: [15.94804283] loss: 30.568974298385196\n",
            "Epoch: 481 / 500 batch step: 120\n",
            "w1: [25.82856929] w2: [-23.56616542] bias: [15.98469454] loss: 30.548636290193524\n",
            "Epoch: 481 / 500 batch step: 150\n",
            "w1: [25.86305419] w2: [-23.5648261] bias: [16.02854762] loss: 30.53048767009739\n",
            "Epoch: 481 / 500 batch step: 180\n",
            "w1: [25.93075502] w2: [-23.54778025] bias: [16.13113122] loss: 30.518472871936492\n",
            "Epoch: 481 / 500 batch step: 210\n",
            "w1: [25.96769722] w2: [-23.52737209] bias: [16.19036874] loss: 30.530745458323754\n",
            "Epoch: 481 / 500 batch step: 240\n",
            "w1: [26.00667605] w2: [-23.5214829] bias: [16.23215234] loss: 30.54936570064328\n",
            "Epoch: 481 / 500 batch step: 270\n",
            "w1: [26.02302933] w2: [-23.52162202] bias: [16.24913101] loss: 30.559066431814017\n",
            "Epoch: 481 / 500 batch step: 300\n",
            "w1: [26.00323048] w2: [-23.52790114] bias: [16.20997769] loss: 30.54066065604486\n",
            "Epoch: 481 / 500 batch step: 330\n",
            "w1: [25.96700443] w2: [-23.5405783] bias: [16.13853371] loss: 30.520654297143796\n",
            "Epoch: 481 / 500 batch step: 360\n",
            "w1: [25.97843536] w2: [-23.51084245] bias: [16.2283253] loss: 30.544419753191818\n",
            "Epoch: 481 / 500 batch step: 390\n",
            "w1: [25.95289663] w2: [-23.52234362] bias: [16.1945535] loss: 30.530498091241135\n",
            "Epoch: 481 / 500 batch step: 420\n",
            "w1: [25.90374793] w2: [-23.56545439] bias: [16.10007974] loss: 30.518069312958882\n",
            "Epoch: 481 / 500 batch step: 450\n",
            "w1: [25.87851165] w2: [-23.58296217] bias: [16.05717628] loss: 30.52434279669334\n",
            "Epoch: 481 / 500 batch step: 480\n",
            "w1: [25.86144833] w2: [-23.58452918] bias: [16.03086528] loss: 30.53149901729714\n",
            "Epoch: 482 / 500 batch step: 0\n",
            "w1: [25.85511321] w2: [-23.58545268] bias: [16.01767716] loss: 30.535717199973288\n",
            "Epoch: 482 / 500 batch step: 30\n",
            "w1: [25.84826799] w2: [-23.58551753] bias: [16.0040561] loss: 30.540638363622858\n",
            "Epoch: 482 / 500 batch step: 60\n",
            "w1: [25.82648799] w2: [-23.59264742] bias: [15.96255371] loss: 30.560345939462145\n",
            "Epoch: 482 / 500 batch step: 90\n",
            "w1: [25.81994892] w2: [-23.59662382] bias: [15.94724316] loss: 30.56895322414649\n",
            "Epoch: 482 / 500 batch step: 120\n",
            "w1: [25.82983863] w2: [-23.56571716] bias: [15.98389528] loss: 30.548614907125085\n",
            "Epoch: 482 / 500 batch step: 150\n",
            "w1: [25.86432342] w2: [-23.56437749] bias: [16.02774893] loss: 30.530467013979774\n",
            "Epoch: 482 / 500 batch step: 180\n",
            "w1: [25.93202308] w2: [-23.54733163] bias: [16.13033121] loss: 30.518453799594614\n",
            "Epoch: 482 / 500 batch step: 210\n",
            "w1: [25.96896378] w2: [-23.52692354] bias: [16.1895671] loss: 30.530726345057197\n",
            "Epoch: 482 / 500 batch step: 240\n",
            "w1: [26.00794109] w2: [-23.52103449] bias: [16.23134922] loss: 30.549346247656494\n",
            "Epoch: 482 / 500 batch step: 270\n",
            "w1: [26.02429385] w2: [-23.52117359] bias: [16.24832739] loss: 30.55904678584938\n",
            "Epoch: 482 / 500 batch step: 300\n",
            "w1: [26.00449531] w2: [-23.52745246] bias: [16.20917499] loss: 30.540641663412\n",
            "Epoch: 482 / 500 batch step: 330\n",
            "w1: [25.96826981] w2: [-23.54012936] bias: [16.13773228] loss: 30.520635842102458\n",
            "Epoch: 482 / 500 batch step: 360\n",
            "w1: [25.97970034] w2: [-23.51039298] bias: [16.22752521] loss: 30.54440069587213\n",
            "Epoch: 482 / 500 batch step: 390\n",
            "w1: [25.95416123] w2: [-23.52189424] bias: [16.19375333] loss: 30.53047869867018\n",
            "Epoch: 482 / 500 batch step: 420\n",
            "w1: [25.90501187] w2: [-23.5650057] bias: [16.09927841] loss: 30.51804999835488\n",
            "Epoch: 482 / 500 batch step: 450\n",
            "w1: [25.87977506] w2: [-23.58251379] bias: [16.05637422] loss: 30.524323782757225\n",
            "Epoch: 482 / 500 batch step: 480\n",
            "w1: [25.86271221] w2: [-23.58408031] bias: [16.03006445] loss: 30.531479643467687\n",
            "Epoch: 483 / 500 batch step: 0\n",
            "w1: [25.85637736] w2: [-23.58500361] bias: [16.01687709] loss: 30.535697580983275\n",
            "Epoch: 483 / 500 batch step: 30\n",
            "w1: [25.84953265] w2: [-23.58506821] bias: [16.0032572] loss: 30.54061824322705\n",
            "Epoch: 483 / 500 batch step: 60\n",
            "w1: [25.8277531] w2: [-23.59219786] bias: [15.96175591] loss: 30.560324991879654\n",
            "Epoch: 483 / 500 batch step: 90\n",
            "w1: [25.82121379] w2: [-23.59617416] bias: [15.94644527] loss: 30.568932266965305\n",
            "Epoch: 483 / 500 batch step: 120\n",
            "w1: [25.8311036] w2: [-23.56526728] bias: [15.98309779] loss: 30.54859365342225\n",
            "Epoch: 483 / 500 batch step: 150\n",
            "w1: [25.86558828] w2: [-23.56392726] bias: [16.02695201] loss: 30.530446475528443\n",
            "Epoch: 483 / 500 batch step: 180\n",
            "w1: [25.93328678] w2: [-23.5468814] bias: [16.12953299] loss: 30.518434830492673\n",
            "Epoch: 483 / 500 batch step: 210\n",
            "w1: [25.97022598] w2: [-23.52647337] bias: [16.18876725] loss: 30.530707335988165\n",
            "Epoch: 483 / 500 batch step: 240\n",
            "w1: [26.00920179] w2: [-23.52058446] bias: [16.23054791] loss: 30.549326900594192\n",
            "Epoch: 483 / 500 batch step: 270\n",
            "w1: [26.02555404] w2: [-23.52072353] bias: [16.2475256] loss: 30.559027250793388\n",
            "Epoch: 483 / 500 batch step: 300\n",
            "w1: [26.00575581] w2: [-23.52700216] bias: [16.20837411] loss: 30.54062278026923\n",
            "Epoch: 483 / 500 batch step: 330\n",
            "w1: [25.96953087] w2: [-23.5396788] bias: [16.13693268] loss: 30.520617491031828\n",
            "Epoch: 483 / 500 batch step: 360\n",
            "w1: [25.980961] w2: [-23.50994191] bias: [16.22672692] loss: 30.54438175330625\n",
            "Epoch: 483 / 500 batch step: 390\n",
            "w1: [25.95542151] w2: [-23.52144327] bias: [16.19295495] loss: 30.530459413920642\n",
            "Epoch: 483 / 500 batch step: 420\n",
            "w1: [25.90627147] w2: [-23.56455543] bias: [16.09847885] loss: 30.518030787397905\n",
            "Epoch: 483 / 500 batch step: 450\n",
            "w1: [25.88103414] w2: [-23.58206383] bias: [16.05557394] loss: 30.52430487373775\n",
            "Epoch: 483 / 500 batch step: 480\n",
            "w1: [25.86397175] w2: [-23.58362987] bias: [16.0292654] loss: 30.531460379454433\n",
            "Epoch: 484 / 500 batch step: 0\n",
            "w1: [25.85763717] w2: [-23.58455297] bias: [16.01607879] loss: 30.535678074221096\n",
            "Epoch: 484 / 500 batch step: 30\n",
            "w1: [25.85079297] w2: [-23.5846173] bias: [16.00246008] loss: 30.540598237637724\n",
            "Epoch: 484 / 500 batch step: 60\n",
            "w1: [25.82901388] w2: [-23.59174671] bias: [15.96095988] loss: 30.560304161486396\n",
            "Epoch: 484 / 500 batch step: 90\n",
            "w1: [25.82247433] w2: [-23.59572292] bias: [15.94564915] loss: 30.568911425700087\n",
            "Epoch: 484 / 500 batch step: 120\n",
            "w1: [25.83236424] w2: [-23.56481583] bias: [15.98230207] loss: 30.548572527728314\n",
            "Epoch: 484 / 500 batch step: 150\n",
            "w1: [25.8668488] w2: [-23.56347546] bias: [16.02615686] loss: 30.530426053575642\n",
            "Epoch: 484 / 500 batch step: 180\n",
            "w1: [25.93454616] w2: [-23.5464296] bias: [16.12873655] loss: 30.518415963670854\n",
            "Epoch: 484 / 500 batch step: 210\n",
            "w1: [25.97148388] w2: [-23.52602163] bias: [16.18796921] loss: 30.530688430141055\n",
            "Epoch: 484 / 500 batch step: 240\n",
            "w1: [26.0104582] w2: [-23.52013287] bias: [16.22974841] loss: 30.549307658461615\n",
            "Epoch: 484 / 500 batch step: 270\n",
            "w1: [26.02680994] w2: [-23.52027191] bias: [16.24672563] loss: 30.559007825566614\n",
            "Epoch: 484 / 500 batch step: 300\n",
            "w1: [26.00701202] w2: [-23.52655029] bias: [16.20757505] loss: 30.54060400553928\n",
            "Epoch: 484 / 500 batch step: 330\n",
            "w1: [25.97078764] w2: [-23.53922667] bias: [16.1361349] loss: 30.520599242936697\n",
            "Epoch: 484 / 500 batch step: 360\n",
            "w1: [25.98221737] w2: [-23.50948928] bias: [16.22593044] loss: 30.544362924323256\n",
            "Epoch: 484 / 500 batch step: 390\n",
            "w1: [25.95667748] w2: [-23.52099075] bias: [16.19215837] loss: 30.530440235961585\n",
            "Epoch: 484 / 500 batch step: 420\n",
            "w1: [25.90752677] w2: [-23.56410362] bias: [16.09768108] loss: 30.51801167913096\n",
            "Epoch: 484 / 500 batch step: 450\n",
            "w1: [25.88228891] w2: [-23.58161233] bias: [16.05477543] loss: 30.524286068643804\n",
            "Epoch: 484 / 500 batch step: 480\n",
            "w1: [25.86522699] w2: [-23.58317788] bias: [16.02846813] loss: 30.53144122418917\n",
            "Epoch: 485 / 500 batch step: 0\n",
            "w1: [25.85889267] w2: [-23.58410079] bias: [16.01528226] loss: 30.535658678583065\n",
            "Epoch: 485 / 500 batch step: 30\n",
            "w1: [25.85204898] w2: [-23.58416487] bias: [16.00166473] loss: 30.540578345722054\n",
            "Epoch: 485 / 500 batch step: 60\n",
            "w1: [25.83027035] w2: [-23.59129404] bias: [15.96016563] loss: 30.560283447136122\n",
            "Epoch: 485 / 500 batch step: 90\n",
            "w1: [25.82373057] w2: [-23.59527015] bias: [15.94485481] loss: 30.568890699228554\n",
            "Epoch: 485 / 500 batch step: 120\n",
            "w1: [25.83362056] w2: [-23.56436287] bias: [15.9815081] loss: 30.548551528709325\n",
            "Epoch: 485 / 500 batch step: 150\n",
            "w1: [25.86810502] w2: [-23.56302215] bias: [16.02536347] loss: 30.53040574697334\n",
            "Epoch: 485 / 500 batch step: 180\n",
            "w1: [25.93580125] w2: [-23.54597629] bias: [16.12794188] loss: 30.51839719818572\n",
            "Epoch: 485 / 500 batch step: 210\n",
            "w1: [25.97273749] w2: [-23.52556838] bias: [16.18717295] loss: 30.530669626556907\n",
            "Epoch: 485 / 500 batch step: 240\n",
            "w1: [26.01171033] w2: [-23.51967976] bias: [16.22895071] loss: 30.54928852028089\n",
            "Epoch: 485 / 500 batch step: 270\n",
            "w1: [26.02806157] w2: [-23.51981876] bias: [16.24592747] loss: 30.55898850910792\n",
            "Epoch: 485 / 500 batch step: 300\n",
            "w1: [26.00826397] w2: [-23.5260969] bias: [16.20677781] loss: 30.540585338163186\n",
            "Epoch: 485 / 500 batch step: 330\n",
            "w1: [25.97204014] w2: [-23.53877303] bias: [16.13533894] loss: 30.520581096838846\n",
            "Epoch: 485 / 500 batch step: 360\n",
            "w1: [25.98346947] w2: [-23.50903514] bias: [16.22513577] loss: 30.544344207772006\n",
            "Epoch: 485 / 500 batch step: 390\n",
            "w1: [25.95792919] w2: [-23.52053674] bias: [16.19136357] loss: 30.530421163779486\n",
            "Epoch: 485 / 500 batch step: 420\n",
            "w1: [25.9087778] w2: [-23.56365031] bias: [16.09688509] loss: 30.5179926726133\n",
            "Epoch: 485 / 500 batch step: 450\n",
            "w1: [25.88353942] w2: [-23.58115934] bias: [16.05397871] loss: 30.52426736650108\n",
            "Epoch: 485 / 500 batch step: 480\n",
            "w1: [25.86647796] w2: [-23.58272441] bias: [16.02767262] loss: 30.531422176621742\n",
            "Epoch: 486 / 500 batch step: 0\n",
            "w1: [25.8601439] w2: [-23.58364713] bias: [16.0144875] loss: 30.535639392984127\n",
            "Epoch: 486 / 500 batch step: 30\n",
            "w1: [25.85330072] w2: [-23.58371095] bias: [16.00087115] loss: 30.54055856636627\n",
            "Epoch: 486 / 500 batch step: 60\n",
            "w1: [25.83152256] w2: [-23.59083988] bias: [15.95937314] loss: 30.560262847701832\n",
            "Epoch: 486 / 500 batch step: 90\n",
            "w1: [25.82498255] w2: [-23.5948159] bias: [15.94406225] loss: 30.56887008644726\n",
            "Epoch: 486 / 500 batch step: 120\n",
            "w1: [25.83487262] w2: [-23.56390842] bias: [15.9807159] loss: 30.548530655053614\n",
            "Epoch: 486 / 500 batch step: 150\n",
            "w1: [25.86935698] w2: [-23.56256735] bias: [16.02457185] loss: 30.53038555459276\n",
            "Epoch: 486 / 500 batch step: 180\n",
            "w1: [25.93705209] w2: [-23.54552149] bias: [16.127149] loss: 30.518378533109818\n",
            "Epoch: 486 / 500 batch step: 210\n",
            "w1: [25.97398686] w2: [-23.52511365] bias: [16.18637848] loss: 30.53065092429298\n",
            "Epoch: 486 / 500 batch step: 240\n",
            "w1: [26.01295822] w2: [-23.51922516] bias: [16.2281548] loss: 30.549269485090676\n",
            "Epoch: 486 / 500 batch step: 270\n",
            "w1: [26.02930898] w2: [-23.51936414] bias: [16.24513111] loss: 30.558969300374034\n",
            "Epoch: 486 / 500 batch step: 300\n",
            "w1: [26.0095117] w2: [-23.52564203] bias: [16.20598238] loss: 30.540566777099855\n",
            "Epoch: 486 / 500 batch step: 330\n",
            "w1: [25.97328843] w2: [-23.5383179] bias: [16.1345448] loss: 30.520563051776644\n",
            "Epoch: 486 / 500 batch step: 360\n",
            "w1: [25.98471735] w2: [-23.50857953] bias: [16.22434289] loss: 30.544325602520743\n",
            "Epoch: 486 / 500 batch step: 390\n",
            "w1: [25.95917667] w2: [-23.52008126] bias: [16.19057055] loss: 30.530402196377903\n",
            "Epoch: 486 / 500 batch step: 420\n",
            "w1: [25.9100246] w2: [-23.56319554] bias: [16.09609088] loss: 30.51797376692002\n",
            "Epoch: 486 / 500 batch step: 450\n",
            "w1: [25.88478568] w2: [-23.58070489] bias: [16.05318375] loss: 30.52424876635171\n",
            "Epoch: 486 / 500 batch step: 480\n",
            "w1: [25.86772469] w2: [-23.58226949] bias: [16.02687889] loss: 30.531403235719623\n",
            "Epoch: 487 / 500 batch step: 0\n",
            "w1: [25.8613909] w2: [-23.58319202] bias: [16.0136945] loss: 30.535620216357426\n",
            "Epoch: 487 / 500 batch step: 30\n",
            "w1: [25.85454822] w2: [-23.58325559] bias: [16.00007932] loss: 30.540538898475234\n",
            "Epoch: 487 / 500 batch step: 60\n",
            "w1: [25.83277052] w2: [-23.59038428] bias: [15.95858242] loss: 30.560242362075282\n",
            "Epoch: 487 / 500 batch step: 90\n",
            "w1: [25.82623029] w2: [-23.5943602] bias: [15.94327145] loss: 30.56884958627112\n",
            "Epoch: 487 / 500 batch step: 120\n",
            "w1: [25.83612044] w2: [-23.56345254] bias: [15.97992545] loss: 30.548509905471285\n",
            "Epoch: 487 / 500 batch step: 150\n",
            "w1: [25.8706047] w2: [-23.56211113] bias: [16.02378199] loss: 30.530365475323947\n",
            "Epoch: 487 / 500 batch step: 180\n",
            "w1: [25.9382987] w2: [-23.54506526] bias: [16.12635788] loss: 30.51835996753132\n",
            "Epoch: 487 / 500 batch step: 210\n",
            "w1: [25.97523201] w2: [-23.52465748] bias: [16.18558579] loss: 30.530632322422406\n",
            "Epoch: 487 / 500 batch step: 240\n",
            "w1: [26.01420191] w2: [-23.51876914] bias: [16.22736069] loss: 30.54925055194576\n",
            "Epoch: 487 / 500 batch step: 270\n",
            "w1: [26.03055219] w2: [-23.51890808] bias: [16.24433657] loss: 30.558950198339144\n",
            "Epoch: 487 / 500 batch step: 300\n",
            "w1: [26.01075523] w2: [-23.52518573] bias: [16.20518876] loss: 30.540548321325673\n",
            "Epoch: 487 / 500 batch step: 330\n",
            "w1: [25.97453251] w2: [-23.53786134] bias: [16.13375246] loss: 30.520545106804665\n",
            "Epoch: 487 / 500 batch step: 360\n",
            "w1: [25.98596103] w2: [-23.5081225] bias: [16.22355181] loss: 30.54430710745661\n",
            "Epoch: 487 / 500 batch step: 390\n",
            "w1: [25.96041994] w2: [-23.51962438] bias: [16.18977932] loss: 30.530383332777053\n",
            "Epoch: 487 / 500 batch step: 420\n",
            "w1: [25.91126719] w2: [-23.56273937] bias: [16.09529843] loss: 30.517954961141733\n",
            "Epoch: 487 / 500 batch step: 450\n",
            "w1: [25.88602774] w2: [-23.58024904] bias: [16.05239057] loss: 30.524230267253866\n",
            "Epoch: 487 / 500 batch step: 480\n",
            "w1: [25.86896721] w2: [-23.58181316] bias: [16.02608691] loss: 30.53138440046755\n",
            "Epoch: 488 / 500 batch step: 0\n",
            "w1: [25.86263368] w2: [-23.5827355] bias: [16.01290327] loss: 30.535601147653882\n",
            "Epoch: 488 / 500 batch step: 30\n",
            "w1: [25.85579152] w2: [-23.58279883] bias: [15.99928926] loss: 30.540519340972025\n",
            "Epoch: 488 / 500 batch step: 60\n",
            "w1: [25.83401429] w2: [-23.58992728] bias: [15.95779346] loss: 30.560221989166614\n",
            "Epoch: 488 / 500 batch step: 90\n",
            "w1: [25.82747382] w2: [-23.59390311] bias: [15.94248242] loss: 30.568829197633036\n",
            "Epoch: 488 / 500 batch step: 120\n",
            "w1: [25.83736405] w2: [-23.56299528] bias: [15.97913676] loss: 30.548489278693765\n",
            "Epoch: 488 / 500 batch step: 150\n",
            "w1: [25.87184822] w2: [-23.56165351] bias: [16.02299388] loss: 30.53034550807534\n",
            "Epoch: 488 / 500 batch step: 180\n",
            "w1: [25.93954112] w2: [-23.54460764] bias: [16.12556854] loss: 30.51834150055365\n",
            "Epoch: 488 / 500 batch step: 210\n",
            "w1: [25.97647298] w2: [-23.52419993] bias: [16.18479487] loss: 30.53061382003376\n",
            "Epoch: 488 / 500 batch step: 240\n",
            "w1: [26.01544142] w2: [-23.51831172] bias: [16.22656837] loss: 30.54923171991667\n",
            "Epoch: 488 / 500 batch step: 270\n",
            "w1: [26.03179123] w2: [-23.51845063] bias: [16.24354382] loss: 30.558931201994465\n",
            "Epoch: 488 / 500 batch step: 300\n",
            "w1: [26.01199459] w2: [-23.52472804] bias: [16.20439694] loss: 30.540529969834065\n",
            "Epoch: 488 / 500 batch step: 330\n",
            "w1: [25.97577244] w2: [-23.53740339] bias: [16.13296193] loss: 30.52052726099329\n",
            "Epoch: 488 / 500 batch step: 360\n",
            "w1: [25.98720055] w2: [-23.50766409] bias: [16.22276253] loss: 30.544288721485234\n",
            "Epoch: 488 / 500 batch step: 390\n",
            "w1: [25.96165905] w2: [-23.51916612] bias: [16.18898986] loss: 30.530364572013404\n",
            "Epoch: 488 / 500 batch step: 420\n",
            "w1: [25.91250561] w2: [-23.56228184] bias: [16.09450776] loss: 30.517936254384136\n",
            "Epoch: 488 / 500 batch step: 450\n",
            "w1: [25.88726563] w2: [-23.57979183] bias: [16.05159915] loss: 30.524211868281387\n",
            "Epoch: 488 / 500 batch step: 480\n",
            "w1: [25.87020556] w2: [-23.58135547] bias: [16.0252967] loss: 30.531365669867107\n",
            "Epoch: 489 / 500 batch step: 0\n",
            "w1: [25.86387229] w2: [-23.58227763] bias: [16.01211379] loss: 30.535582185841804\n",
            "Epoch: 489 / 500 batch step: 30\n",
            "w1: [25.85703064] w2: [-23.58234071] bias: [15.99850095] loss: 30.540499892797513\n",
            "Epoch: 489 / 500 batch step: 60\n",
            "w1: [25.83525388] w2: [-23.58946892] bias: [15.95700626] loss: 30.560201727903905\n",
            "Epoch: 489 / 500 batch step: 90\n",
            "w1: [25.82871319] w2: [-23.59344465] bias: [15.94169515] loss: 30.568808919483505\n",
            "Epoch: 489 / 500 batch step: 120\n",
            "w1: [25.83860348] w2: [-23.56253666] bias: [15.97834981] loss: 30.548468773473317\n",
            "Epoch: 489 / 500 batch step: 150\n",
            "w1: [25.87308757] w2: [-23.56119454] bias: [16.02220753] loss: 30.530325651773367\n",
            "Epoch: 489 / 500 batch step: 180\n",
            "w1: [25.94077937] w2: [-23.54414867] bias: [16.12478096] loss: 30.51832313129511\n",
            "Epoch: 489 / 500 batch step: 210\n",
            "w1: [25.97770979] w2: [-23.52374102] bias: [16.18400574] loss: 30.530595416230767\n",
            "Epoch: 489 / 500 batch step: 240\n",
            "w1: [26.0166768] w2: [-23.51785296] bias: [16.22577784] loss: 30.5492129880893\n",
            "Epoch: 489 / 500 batch step: 270\n",
            "w1: [26.03302613] w2: [-23.51799183] bias: [16.24275288] loss: 30.558912310347917\n",
            "Epoch: 489 / 500 batch step: 300\n",
            "w1: [26.01322982] w2: [-23.52426899] bias: [16.20360692] loss: 30.540511721635156\n",
            "Epoch: 489 / 500 batch step: 330\n",
            "w1: [25.97700823] w2: [-23.53694409] bias: [16.1321732] loss: 30.520509513428365\n",
            "Epoch: 489 / 500 batch step: 360\n",
            "w1: [25.98843593] w2: [-23.50720433] bias: [16.22197503] loss: 30.544270443530355\n",
            "Epoch: 489 / 500 batch step: 390\n",
            "w1: [25.96289402] w2: [-23.51870653] bias: [16.18820217] loss: 30.53034591313933\n",
            "Epoch: 489 / 500 batch step: 420\n",
            "w1: [25.91373988] w2: [-23.56182297] bias: [16.09371885] loss: 30.51791764576771\n",
            "Epoch: 489 / 500 batch step: 450\n",
            "w1: [25.88849938] w2: [-23.57933329] bias: [16.05080949] loss: 30.524193568523412\n",
            "Epoch: 489 / 500 batch step: 480\n",
            "w1: [25.87143976] w2: [-23.58089647] bias: [16.02450824] loss: 30.531347042936307\n",
            "Epoch: 490 / 500 batch step: 0\n",
            "w1: [25.86510675] w2: [-23.58181844] bias: [16.01132607] loss: 30.53556332990649\n",
            "Epoch: 490 / 500 batch step: 30\n",
            "w1: [25.85826562] w2: [-23.58188128] bias: [15.9977144] loss: 30.540480552909962\n",
            "Epoch: 490 / 500 batch step: 60\n",
            "w1: [25.83648932] w2: [-23.58900925] bias: [15.95622082] loss: 30.560181577232758\n",
            "Epoch: 490 / 500 batch step: 90\n",
            "w1: [25.82994842] w2: [-23.59298489] bias: [15.94090964] loss: 30.568788750790144\n",
            "Epoch: 490 / 500 batch step: 120\n",
            "w1: [25.83983877] w2: [-23.56207673] bias: [15.97756461] loss: 30.54844838858261\n",
            "Epoch: 490 / 500 batch step: 150\n",
            "w1: [25.87432278] w2: [-23.56073427] bias: [16.02142292] loss: 30.530305905362063\n",
            "Epoch: 490 / 500 batch step: 180\n",
            "w1: [25.9420135] w2: [-23.5436884] bias: [16.12399515] loss: 30.51830485888852\n",
            "Epoch: 490 / 500 batch step: 210\n",
            "w1: [25.97894248] w2: [-23.52328081] bias: [16.18321837] loss: 30.53057711013188\n",
            "Epoch: 490 / 500 batch step: 240\n",
            "w1: [26.01790806] w2: [-23.51739288] bias: [16.22498909] loss: 30.549194355564588\n",
            "Epoch: 490 / 500 batch step: 270\n",
            "w1: [26.03425694] w2: [-23.51753173] bias: [16.24196372] loss: 30.558893522423684\n",
            "Epoch: 490 / 500 batch step: 300\n",
            "w1: [26.01446095] w2: [-23.52380864] bias: [16.2028187] loss: 30.540493575755356\n",
            "Epoch: 490 / 500 batch step: 330\n",
            "w1: [25.97823992] w2: [-23.53648348] bias: [16.13138627] loss: 30.5204918632108\n",
            "Epoch: 490 / 500 batch step: 360\n",
            "w1: [25.98966722] w2: [-23.50674329] bias: [16.22118931] loss: 30.544252272533367\n",
            "Epoch: 490 / 500 batch step: 390\n",
            "w1: [25.96412488] w2: [-23.51824566] bias: [16.18741625] loss: 30.530327355222727\n",
            "Epoch: 490 / 500 batch step: 420\n",
            "w1: [25.91497005] w2: [-23.56136283] bias: [16.0929317] loss: 30.517899134427335\n",
            "Epoch: 490 / 500 batch step: 450\n",
            "w1: [25.88972901] w2: [-23.57887347] bias: [16.05002159] loss: 30.524175367084034\n",
            "Epoch: 490 / 500 batch step: 480\n",
            "w1: [25.87266985] w2: [-23.58043618] bias: [16.02372154] loss: 30.531328518709298\n",
            "Epoch: 491 / 500 batch step: 0\n",
            "w1: [25.86633711] w2: [-23.58135798] bias: [16.01054009] loss: 30.535544578849834\n",
            "Epoch: 491 / 500 batch step: 30\n",
            "w1: [25.85949648] w2: [-23.58142057] bias: [15.99692959] loss: 30.540461320284663\n",
            "Epoch: 491 / 500 batch step: 60\n",
            "w1: [25.83772066] w2: [-23.5885483] bias: [15.95543713] loss: 30.560161536115967\n",
            "Epoch: 491 / 500 batch step: 90\n",
            "w1: [25.83117954] w2: [-23.59252384] bias: [15.94012588] loss: 30.568768690537404\n",
            "Epoch: 491 / 500 batch step: 120\n",
            "w1: [25.84106995] w2: [-23.56161554] bias: [15.97678115] loss: 30.548428122814293\n",
            "Epoch: 491 / 500 batch step: 150\n",
            "w1: [25.87555388] w2: [-23.56027274] bias: [16.02064006] loss: 30.530286267802627\n",
            "Epoch: 491 / 500 batch step: 180\n",
            "w1: [25.94324352] w2: [-23.54322686] bias: [16.12321109] loss: 30.518286682480912\n",
            "Epoch: 491 / 500 batch step: 210\n",
            "w1: [25.98017108] w2: [-23.52281934] bias: [16.18243278] loss: 30.53055890086997\n",
            "Epoch: 491 / 500 batch step: 240\n",
            "w1: [26.01913523] w2: [-23.51693154] bias: [16.22420212] loss: 30.549175821458107\n",
            "Epoch: 491 / 500 batch step: 270\n",
            "w1: [26.03548366] w2: [-23.51707035] bias: [16.24117636] loss: 30.55887483726186\n",
            "Epoch: 491 / 500 batch step: 300\n",
            "w1: [26.015688] w2: [-23.52334703] bias: [16.20203227] loss: 30.54047553123699\n",
            "Epoch: 491 / 500 batch step: 330\n",
            "w1: [25.97946754] w2: [-23.5360216] bias: [16.13060113] loss: 30.520474309456265\n",
            "Epoch: 491 / 500 batch step: 360\n",
            "w1: [25.99089443] w2: [-23.50628098] bias: [16.22040537] loss: 30.544234207452963\n",
            "Epoch: 491 / 500 batch step: 390\n",
            "w1: [25.96535166] w2: [-23.51778354] bias: [16.18663209] loss: 30.530308897346668\n",
            "Epoch: 491 / 500 batch step: 420\n",
            "w1: [25.91619614] w2: [-23.56090144] bias: [16.09214631] loss: 30.51788071951196\n",
            "Epoch: 491 / 500 batch step: 450\n",
            "w1: [25.89095456] w2: [-23.5784124] bias: [16.04923544] loss: 30.52415726308194\n",
            "Epoch: 491 / 500 batch step: 480\n",
            "w1: [25.87389586] w2: [-23.57997466] bias: [16.02293658] loss: 30.531310096235906\n",
            "Epoch: 492 / 500 batch step: 0\n",
            "w1: [25.86756338] w2: [-23.58089628] bias: [16.00975587] loss: 30.53552593168997\n",
            "Epoch: 492 / 500 batch step: 30\n",
            "w1: [25.86072326] w2: [-23.58095863] bias: [15.99614654] loss: 30.540442193913528\n",
            "Epoch: 492 / 500 batch step: 60\n",
            "w1: [25.83894792] w2: [-23.58808612] bias: [15.95465519] loss: 30.560141603533086\n",
            "Epoch: 492 / 500 batch step: 90\n",
            "w1: [25.83240658] w2: [-23.59206157] bias: [15.93934388] loss: 30.568748737726125\n",
            "Epoch: 492 / 500 batch step: 120\n",
            "w1: [25.84229704] w2: [-23.56115313] bias: [15.97599943] loss: 30.548407974980545\n",
            "Epoch: 492 / 500 batch step: 150\n",
            "w1: [25.8767809] w2: [-23.55980998] bias: [16.01985895] loss: 30.530266738073077\n",
            "Epoch: 492 / 500 batch step: 180\n",
            "w1: [25.94446948] w2: [-23.54276409] bias: [16.12242878] loss: 30.518268601233164\n",
            "Epoch: 492 / 500 batch step: 210\n",
            "w1: [25.98139562] w2: [-23.52235664] bias: [16.18164894] loss: 30.53054078759197\n",
            "Epoch: 492 / 500 batch step: 240\n",
            "w1: [26.02035836] w2: [-23.51646898] bias: [16.22341692] loss: 30.549157384899782\n",
            "Epoch: 492 / 500 batch step: 270\n",
            "w1: [26.03670635] w2: [-23.51660775] bias: [16.24039078] loss: 30.558856253918083\n",
            "Epoch: 492 / 500 batch step: 300\n",
            "w1: [26.01691102] w2: [-23.52288418] bias: [16.20124763] loss: 30.540457587137965\n",
            "Epoch: 492 / 500 batch step: 330\n",
            "w1: [25.98069112] w2: [-23.5355585] bias: [16.12981778] loss: 30.520456851294803\n",
            "Epoch: 492 / 500 batch step: 360\n",
            "w1: [25.99211759] w2: [-23.50581746] bias: [16.21962321] loss: 30.544216247264742\n",
            "Epoch: 492 / 500 batch step: 390\n",
            "w1: [25.96657439] w2: [-23.51732021] bias: [16.18584969] loss: 30.530290538609055\n",
            "Epoch: 492 / 500 batch step: 420\n",
            "w1: [25.91741817] w2: [-23.56043885] bias: [16.09136268] loss: 30.5178624001843\n",
            "Epoch: 492 / 500 batch step: 450\n",
            "w1: [25.89217606] w2: [-23.57795014] bias: [16.04845105] loss: 30.524139255650066\n",
            "Epoch: 492 / 500 batch step: 480\n",
            "w1: [25.87511782] w2: [-23.57951194] bias: [16.02215338] loss: 30.531291774581348\n",
            "Epoch: 493 / 500 batch step: 0\n",
            "w1: [25.86878559] w2: [-23.58043338] bias: [16.00897339] loss: 30.5355073874609\n",
            "Epoch: 493 / 500 batch step: 30\n",
            "w1: [25.86194599] w2: [-23.5804955] bias: [15.99536522] loss: 30.540423172804733\n",
            "Epoch: 493 / 500 batch step: 60\n",
            "w1: [25.84017112] w2: [-23.58762274] bias: [15.95387499] loss: 30.56012177848006\n",
            "Epoch: 493 / 500 batch step: 90\n",
            "w1: [25.83362957] w2: [-23.5915981] bias: [15.93856362] loss: 30.568728891373205\n",
            "Epoch: 493 / 500 batch step: 120\n",
            "w1: [25.84352008] w2: [-23.56068952] bias: [15.97521945] loss: 30.548387943912665\n",
            "Epoch: 493 / 500 batch step: 150\n",
            "w1: [25.87800387] w2: [-23.55934603] bias: [16.01907957] loss: 30.53024731516788\n",
            "Epoch: 493 / 500 batch step: 180\n",
            "w1: [25.9456914] w2: [-23.54230014] bias: [16.12164823] loss: 30.518250614319676\n",
            "Epoch: 493 / 500 batch step: 210\n",
            "w1: [25.98261613] w2: [-23.52189276] bias: [16.18086687] loss: 30.530522769458596\n",
            "Epoch: 493 / 500 batch step: 240\n",
            "w1: [26.02157746] w2: [-23.51600523] bias: [16.2226335] loss: 30.549139045033527\n",
            "Epoch: 493 / 500 batch step: 270\n",
            "w1: [26.03792502] w2: [-23.51614397] bias: [16.23960698] loss: 30.558837771463235\n",
            "Epoch: 493 / 500 batch step: 300\n",
            "w1: [26.01813002] w2: [-23.52242015] bias: [16.20046477] loss: 30.540439742531387\n",
            "Epoch: 493 / 500 batch step: 330\n",
            "w1: [25.98191069] w2: [-23.53509421] bias: [16.12903621] loss: 30.520439487870537\n",
            "Epoch: 493 / 500 batch step: 360\n",
            "w1: [25.99333675] w2: [-23.50535276] bias: [16.21884282] loss: 30.54419839096084\n",
            "Epoch: 493 / 500 batch step: 390\n",
            "w1: [25.96779311] w2: [-23.51685572] bias: [16.18506906] loss: 30.53027227812227\n",
            "Epoch: 493 / 500 batch step: 420\n",
            "w1: [25.91863619] w2: [-23.55997509] bias: [16.09058079] loss: 30.517844175620482\n",
            "Epoch: 493 / 500 batch step: 450\n",
            "w1: [25.89339354] w2: [-23.57748672] bias: [16.0476684] loss: 30.524121343935317\n",
            "Epoch: 493 / 500 batch step: 480\n",
            "w1: [25.87633575] w2: [-23.57904806] bias: [16.02137192] loss: 30.531273552825855\n",
            "Epoch: 494 / 500 batch step: 0\n",
            "w1: [25.87000378] w2: [-23.57996932] bias: [16.00819265] loss: 30.53548894521214\n",
            "Epoch: 494 / 500 batch step: 30\n",
            "w1: [25.86316469] w2: [-23.58003121] bias: [15.99458564] loss: 30.540404255982363\n",
            "Epoch: 494 / 500 batch step: 60\n",
            "w1: [25.8413903] w2: [-23.58715821] bias: [15.95309653] loss: 30.5601020599689\n",
            "Epoch: 494 / 500 batch step: 90\n",
            "w1: [25.83484854] w2: [-23.59113347] bias: [15.93778511] loss: 30.56870915051123\n",
            "Epoch: 494 / 500 batch step: 120\n",
            "w1: [25.8447391] w2: [-23.56022477] bias: [15.9744412] loss: 30.548368028460693\n",
            "Epoch: 494 / 500 batch step: 150\n",
            "w1: [25.87922282] w2: [-23.55888094] bias: [16.01830193] loss: 30.5302279980976\n",
            "Epoch: 494 / 500 batch step: 180\n",
            "w1: [25.9469093] w2: [-23.54183504] bias: [16.12086943] loss: 30.518232720928086\n",
            "Epoch: 494 / 500 batch step: 210\n",
            "w1: [25.98383264] w2: [-23.52142773] bias: [16.18008655] loss: 30.53050484564395\n",
            "Epoch: 494 / 500 batch step: 240\n",
            "w1: [26.02279257] w2: [-23.51554033] bias: [16.22185184] loss: 30.549120801016937\n",
            "Epoch: 494 / 500 batch step: 270\n",
            "w1: [26.0391397] w2: [-23.51567903] bias: [16.23882496] loss: 30.558819388983018\n",
            "Epoch: 494 / 500 batch step: 300\n",
            "w1: [26.01934503] w2: [-23.52195497] bias: [16.19968369] loss: 30.54042199650523\n",
            "Epoch: 494 / 500 batch step: 330\n",
            "w1: [25.98312627] w2: [-23.53462878] bias: [16.12825643] loss: 30.52042221834133\n",
            "Epoch: 494 / 500 batch step: 360\n",
            "w1: [25.99455192] w2: [-23.50488693] bias: [16.21806419] loss: 30.544180637549577\n",
            "Epoch: 494 / 500 batch step: 390\n",
            "w1: [25.96900784] w2: [-23.5163901] bias: [16.18429017] loss: 30.530254115012855\n",
            "Epoch: 494 / 500 batch step: 420\n",
            "w1: [25.91985021] w2: [-23.55951021] bias: [16.08980066] loss: 30.51782604500975\n",
            "Epoch: 494 / 500 batch step: 450\n",
            "w1: [25.89460702] w2: [-23.57702217] bias: [16.0468875] loss: 30.524103527098188\n",
            "Epoch: 494 / 500 batch step: 480\n",
            "w1: [25.87754969] w2: [-23.57858305] bias: [16.02059219] loss: 30.53125543006434\n",
            "Epoch: 495 / 500 batch step: 0\n",
            "w1: [25.87121798] w2: [-23.57950415] bias: [16.00741365] loss: 30.53547060400837\n",
            "Epoch: 495 / 500 batch step: 30\n",
            "w1: [25.8643794] w2: [-23.5795658] bias: [15.9938078] loss: 30.540385442486038\n",
            "Epoch: 495 / 500 batch step: 60\n",
            "w1: [25.84260549] w2: [-23.58669256] bias: [15.95231982] loss: 30.56008244702728\n",
            "Epoch: 495 / 500 batch step: 90\n",
            "w1: [25.83606352] w2: [-23.59066773] bias: [15.93700834] loss: 30.56868951418811\n",
            "Epoch: 495 / 500 batch step: 120\n",
            "w1: [25.84595412] w2: [-23.55975891] bias: [15.97366468] loss: 30.548348227492966\n",
            "Epoch: 495 / 500 batch step: 150\n",
            "w1: [25.88043778] w2: [-23.55841473] bias: [16.01752602] loss: 30.530208785888483\n",
            "Epoch: 495 / 500 batch step: 180\n",
            "w1: [25.94812323] w2: [-23.54136883] bias: [16.12009237] loss: 30.51821492025894\n",
            "Epoch: 495 / 500 batch step: 210\n",
            "w1: [25.98504518] w2: [-23.52096159] bias: [16.17930799] loss: 30.530487015335297\n",
            "Epoch: 495 / 500 batch step: 240\n",
            "w1: [26.02400372] w2: [-23.51507432] bias: [16.22107194] loss: 30.54910265202097\n",
            "Epoch: 495 / 500 batch step: 270\n",
            "w1: [26.04035042] w2: [-23.51521299] bias: [16.23804471] loss: 30.558801105577697\n",
            "Epoch: 495 / 500 batch step: 300\n",
            "w1: [26.02055609] w2: [-23.52148868] bias: [16.19890438] loss: 30.540404348162046\n",
            "Epoch: 495 / 500 batch step: 330\n",
            "w1: [25.9843379] w2: [-23.53416223] bias: [16.12747842] loss: 30.520405041878462\n",
            "Epoch: 495 / 500 batch step: 360\n",
            "w1: [25.99576313] w2: [-23.50441999] bias: [16.21728734] loss: 30.54416298605508\n",
            "Epoch: 495 / 500 batch step: 390\n",
            "w1: [25.97021861] w2: [-23.51592338] bias: [16.18351304] loss: 30.530236048421212\n",
            "Epoch: 495 / 500 batch step: 420\n",
            "w1: [25.92106027] w2: [-23.55904424] bias: [16.08902226] loss: 30.517808007554166\n",
            "Epoch: 495 / 500 batch step: 450\n",
            "w1: [25.89581654] w2: [-23.57655653] bias: [16.04610834] loss: 30.524085804312463\n",
            "Epoch: 495 / 500 batch step: 480\n",
            "w1: [25.87875967] w2: [-23.57811697] bias: [16.01981421] loss: 30.531237405406085\n",
            "Epoch: 496 / 500 batch step: 0\n",
            "w1: [25.87242822] w2: [-23.57903789] bias: [16.00663638] loss: 30.535452362929128\n",
            "Epoch: 496 / 500 batch step: 30\n",
            "w1: [25.86559014] w2: [-23.57909932] bias: [15.99303169] loss: 30.540366731370604\n",
            "Epoch: 496 / 500 batch step: 60\n",
            "w1: [25.84381672] w2: [-23.58622583] bias: [15.95154484] loss: 30.560062938698227\n",
            "Epoch: 496 / 500 batch step: 90\n",
            "w1: [25.83727454] w2: [-23.59020091] bias: [15.9362333] loss: 30.568669981466797\n",
            "Epoch: 496 / 500 batch step: 120\n",
            "w1: [25.84716518] w2: [-23.55929198] bias: [15.97288988] loss: 30.54832853989575\n",
            "Epoch: 496 / 500 batch step: 150\n",
            "w1: [25.88164878] w2: [-23.55794746] bias: [16.01675184] loss: 30.53018967758219\n",
            "Epoch: 496 / 500 batch step: 180\n",
            "w1: [25.9493332] w2: [-23.54090156] bias: [16.11931705] loss: 30.518197211525397\n",
            "Epoch: 496 / 500 batch step: 210\n",
            "w1: [25.98625376] w2: [-23.52049438] bias: [16.17853118] loss: 30.530469277732692\n",
            "Epoch: 496 / 500 batch step: 240\n",
            "w1: [26.02521093] w2: [-23.51460724] bias: [16.22029381] loss: 30.549084597229644\n",
            "Epoch: 496 / 500 batch step: 270\n",
            "w1: [26.04155722] w2: [-23.51474587] bias: [16.23726623] loss: 30.558782920361743\n",
            "Epoch: 496 / 500 batch step: 300\n",
            "w1: [26.02176322] w2: [-23.52102132] bias: [16.19812684] loss: 30.540386796618556\n",
            "Epoch: 496 / 500 batch step: 330\n",
            "w1: [25.9855456] w2: [-23.53369461] bias: [16.12670218] loss: 30.520387957666358\n",
            "Epoch: 496 / 500 batch step: 360\n",
            "w1: [25.99697042] w2: [-23.50395199] bias: [16.21651224] loss: 30.544145435516967\n",
            "Epoch: 496 / 500 batch step: 390\n",
            "w1: [25.97142545] w2: [-23.51545562] bias: [16.18273765] loss: 30.530218077501257\n",
            "Epoch: 496 / 500 batch step: 420\n",
            "w1: [25.9222664] w2: [-23.55857722] bias: [16.08824561] loss: 30.51779006246831\n",
            "Epoch: 496 / 500 batch step: 450\n",
            "w1: [25.89702213] w2: [-23.57608984] bias: [16.04533092] loss: 30.524068174764977\n",
            "Epoch: 496 / 500 batch step: 480\n",
            "w1: [25.87996571] w2: [-23.57764983] bias: [16.01903796] loss: 30.531219477974382\n",
            "Epoch: 497 / 500 batch step: 0\n",
            "w1: [25.87363451] w2: [-23.57857059] bias: [16.00586084] loss: 30.535434221068435\n",
            "Epoch: 497 / 500 batch step: 30\n",
            "w1: [25.86679695] w2: [-23.57863179] bias: [15.99225731] loss: 30.54034812170578\n",
            "Epoch: 497 / 500 batch step: 60\n",
            "w1: [25.84502401] w2: [-23.58575806] bias: [15.95077159] loss: 30.560043534039792\n",
            "Epoch: 497 / 500 batch step: 90\n",
            "w1: [25.83848163] w2: [-23.58973305] bias: [15.93546] loss: 30.568650551424913\n",
            "Epoch: 497 / 500 batch step: 120\n",
            "w1: [25.8483723] w2: [-23.55882401] bias: [15.97211681] loss: 30.54830896457293\n",
            "Epoch: 497 / 500 batch step: 150\n",
            "w1: [25.88285584] w2: [-23.55747915] bias: [16.01597939] loss: 30.530170672235442\n",
            "Epoch: 497 / 500 batch step: 180\n",
            "w1: [25.95053925] w2: [-23.54043324] bias: [16.11854347] loss: 30.518179593952933\n",
            "Epoch: 497 / 500 batch step: 210\n",
            "w1: [25.98745844] w2: [-23.52002614] bias: [16.17775611] loss: 30.53045163204874\n",
            "Epoch: 497 / 500 batch step: 240\n",
            "w1: [26.02641423] w2: [-23.51413913] bias: [16.21951743] loss: 30.54906663583974\n",
            "Epoch: 497 / 500 batch step: 270\n",
            "w1: [26.04276011] w2: [-23.51427771] bias: [16.23648952] loss: 30.5587648324635\n",
            "Epoch: 497 / 500 batch step: 300\n",
            "w1: [26.02296646] w2: [-23.52055293] bias: [16.19735108] loss: 30.540369341005412\n",
            "Epoch: 497 / 500 batch step: 330\n",
            "w1: [25.98674941] w2: [-23.53322596] bias: [16.12592771] loss: 30.520370964902245\n",
            "Epoch: 497 / 500 batch step: 360\n",
            "w1: [25.99817381] w2: [-23.50348296] bias: [16.21573889] loss: 30.54412798499\n",
            "Epoch: 497 / 500 batch step: 390\n",
            "w1: [25.97262838] w2: [-23.51498683] bias: [16.181964] loss: 30.53020020142014\n",
            "Epoch: 497 / 500 batch step: 420\n",
            "w1: [25.92346862] w2: [-23.55810919] bias: [16.0874707] loss: 30.51777220897901\n",
            "Epoch: 497 / 500 batch step: 450\n",
            "w1: [25.89822381] w2: [-23.57562215] bias: [16.04455523] loss: 30.52405063765524\n",
            "Epoch: 497 / 500 batch step: 480\n",
            "w1: [25.88116784] w2: [-23.57718169] bias: [16.01826343] loss: 30.531201646906297\n",
            "Epoch: 498 / 500 batch step: 0\n",
            "w1: [25.8748369] w2: [-23.57810228] bias: [16.00508703] loss: 30.53541617753452\n",
            "Epoch: 498 / 500 batch step: 30\n",
            "w1: [25.86799984] w2: [-23.57816325] bias: [15.99148466] loss: 30.54032961257585\n",
            "Epoch: 498 / 500 batch step: 60\n",
            "w1: [25.8462274] w2: [-23.58528929] bias: [15.95000006] loss: 30.560024232124682\n",
            "Epoch: 498 / 500 batch step: 90\n",
            "w1: [25.83968481] w2: [-23.58926418] bias: [15.93468843] loss: 30.568631223154405\n",
            "Epoch: 498 / 500 batch step: 120\n",
            "w1: [25.84957551] w2: [-23.55835505] bias: [15.97134546] loss: 30.548289500445527\n",
            "Epoch: 498 / 500 batch step: 150\n",
            "w1: [25.884059] w2: [-23.55700985] bias: [16.01520865] loss: 30.53015176891965\n",
            "Epoch: 498 / 500 batch step: 180\n",
            "w1: [25.9517414] w2: [-23.53996393] bias: [16.11777162] loss: 30.518162066779087\n",
            "Epoch: 498 / 500 batch step: 210\n",
            "w1: [25.98865922] w2: [-23.51955689] bias: [16.17698279] loss: 30.53043407750828\n",
            "Epoch: 498 / 500 batch step: 240\n",
            "w1: [26.02761365] w2: [-23.51367001] bias: [16.21874281] loss: 30.549048767060516\n",
            "Epoch: 498 / 500 batch step: 270\n",
            "w1: [26.04395913] w2: [-23.51380856] bias: [16.23571457] loss: 30.55874684102492\n",
            "Epoch: 498 / 500 batch step: 300\n",
            "w1: [26.02416582] w2: [-23.52008353] bias: [16.19657707] loss: 30.54035198046686\n",
            "Epoch: 498 / 500 batch step: 330\n",
            "w1: [25.98794934] w2: [-23.53275631] bias: [16.12515501] loss: 30.520354062795896\n",
            "Epoch: 498 / 500 batch step: 360\n",
            "w1: [25.99937332] w2: [-23.50301294] bias: [16.2149673] loss: 30.544110633543767\n",
            "Epoch: 498 / 500 batch step: 390\n",
            "w1: [25.97382744] w2: [-23.51451706] bias: [16.1811921] loss: 30.53018241935794\n",
            "Epoch: 498 / 500 batch step: 420\n",
            "w1: [25.92466696] w2: [-23.55764017] bias: [16.08669752] loss: 30.51775444632503\n",
            "Epoch: 498 / 500 batch step: 450\n",
            "w1: [25.89942161] w2: [-23.57515347] bias: [16.04378128] loss: 30.524033192195194\n",
            "Epoch: 498 / 500 batch step: 480\n",
            "w1: [25.88236609] w2: [-23.57671257] bias: [16.01749064] loss: 30.531183911352283\n",
            "Epoch: 499 / 500 batch step: 0\n",
            "w1: [25.87603541] w2: [-23.577633] bias: [16.00431495] loss: 30.53539823144949\n",
            "Epoch: 499 / 500 batch step: 30\n",
            "w1: [25.86919886] w2: [-23.57769375] bias: [15.99071373] loss: 30.540311203079316\n",
            "Epoch: 499 / 500 batch step: 60\n",
            "w1: [25.8474269] w2: [-23.58481954] bias: [15.94923027] loss: 30.56000503204002\n",
            "Epoch: 499 / 500 batch step: 90\n",
            "w1: [25.84088412] w2: [-23.58879434] bias: [15.93391859] loss: 30.56861199576134\n",
            "Epoch: 499 / 500 batch step: 120\n",
            "w1: [25.85077484] w2: [-23.55788512] bias: [15.97057582] loss: 30.548270146451426\n",
            "Epoch: 499 / 500 batch step: 150\n",
            "w1: [25.88525828] w2: [-23.55653958] bias: [16.01443964] loss: 30.53013296672065\n",
            "Epoch: 499 / 500 batch step: 180\n",
            "w1: [25.95293968] w2: [-23.53949365] bias: [16.1170015] loss: 30.518144629253154\n",
            "Epoch: 499 / 500 batch step: 210\n",
            "w1: [25.98985614] w2: [-23.51908669] bias: [16.1762112] loss: 30.530416613348113\n",
            "Epoch: 499 / 500 batch step: 240\n",
            "w1: [26.02880922] w2: [-23.51319993] bias: [16.21796993] loss: 30.549030990113412\n",
            "Epoch: 499 / 500 batch step: 270\n",
            "w1: [26.04515431] w2: [-23.51333844] bias: [16.23494137] loss: 30.558728945201235\n",
            "Epoch: 499 / 500 batch step: 300\n",
            "w1: [26.02536134] w2: [-23.51961317] bias: [16.19580483] loss: 30.540334714160426\n",
            "Epoch: 499 / 500 batch step: 330\n",
            "w1: [25.98914543] w2: [-23.53228569] bias: [16.12438407] loss: 30.52033725056933\n",
            "Epoch: 499 / 500 batch step: 360\n",
            "w1: [26.00056899] w2: [-23.50254197] bias: [16.21419746] loss: 30.544093380262325\n",
            "Epoch: 499 / 500 batch step: 390\n",
            "w1: [25.97502264] w2: [-23.51404635] bias: [16.18042193] loss: 30.530164730507398\n",
            "Epoch: 499 / 500 batch step: 420\n",
            "w1: [25.92586145] w2: [-23.55717021] bias: [16.08592607] loss: 30.517736773756827\n",
            "Epoch: 499 / 500 batch step: 450\n",
            "w1: [25.90061556] w2: [-23.57468385] bias: [16.04300905] loss: 30.524015837608925\n",
            "Epoch: 499 / 500 batch step: 480\n",
            "w1: [25.88356048] w2: [-23.57624252] bias: [16.01671957] loss: 30.531166270475943\n",
            "Epoch: 500 / 500 batch step: 0\n",
            "w1: [25.87723006] w2: [-23.57716278] bias: [16.00354458] loss: 30.53538038194904\n",
            "Epoch: 500 / 500 batch step: 30\n",
            "w1: [25.87039402] w2: [-23.57722331] bias: [15.98994451] loss: 30.54029289232863\n",
            "Epoch: 500 / 500 batch step: 60\n",
            "w1: [25.84862255] w2: [-23.58434886] bias: [15.94846219] loss: 30.559985932886946\n",
            "Epoch: 500 / 500 batch step: 90\n",
            "w1: [25.84207958] w2: [-23.58832356] bias: [15.93315047] loss: 30.568592868365435\n",
            "Epoch: 500 / 500 batch step: 120\n",
            "w1: [25.85197032] w2: [-23.55741426] bias: [15.9698079] loss: 30.548250901545\n",
            "Epoch: 500 / 500 batch step: 150\n",
            "w1: [25.88645371] w2: [-23.55606838] bias: [16.01367235] loss: 30.530114264738376\n",
            "Epoch: 500 / 500 batch step: 180\n",
            "w1: [25.95413412] w2: [-23.53902245] bias: [16.11623311] loss: 30.518127280635937\n",
            "Epoch: 500 / 500 batch step: 210\n",
            "w1: [25.99104923] w2: [-23.51861556] bias: [16.17544135] loss: 30.53039923881674\n",
            "Epoch: 500 / 500 batch step: 240\n",
            "w1: [26.03000097] w2: [-23.51272892] bias: [16.2171988] loss: 30.54901330423182\n",
            "Epoch: 500 / 500 batch step: 270\n",
            "w1: [26.04634566] w2: [-23.51286739] bias: [16.23416993] loss: 30.558711144160675\n",
            "Epoch: 500 / 500 batch step: 300\n",
            "w1: [26.02655303] w2: [-23.51914188] bias: [16.19503434] loss: 30.540317541256666\n",
            "Epoch: 500 / 500 batch step: 330\n",
            "w1: [25.9903377] w2: [-23.53181414] bias: [16.12361488] loss: 30.520320527456555\n",
            "Epoch: 500 / 500 batch step: 360\n",
            "w1: [26.00176084] w2: [-23.50207008] bias: [16.21342936] loss: 30.54407622424397\n",
            "Epoch: 500 / 500 batch step: 390\n",
            "w1: [25.97621403] w2: [-23.51357472] bias: [16.17965349] loss: 30.53014713407361\n",
            "Epoch: 500 / 500 batch step: 420\n",
            "w1: [25.92705212] w2: [-23.55669935] bias: [16.08515635] loss: 30.51771919053627\n",
            "Epoch: 500 / 500 batch step: 450\n",
            "w1: [25.90180568] w2: [-23.57421332] bias: [16.04223854] loss: 30.5239985731324\n",
            "Epoch: 500 / 500 batch step: 480\n",
            "w1: [25.88475105] w2: [-23.57577155] bias: [16.01595022] loss: 30.53114872345372\n",
            "##### 최종 w1, w2, bias #######\n",
            "[25.88475105] [-23.57577155] [16.01595022]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weight와 bias로 예측 값 생성 후 dataFrame에 'PREDICTED_PRICE_BATCH' 컬럼 추가\n",
        "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
        "bostonDF['PREDICTED_PRICE_BATCH'] = predicted\n",
        "bostonDF.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "BPJ_guI5u7Yq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "69b24c22-a580-40d2-d81a-2c37d22bbd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE_BATCH  \n",
              "0     15.3  396.90   4.98   24.0              28.850257  \n",
              "1     17.8  396.90   9.14   21.6              25.380192  \n",
              "2     17.8  392.83   4.03   34.7              32.493701  \n",
              "3     18.7  394.63   2.94   33.4              32.275330  \n",
              "4     18.7  396.90   5.33   36.2              31.459523  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1aa71b9b-e3bf-46e4-b24f-49f07994b2d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE_BATCH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.850257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.380192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.493701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.275330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.459523</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1aa71b9b-e3bf-46e4-b24f-49f07994b2d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1aa71b9b-e3bf-46e4-b24f-49f07994b2d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1aa71b9b-e3bf-46e4-b24f-49f07994b2d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17027a8d-0e3b-4bb1-9471-6f9e8e34e4e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17027a8d-0e3b-4bb1-9471-6f9e8e34e4e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17027a8d-0e3b-4bb1-9471-6f9e8e34e4e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bostonDF",
              "summary": "{\n  \"name\": \"bostonDF\",\n  \"rows\": 506,\n  \"fields\": [\n    {\n      \"column\": \"CRIM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.60154510533249,\n        \"min\": 0.00632,\n        \"max\": 88.9762,\n        \"num_unique_values\": 504,\n        \"samples\": [\n          0.09178,\n          0.05644,\n          0.10574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.32245299451514,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          25.0,\n          30.0,\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INDUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.860352940897585,\n        \"min\": 0.46,\n        \"max\": 27.74,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          8.14,\n          1.47,\n          1.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CHAS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25399404134041037,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NOX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11587767566755595,\n        \"min\": 0.385,\n        \"max\": 0.871,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          0.401,\n          0.538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7026171434153233,\n        \"min\": 3.561,\n        \"max\": 8.78,\n        \"num_unique_values\": 446,\n        \"samples\": [\n          6.849,\n          4.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.148861406903617,\n        \"min\": 2.9,\n        \"max\": 100.0,\n        \"num_unique_values\": 356,\n        \"samples\": [\n          51.8,\n          33.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DIS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.105710126627611,\n        \"min\": 1.1296,\n        \"max\": 12.1265,\n        \"num_unique_values\": 412,\n        \"samples\": [\n          2.2955,\n          4.2515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.707259384239366,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 168.53711605495903,\n        \"min\": 187.0,\n        \"max\": 711.0,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          370.0,\n          666.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PTRATIO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1649455237144406,\n        \"min\": 12.6,\n        \"max\": 22.0,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          19.6,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91.29486438415783,\n        \"min\": 0.32,\n        \"max\": 396.9,\n        \"num_unique_values\": 357,\n        \"samples\": [\n          396.24,\n          395.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LSTAT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.141061511348571,\n        \"min\": 1.73,\n        \"max\": 37.97,\n        \"num_unique_values\": 455,\n        \"samples\": [\n          6.15,\n          4.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRICE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.197104087379818,\n        \"min\": 5.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          14.1,\n          22.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PREDICTED_PRICE_BATCH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.321124351199802,\n        \"min\": -4.6980659527171476,\n        \"max\": 39.74133479801449,\n        \"num_unique_values\": 506,\n        \"samples\": [\n          25.420447565741004,\n          30.701176100741876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini BATCH GD를 Keras로 수행\n",
        "* Keras는 기본적으로 (Random) Mini Batch GD를 수행"
      ],
      "metadata": {
        "id": "200_Fl5Wu7Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "  # 단 하나의 units 설정. input_shape는 2차원, 회귀이므로 activation은 설정하지 않음.\n",
        "  # weight와 bias 초기화는 kernel_inbitializer와 bias_initializer를 이용.\n",
        "  Dense(1, input_shape=(2, ), activation=None, kernel_initializer='zeros', bias_initializer='ones')\n",
        "])\n",
        "\n",
        "# Adam optimizer를 이용하고 Loss 함수는 Mean Squared Error, 성능 측정 역시 MSE를 이용하여 학습 수행.\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n",
        "\n",
        "# Keras는 반드시 Batch GD를 적용함. batch_size는 30으로(None이면 32), epoch 횟수는 500 할당\n",
        "model.fit(scaled_features, bostonDF['PRICE'].values, batch_size=30, epochs=500)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yGmpCL7fu7Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras로 예측하고 dataFrame에 'KERAS_PREDICTED_PRICE_BATCH' 컬럼으로 추가하기\n",
        "predicted = model.predict(scaled_features)\n",
        "bostonDF['KERAS_PREDICTED_PRICE_BATCH'] = predicted\n",
        "\n",
        "bostonDF.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "u4BtJfXUu7Yr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "b58098c1-9203-4692-d85e-cc72024b55f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE_BATCH  \\\n",
              "0     15.3  396.90   4.98   24.0              28.850257   \n",
              "1     17.8  396.90   9.14   21.6              25.380192   \n",
              "2     17.8  392.83   4.03   34.7              32.493701   \n",
              "3     18.7  394.63   2.94   33.4              32.275330   \n",
              "4     18.7  396.90   5.33   36.2              31.459523   \n",
              "\n",
              "   KERAS_PREDICTED_PRICE_BATCH  \n",
              "0                    28.910387  \n",
              "1                    25.478966  \n",
              "2                    32.455235  \n",
              "3                    32.262241  \n",
              "4                    31.431549  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02be2e50-64fa-4701-8967-77fe0dec5b39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE_BATCH</th>\n",
              "      <th>KERAS_PREDICTED_PRICE_BATCH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.850257</td>\n",
              "      <td>28.910387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.380192</td>\n",
              "      <td>25.478966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.493701</td>\n",
              "      <td>32.455235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.275330</td>\n",
              "      <td>32.262241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.459523</td>\n",
              "      <td>31.431549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02be2e50-64fa-4701-8967-77fe0dec5b39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02be2e50-64fa-4701-8967-77fe0dec5b39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02be2e50-64fa-4701-8967-77fe0dec5b39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-354f4c41-ffcb-44c1-97d8-8cff619bdbe4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-354f4c41-ffcb-44c1-97d8-8cff619bdbe4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-354f4c41-ffcb-44c1-97d8-8cff619bdbe4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bostonDF",
              "summary": "{\n  \"name\": \"bostonDF\",\n  \"rows\": 506,\n  \"fields\": [\n    {\n      \"column\": \"CRIM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.60154510533249,\n        \"min\": 0.00632,\n        \"max\": 88.9762,\n        \"num_unique_values\": 504,\n        \"samples\": [\n          0.09178,\n          0.05644,\n          0.10574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.32245299451514,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          25.0,\n          30.0,\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INDUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.860352940897585,\n        \"min\": 0.46,\n        \"max\": 27.74,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          8.14,\n          1.47,\n          1.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CHAS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25399404134041037,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NOX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11587767566755595,\n        \"min\": 0.385,\n        \"max\": 0.871,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          0.401,\n          0.538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7026171434153233,\n        \"min\": 3.561,\n        \"max\": 8.78,\n        \"num_unique_values\": 446,\n        \"samples\": [\n          6.849,\n          4.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.148861406903617,\n        \"min\": 2.9,\n        \"max\": 100.0,\n        \"num_unique_values\": 356,\n        \"samples\": [\n          51.8,\n          33.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DIS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.105710126627611,\n        \"min\": 1.1296,\n        \"max\": 12.1265,\n        \"num_unique_values\": 412,\n        \"samples\": [\n          2.2955,\n          4.2515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.707259384239366,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 168.53711605495903,\n        \"min\": 187.0,\n        \"max\": 711.0,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          370.0,\n          666.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PTRATIO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1649455237144406,\n        \"min\": 12.6,\n        \"max\": 22.0,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          19.6,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91.29486438415783,\n        \"min\": 0.32,\n        \"max\": 396.9,\n        \"num_unique_values\": 357,\n        \"samples\": [\n          396.24,\n          395.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LSTAT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.141061511348571,\n        \"min\": 1.73,\n        \"max\": 37.97,\n        \"num_unique_values\": 455,\n        \"samples\": [\n          6.15,\n          4.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRICE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.197104087379818,\n        \"min\": 5.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          14.1,\n          22.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PREDICTED_PRICE_BATCH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.321124351199802,\n        \"min\": -4.6980659527171476,\n        \"max\": 39.74133479801449,\n        \"num_unique_values\": 506,\n        \"samples\": [\n          25.420447565741004,\n          30.701176100741876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KERAS_PREDICTED_PRICE_BATCH\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 506,\n        \"samples\": [\n          25.5196533203125,\n          30.727638244628906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}